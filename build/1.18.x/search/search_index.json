{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"MinecraftForge Documentation This is the official documentation for MinecraftForge , the Minecraft modding API. This documentation is only for Forge, this is not a Java tutorial . Contribute to the docs at GitHub .","title":"Home"},{"location":"#minecraftforge-documentation","text":"This is the official documentation for MinecraftForge , the Minecraft modding API. This documentation is only for Forge, this is not a Java tutorial . Contribute to the docs at GitHub .","title":"MinecraftForge Documentation"},{"location":"contributing/","text":"Contributing to This Documentation This documentation is meant to be explanatory. Please explain how to do things, and break it down into reasonable chunks. We have a wiki elsewhere that can capture more comprehensive code examples. Our audience is anyone who wants to understand how to build a mod using Forge. Please don\u2019t try to turn this documentation into a tutorial on Java Development - it is intended for people who understand how a Java class works, and other fundamental structures of Java. Style Guide Important Please use two spaces to indent, not tabs. Titles should be capitalized in the standard titling format. For example, Guide For Contributing to This Documentation Building and Testing Your Mod Essentially, capitalize everything but unimportant words. Spelling, grammar, and syntax should follow those of American English. Also, prefer using separate words over contractions (e.g. \u201care not\u201d instead of \u201caren\u2019t\u201d). Please use equals and dash underlines, instead of # and ## . For h3 and lower, ### etc. is fine. The source of this file contains an example for equals and dash underlining. Equals underlines create h1 text, and dash underlines create h2 text. When referencing fields and methods outside of code block snippets, they should use a # separator (e.g. ClassName#methodName ). Inner classes should use a $ separator (e.g. ClassName$InnerClassName ). JSON code block snippets should use js syntax highlighting. All links should have their location specified at the bottom of the page. Any internal links should reference the page via their relative path. Admonitions (represented by !!! <type> ) must be formatted as documented ; otherwise they may end up rendering incorrectly.","title":"Contributing to the Docs"},{"location":"contributing/#contributing-to-this-documentation","text":"This documentation is meant to be explanatory. Please explain how to do things, and break it down into reasonable chunks. We have a wiki elsewhere that can capture more comprehensive code examples. Our audience is anyone who wants to understand how to build a mod using Forge. Please don\u2019t try to turn this documentation into a tutorial on Java Development - it is intended for people who understand how a Java class works, and other fundamental structures of Java.","title":"Contributing to This Documentation"},{"location":"contributing/#style-guide","text":"Important Please use two spaces to indent, not tabs. Titles should be capitalized in the standard titling format. For example, Guide For Contributing to This Documentation Building and Testing Your Mod Essentially, capitalize everything but unimportant words. Spelling, grammar, and syntax should follow those of American English. Also, prefer using separate words over contractions (e.g. \u201care not\u201d instead of \u201caren\u2019t\u201d). Please use equals and dash underlines, instead of # and ## . For h3 and lower, ### etc. is fine. The source of this file contains an example for equals and dash underlining. Equals underlines create h1 text, and dash underlines create h2 text. When referencing fields and methods outside of code block snippets, they should use a # separator (e.g. ClassName#methodName ). Inner classes should use a $ separator (e.g. ClassName$InnerClassName ). JSON code block snippets should use js syntax highlighting. All links should have their location specified at the bottom of the page. Any internal links should reference the page via their relative path. Admonitions (represented by !!! <type> ) must be formatted as documented ; otherwise they may end up rendering incorrectly.","title":"Style Guide"},{"location":"advanced/accesstransformers/","text":"Access Transformers Access Transformers (ATs for short) allow for widening the visibility and modifying the final flags of classes, methods, and fields. They allow modders to access and modify otherwise inaccessible members in classes outside their control. The specification document can be viewed on the Minecraft Forge GitHub. Adding ATs Adding an Access Transformer to your mod project is as simple as adding a single line into your build.gradle : // This block is where your mappings version is also specified minecraft { accessTransformer = file('src/main/resources/META-INF/accesstransformer.cfg') } After adding or modifying the Access Transformer, the gradle project must be refreshed for the transformations to take effect. During development, the AT file can be anywhere specified by the line above. However, when loading in a non-development environment, Forge will only search for the exact path of META-INF/accesstransformer.cfg in your JAR file. Comments All text after a # until the end of the line will be treated as a comment and will not be parsed. Access Modifiers Access modifiers specify to what new member visibility the given target will be transformed to. In decreasing order of visibility: public - visible to all classes inside and outside its package protected - visible only to classes inside the package and subclasses default - visible only to classes inside the package private - visible only to inside the class A special modifier +f and -f can be appended to the aforementioned modifiers to either add or remove respectively the final modifier, which prevents subclassing, method overriding, or field modification when applied. Warning Directives only modify the method they directly reference; any overriding methods will not be access-transformed. It is advised to ensure transformed methods do not have non-transformed overrides that restrict the visibility, which will result in the JVM throwing an error. Examples of methods that can be safely transformed are private methods, final methods (or methods in final classes), and static methods. Targets and Directives Important When using Access Transformers on Minecraft classes, the SRG name must be used for fields and methods. Classes To target classes: <access modifier> <fully qualified class name> Inner classes are denoted by combining the fully qualified name of the outer class and the name of the inner class with a $ as separator. Fields To target fields: <access modifier> <fully qualified class name> <field name> Methods Targeting methods require a special syntax to denote the method parameters and return type: <access modifier> <fully qualified class name> <method name>(<parameter types>)<return type> Specifying Types Also called \u201cdescriptors\u201d: see the Java Virtual Machine Specification, SE 8, sections 4.3.2 and 4.3.3 for more technical details. B - byte , a signed byte C - char , a Unicode character code point in UTF-16 D - double , a double-precision floating-point value F - float , a single-precision floating-point value I - integer , a 32-bit integer J - long , a 64-bit integer S - short , a signed short Z - boolean , a true or false value [ - references one dimension of an array Example: [[S refers to short[][] L<class name>; - references a reference type Example: Ljava/lang/String; refers to java.lang.String reference type (note the use of slashes instead of periods) ( - references a method descriptor, parameters should be supplied here or nothing if no parameters are present Example: <method>(I)Z refers to a method that requires an integer argument and returns a boolean V - indicates a method returns no value, can only be used at the end of a method descriptor Example: <method>()V refers to a method that has no arguments and returns nothing Examples # Makes public the ScreenConstructor class in MenuScreens public net.minecraft.client.gui.screens.MenuScreens$ScreenConstructor # Makes protected and removes the final modifier from 'random' in MinecraftServer protected-f net.minecraft.server.MinecraftServer f_129758_ #random # Makes public the 'makeExecutor' method in Util, # accepting a String and returns an ExecutorService public net.minecraft.Util m_137477_(Ljava/lang/String;)Ljava/util/concurrent/ExecutorService; #makeExecutor # Makes public the 'leastMostToIntArray' method in SerializableUUID, # accepting two longs and returning an int[] public net.minecraft.core.SerializableUUID m_123274_(JJ)[I #leastMostToIntArray","title":"Access Transformers"},{"location":"advanced/accesstransformers/#access-transformers","text":"Access Transformers (ATs for short) allow for widening the visibility and modifying the final flags of classes, methods, and fields. They allow modders to access and modify otherwise inaccessible members in classes outside their control. The specification document can be viewed on the Minecraft Forge GitHub.","title":"Access Transformers"},{"location":"advanced/accesstransformers/#adding-ats","text":"Adding an Access Transformer to your mod project is as simple as adding a single line into your build.gradle : // This block is where your mappings version is also specified minecraft { accessTransformer = file('src/main/resources/META-INF/accesstransformer.cfg') } After adding or modifying the Access Transformer, the gradle project must be refreshed for the transformations to take effect. During development, the AT file can be anywhere specified by the line above. However, when loading in a non-development environment, Forge will only search for the exact path of META-INF/accesstransformer.cfg in your JAR file.","title":"Adding ATs"},{"location":"advanced/accesstransformers/#comments","text":"All text after a # until the end of the line will be treated as a comment and will not be parsed.","title":"Comments"},{"location":"advanced/accesstransformers/#access-modifiers","text":"Access modifiers specify to what new member visibility the given target will be transformed to. In decreasing order of visibility: public - visible to all classes inside and outside its package protected - visible only to classes inside the package and subclasses default - visible only to classes inside the package private - visible only to inside the class A special modifier +f and -f can be appended to the aforementioned modifiers to either add or remove respectively the final modifier, which prevents subclassing, method overriding, or field modification when applied. Warning Directives only modify the method they directly reference; any overriding methods will not be access-transformed. It is advised to ensure transformed methods do not have non-transformed overrides that restrict the visibility, which will result in the JVM throwing an error. Examples of methods that can be safely transformed are private methods, final methods (or methods in final classes), and static methods.","title":"Access Modifiers"},{"location":"advanced/accesstransformers/#targets-and-directives","text":"Important When using Access Transformers on Minecraft classes, the SRG name must be used for fields and methods.","title":"Targets and Directives"},{"location":"advanced/accesstransformers/#classes","text":"To target classes: <access modifier> <fully qualified class name> Inner classes are denoted by combining the fully qualified name of the outer class and the name of the inner class with a $ as separator.","title":"Classes"},{"location":"advanced/accesstransformers/#fields","text":"To target fields: <access modifier> <fully qualified class name> <field name>","title":"Fields"},{"location":"advanced/accesstransformers/#methods","text":"Targeting methods require a special syntax to denote the method parameters and return type: <access modifier> <fully qualified class name> <method name>(<parameter types>)<return type>","title":"Methods"},{"location":"advanced/accesstransformers/#specifying-types","text":"Also called \u201cdescriptors\u201d: see the Java Virtual Machine Specification, SE 8, sections 4.3.2 and 4.3.3 for more technical details. B - byte , a signed byte C - char , a Unicode character code point in UTF-16 D - double , a double-precision floating-point value F - float , a single-precision floating-point value I - integer , a 32-bit integer J - long , a 64-bit integer S - short , a signed short Z - boolean , a true or false value [ - references one dimension of an array Example: [[S refers to short[][] L<class name>; - references a reference type Example: Ljava/lang/String; refers to java.lang.String reference type (note the use of slashes instead of periods) ( - references a method descriptor, parameters should be supplied here or nothing if no parameters are present Example: <method>(I)Z refers to a method that requires an integer argument and returns a boolean V - indicates a method returns no value, can only be used at the end of a method descriptor Example: <method>()V refers to a method that has no arguments and returns nothing","title":"Specifying Types"},{"location":"advanced/accesstransformers/#examples","text":"# Makes public the ScreenConstructor class in MenuScreens public net.minecraft.client.gui.screens.MenuScreens$ScreenConstructor # Makes protected and removes the final modifier from 'random' in MinecraftServer protected-f net.minecraft.server.MinecraftServer f_129758_ #random # Makes public the 'makeExecutor' method in Util, # accepting a String and returns an ExecutorService public net.minecraft.Util m_137477_(Ljava/lang/String;)Ljava/util/concurrent/ExecutorService; #makeExecutor # Makes public the 'leastMostToIntArray' method in SerializableUUID, # accepting two longs and returning an int[] public net.minecraft.core.SerializableUUID m_123274_(JJ)[I #leastMostToIntArray","title":"Examples"},{"location":"blockentities/","text":"BlockEntities BlockEntities are like simplified Entities that are bound to a Block. They are used to store dynamic data, execute tick based tasks, and dynamic rendering. Some examples from vanilla Minecraft would be handling of inventories on chests, smelting logic on furnaces, or area effects on beacons. More advanced examples exist in mods, such as quarries, sorting machines, pipes, and displays. Note BlockEntities aren\u2019t a solution for everything and they can cause lag when used wrongly. When possible, try to avoid them. Registering Block Entities are created and removed dynamically and as such are not registry objects on their own. In order to create a BlockEntity , you need to extend the BlockEntity class. As such, another object is registered instead to easily create and refer to the type of the dynamic object. For a BlockEntity , these are known as BlockEntityType s. A BlockEntityType can be registered like any other registry object. To construct a BlockEntityType , its builder form can be used via BlockEntityType$Builder#of . This takes in two arguments: a BlockEntityType$BlockEntitySupplier which takes in a BlockPos and BlockState to create a new instance of the associated BlockEntity , and a varargs of Block s which this BlockEntity can be attached to. Building the BlockEntityType is done by calling BlockEntityType$Builder#build . This takes in a Type which represents the type-safe reference used to refer to this registry object in a DataFixer . Since DataFixer s are an optional system to use for mods, this can be passed as null . // For some DeferredRegister<BlockEntityType<?>> REGISTER public static final RegistryObject<BlockEntityType<MyBE>> MY_BE = REGISTER.register(\"mybe\", () -> BlockEntityType.Builder.of(MyBE::new, validBlocks).build(null)); // In MyBE, a BlockEntity subclass public MyBE(BlockPos pos, BlockState state) { super(MY_BE.get(), pos, state); } Creating a BlockEntity To create a BlockEntity and attach it to a Block , the EntityBlock interface must be implemented on your Block subclass. The method EntityBlock#newBlockEntity(BlockPos, BlockState) must be implemented and return a new instance of your BlockEntity . Storing Data within your BlockEntity In order to save data, override the following two methods: BlockEntity#saveAdditional(CompoundTag tag) BlockEntity#load(CompoundTag tag) These methods are called whenever the LevelChunk containing the BlockEntity gets loaded from/saved to a tag. Use them to read and write to the fields in your block entity class. Note Whenever your data changes, you need to call BlockEntity#setChanged ; otherwise, the LevelChunk containing your BlockEntity might be skipped while the level is saved. Important It is important that you call the super methods! The tag names id , x , y , z , ForgeData and ForgeCaps are reserved by the super methods. Ticking BlockEntities If you need a ticking BlockEntity , for example to keep track of the progress during a smelting process, another method must be implemented and overridden within EntityBlock : EntityBlock#getTicker(Level, BlockState, BlockEntityType) . This can implement different tickers depending on which logical side the user is on, or just implement one general ticker. In either case, a BlockEntityTicker must be returned. Since this is a functional interface, it can just take in a method representing the ticker instead: // Inside some Block subclass @Nullable @Override public <T extends BlockEntity> BlockEntityTicker<T> getTicker(Level level, BlockState state, BlockEntityType<T> type) { return type == MyBlockEntityTypes.MYBE.get() ? MyBlockEntity::tick : null; } // Inside MyBlockEntity public static void tick(Level level, BlockPos pos, BlockState state, T blockEntity) { // Do stuff } Note This method is called each tick; therefore, you should avoid having complicated calculations in here. If possible, you should make more complex calculations every X ticks. (The amount of ticks in a second may be lower then 20 (twenty) but won\u2019t be higher) Synchronizing the Data to the Client There are three ways of syncing data to the client: synchronizing on chunk load, on block updates, and with a custom network message. Synchronizing on LevelChunk Load For this you need to override BlockEntity#getUpdateTag() IForgeBlockEntity#handleUpdateTag(CompoundTag tag) Again, this is pretty simple, the first method collects the data that should be sent to the client, while the second one processes that data. If your BlockEntity doesn\u2019t contain much data, you might be able to use the methods out of the Storing Data within your BlockEntity section. Important Synchronizing excessive/useless data for block entities can lead to network congestion. You should optimize your network usage by sending only the information the client needs when the client needs it. For instance, it is more often than not unnecessary to send the inventory of a block entity in the update tag, as this can be synchronized via its AbstractContainerMenu . Synchronizing on Block Update This method is a bit more complicated, but again you just need to override two or three methods. Here is a tiny example implementation of it: @Override public CompoundTag getUpdateTag() { CompoundTag tag = new CompoundTag(); //Write your data into the tag return tag; } @Override public Packet<ClientGamePacketListener> getUpdatePacket() { // Will get tag from #getUpdateTag return ClientboundBlockEntityDataPacket.create(this); } // Can override IForgeBlockEntity#onDataPacket. By default, this will defer to the #load. The static constructors ClientboundBlockEntityDataPacket#create takes: The BlockEntity . An optional function to get the CompoundTag from the BlockEntity . By default, this uses BlockEntity#getUpdateTag . Now, to send the packet, an update notification must be given on the server. Level#sendBlockUpdated(BlockPos pos, BlockState oldState, BlockState newState, int flags) The pos should be your BlockEntity \u2018s position. For oldState and newState , you can pass the current BlockState at that position. flags is a bitmask that should contain 2 , which will sync the changes to the client. See Block for more info as well as the rest of the flags. The flag 2 is equivalent to Block#UPDATE_CLIENTS . Synchronizing Using a Custom Network Message This way of synchronizing is probably the most complicated but is usually the most optimized, as you can make sure that only the data you need to be synchronized is actually synchronized. You should first check out the Networking section and especially SimpleImpl before attempting this. Once you\u2019ve created your custom network message, you can send it to all users that have the BlockEntity loaded with SimpleChannel#send(PacketDistributor$PacketTarget, MSG) . Warning It is important that you do safety checks, the BlockEntity might already be destroyed/replaced when the message arrives at the player! You should also check if the chunk is loaded ( Level#hasChunkAt(BlockPos) ).","title":"Introduction"},{"location":"blockentities/#blockentities","text":"BlockEntities are like simplified Entities that are bound to a Block. They are used to store dynamic data, execute tick based tasks, and dynamic rendering. Some examples from vanilla Minecraft would be handling of inventories on chests, smelting logic on furnaces, or area effects on beacons. More advanced examples exist in mods, such as quarries, sorting machines, pipes, and displays. Note BlockEntities aren\u2019t a solution for everything and they can cause lag when used wrongly. When possible, try to avoid them.","title":"BlockEntities"},{"location":"blockentities/#registering","text":"Block Entities are created and removed dynamically and as such are not registry objects on their own. In order to create a BlockEntity , you need to extend the BlockEntity class. As such, another object is registered instead to easily create and refer to the type of the dynamic object. For a BlockEntity , these are known as BlockEntityType s. A BlockEntityType can be registered like any other registry object. To construct a BlockEntityType , its builder form can be used via BlockEntityType$Builder#of . This takes in two arguments: a BlockEntityType$BlockEntitySupplier which takes in a BlockPos and BlockState to create a new instance of the associated BlockEntity , and a varargs of Block s which this BlockEntity can be attached to. Building the BlockEntityType is done by calling BlockEntityType$Builder#build . This takes in a Type which represents the type-safe reference used to refer to this registry object in a DataFixer . Since DataFixer s are an optional system to use for mods, this can be passed as null . // For some DeferredRegister<BlockEntityType<?>> REGISTER public static final RegistryObject<BlockEntityType<MyBE>> MY_BE = REGISTER.register(\"mybe\", () -> BlockEntityType.Builder.of(MyBE::new, validBlocks).build(null)); // In MyBE, a BlockEntity subclass public MyBE(BlockPos pos, BlockState state) { super(MY_BE.get(), pos, state); }","title":"Registering"},{"location":"blockentities/#creating-a-blockentity","text":"To create a BlockEntity and attach it to a Block , the EntityBlock interface must be implemented on your Block subclass. The method EntityBlock#newBlockEntity(BlockPos, BlockState) must be implemented and return a new instance of your BlockEntity .","title":"Creating a BlockEntity"},{"location":"blockentities/#storing-data-within-your-blockentity","text":"In order to save data, override the following two methods: BlockEntity#saveAdditional(CompoundTag tag) BlockEntity#load(CompoundTag tag) These methods are called whenever the LevelChunk containing the BlockEntity gets loaded from/saved to a tag. Use them to read and write to the fields in your block entity class. Note Whenever your data changes, you need to call BlockEntity#setChanged ; otherwise, the LevelChunk containing your BlockEntity might be skipped while the level is saved. Important It is important that you call the super methods! The tag names id , x , y , z , ForgeData and ForgeCaps are reserved by the super methods.","title":"Storing Data within your BlockEntity"},{"location":"blockentities/#ticking-blockentities","text":"If you need a ticking BlockEntity , for example to keep track of the progress during a smelting process, another method must be implemented and overridden within EntityBlock : EntityBlock#getTicker(Level, BlockState, BlockEntityType) . This can implement different tickers depending on which logical side the user is on, or just implement one general ticker. In either case, a BlockEntityTicker must be returned. Since this is a functional interface, it can just take in a method representing the ticker instead: // Inside some Block subclass @Nullable @Override public <T extends BlockEntity> BlockEntityTicker<T> getTicker(Level level, BlockState state, BlockEntityType<T> type) { return type == MyBlockEntityTypes.MYBE.get() ? MyBlockEntity::tick : null; } // Inside MyBlockEntity public static void tick(Level level, BlockPos pos, BlockState state, T blockEntity) { // Do stuff } Note This method is called each tick; therefore, you should avoid having complicated calculations in here. If possible, you should make more complex calculations every X ticks. (The amount of ticks in a second may be lower then 20 (twenty) but won\u2019t be higher)","title":"Ticking BlockEntities"},{"location":"blockentities/#synchronizing-the-data-to-the-client","text":"There are three ways of syncing data to the client: synchronizing on chunk load, on block updates, and with a custom network message.","title":"Synchronizing the Data to the Client"},{"location":"blockentities/#synchronizing-on-levelchunk-load","text":"For this you need to override BlockEntity#getUpdateTag() IForgeBlockEntity#handleUpdateTag(CompoundTag tag) Again, this is pretty simple, the first method collects the data that should be sent to the client, while the second one processes that data. If your BlockEntity doesn\u2019t contain much data, you might be able to use the methods out of the Storing Data within your BlockEntity section. Important Synchronizing excessive/useless data for block entities can lead to network congestion. You should optimize your network usage by sending only the information the client needs when the client needs it. For instance, it is more often than not unnecessary to send the inventory of a block entity in the update tag, as this can be synchronized via its AbstractContainerMenu .","title":"Synchronizing on LevelChunk Load"},{"location":"blockentities/#synchronizing-on-block-update","text":"This method is a bit more complicated, but again you just need to override two or three methods. Here is a tiny example implementation of it: @Override public CompoundTag getUpdateTag() { CompoundTag tag = new CompoundTag(); //Write your data into the tag return tag; } @Override public Packet<ClientGamePacketListener> getUpdatePacket() { // Will get tag from #getUpdateTag return ClientboundBlockEntityDataPacket.create(this); } // Can override IForgeBlockEntity#onDataPacket. By default, this will defer to the #load. The static constructors ClientboundBlockEntityDataPacket#create takes: The BlockEntity . An optional function to get the CompoundTag from the BlockEntity . By default, this uses BlockEntity#getUpdateTag . Now, to send the packet, an update notification must be given on the server. Level#sendBlockUpdated(BlockPos pos, BlockState oldState, BlockState newState, int flags) The pos should be your BlockEntity \u2018s position. For oldState and newState , you can pass the current BlockState at that position. flags is a bitmask that should contain 2 , which will sync the changes to the client. See Block for more info as well as the rest of the flags. The flag 2 is equivalent to Block#UPDATE_CLIENTS .","title":"Synchronizing on Block Update"},{"location":"blockentities/#synchronizing-using-a-custom-network-message","text":"This way of synchronizing is probably the most complicated but is usually the most optimized, as you can make sure that only the data you need to be synchronized is actually synchronized. You should first check out the Networking section and especially SimpleImpl before attempting this. Once you\u2019ve created your custom network message, you can send it to all users that have the BlockEntity loaded with SimpleChannel#send(PacketDistributor$PacketTarget, MSG) . Warning It is important that you do safety checks, the BlockEntity might already be destroyed/replaced when the message arrives at the player! You should also check if the chunk is loaded ( Level#hasChunkAt(BlockPos) ).","title":"Synchronizing Using a Custom Network Message"},{"location":"blockentities/ber/","text":"BlockEntityRenderer A BlockEntityRenderer or BER is used to render blocks in a way that cannot be represented with a static baked model (JSON, OBJ, B3D, others). A block entity renderer requires the block to have a BlockEntity . Creating a BER To create a BER, create a class that inherits from BlockEntityRenderer . It takes a generic argument specifying the block\u2019s BlockEntity class. The generic argument is used in the BER\u2019s render method. Only one BER exists for a given BlockEntityType . Therefore, values that are specific to a single instance in the level should be stored in the block entity being passed to the renderer rather than in the BER itself. For example, an integer that increments every frame, if stored in the BER, will increment every frame for every block entity of this type in the level. render This method is called every frame in order to render the block entity. Parameters blockEntity : This is the instance of the block entity being rendered. partialTicks : The amount of time, in fractions of a tick, that has passed since the last full tick. poseStack : A stack holding four-dimensional matrix entries offset to the current position of the block entity. bufferSource : A rendering buffer able to access a vertex consumer. combinedLight : An integer of the current light value on the block entity. combinedOverlay : An integer set to the current overlay of the block entity, usually OverlayTexture#NO_OVERLAY or 655,360. Registering a BER In order to register a BER, you must subscribe to the EntityRenderersEvent$RegisterRenderers event on the mod event bus and call #registerBlockEntityRenderer .","title":"BlockEntityRenderer"},{"location":"blockentities/ber/#blockentityrenderer","text":"A BlockEntityRenderer or BER is used to render blocks in a way that cannot be represented with a static baked model (JSON, OBJ, B3D, others). A block entity renderer requires the block to have a BlockEntity .","title":"BlockEntityRenderer"},{"location":"blockentities/ber/#creating-a-ber","text":"To create a BER, create a class that inherits from BlockEntityRenderer . It takes a generic argument specifying the block\u2019s BlockEntity class. The generic argument is used in the BER\u2019s render method. Only one BER exists for a given BlockEntityType . Therefore, values that are specific to a single instance in the level should be stored in the block entity being passed to the renderer rather than in the BER itself. For example, an integer that increments every frame, if stored in the BER, will increment every frame for every block entity of this type in the level.","title":"Creating a BER"},{"location":"blockentities/ber/#render","text":"This method is called every frame in order to render the block entity.","title":"render"},{"location":"blockentities/ber/#parameters","text":"blockEntity : This is the instance of the block entity being rendered. partialTicks : The amount of time, in fractions of a tick, that has passed since the last full tick. poseStack : A stack holding four-dimensional matrix entries offset to the current position of the block entity. bufferSource : A rendering buffer able to access a vertex consumer. combinedLight : An integer of the current light value on the block entity. combinedOverlay : An integer set to the current overlay of the block entity, usually OverlayTexture#NO_OVERLAY or 655,360.","title":"Parameters"},{"location":"blockentities/ber/#registering-a-ber","text":"In order to register a BER, you must subscribe to the EntityRenderersEvent$RegisterRenderers event on the mod event bus and call #registerBlockEntityRenderer .","title":"Registering a BER"},{"location":"blocks/","text":"Blocks Blocks are, obviously, essential to the Minecraft world. They make up all of the terrain, structures, and machines. Chances are if you are interested in making a mod, then you will want to add some blocks. This page will guide you through the creation of blocks, and some of the things you can do with them. Creating a Block Basic Blocks For simple blocks, which need no special functionality (think cobblestone, wooden planks, etc.), a custom class is not necessary. You can create a block by instantiating the Block class with a BlockBehaviour$Properties object. This BlockBehaviour$Properties object can be made using BlockBehaviour$Properties#of , and it can be customized by calling its methods. For instance: strength - The hardness controls the time it takes to break the block. It is an arbitrary value. For reference, stone has a hardness of 1.5, and dirt 0.5. If the block should be unbreakable a hardness of -1.0 should be used, see the definition of Blocks#BEDROCK as an example. The resistance controls the explosion resistance of the block. For reference, stone has a resistance of 6.0, and dirt 0.5. sound - Controls the sound the block makes when it is punched, broken, or placed. Requires a SoundType argument, see the sounds page for more details. lightLevel - Controls the light emission of the block. Takes a function with a BlockState parameter that returns a value from zero to fifteen. friction - Controls how slippery the block is. For reference, ice has a slipperiness of 0.98. All these methods are chainable which means you can call them in series. See the Blocks class for examples of this. Note Blocks have no setter for their CreativeModeTab . This has been moved to the BlockItem and is now its responsibility. Furthermore, there is no setter for translation key as it is now generated from the registry name. Advanced Blocks Of course, the above only allows for extremely basic blocks. If you want to add functionality, like player interaction, a custom class is required. However, the Block class has many methods and unfortunately not every single one can be documented here. See the rest of the pages in this section for things you can do with blocks. Registering a Block Blocks must be registered to function. Important A block in the level and a \u201cblock\u201d in an inventory are very different things. A block in the level is represented by an BlockState , and its behavior defined by an instance of Block . Meanwhile, an item in an inventory is an ItemStack , controlled by an Item . As a bridge between the different worlds of Block and Item , there exists the class BlockItem . BlockItem is a subclass of Item that has a field block that holds a reference to the Block it represents. BlockItem defines some of the behavior of a \u201cblock\u201d as an item, like how a right click places the block. It\u2019s possible to have a Block without an BlockItem . (E.g. minecraft:water exists a block, but not an item. It is therefore impossible to hold it in an inventory as one.) When a block is registered, only a block is registered. The block does not automatically have an BlockItem . To create a basic BlockItem for a block, one should set the registry name of the BlockItem to that of its Block . Custom subclasses of BlockItem may be used as well. Once an BlockItem has been registered for a block, Block#asItem can be used to retrieve it. Block#asItem will return Items#AIR if there is no BlockItem for the Block , so if you are not certain that there is an BlockItem for the Block you are using, check for if Block#asItem returns Items#AIR . Optionally Registering Blocks In the past there have been several mods that have allowed users to disable blocks/items in a configuration file. However, you shouldn\u2019t do this. There is no limit on the amount of blocks that can be register, so register all blocks in your mod! If you want a block to be disabled through a configuration file, you should disable the crafting recipe. Further Reading For information about block properties, such as those used for vanilla blocks like fences, walls, and many more, see the section on blockstates .","title":"Introduction"},{"location":"blocks/#blocks","text":"Blocks are, obviously, essential to the Minecraft world. They make up all of the terrain, structures, and machines. Chances are if you are interested in making a mod, then you will want to add some blocks. This page will guide you through the creation of blocks, and some of the things you can do with them.","title":"Blocks"},{"location":"blocks/#creating-a-block","text":"","title":"Creating a Block"},{"location":"blocks/#basic-blocks","text":"For simple blocks, which need no special functionality (think cobblestone, wooden planks, etc.), a custom class is not necessary. You can create a block by instantiating the Block class with a BlockBehaviour$Properties object. This BlockBehaviour$Properties object can be made using BlockBehaviour$Properties#of , and it can be customized by calling its methods. For instance: strength - The hardness controls the time it takes to break the block. It is an arbitrary value. For reference, stone has a hardness of 1.5, and dirt 0.5. If the block should be unbreakable a hardness of -1.0 should be used, see the definition of Blocks#BEDROCK as an example. The resistance controls the explosion resistance of the block. For reference, stone has a resistance of 6.0, and dirt 0.5. sound - Controls the sound the block makes when it is punched, broken, or placed. Requires a SoundType argument, see the sounds page for more details. lightLevel - Controls the light emission of the block. Takes a function with a BlockState parameter that returns a value from zero to fifteen. friction - Controls how slippery the block is. For reference, ice has a slipperiness of 0.98. All these methods are chainable which means you can call them in series. See the Blocks class for examples of this. Note Blocks have no setter for their CreativeModeTab . This has been moved to the BlockItem and is now its responsibility. Furthermore, there is no setter for translation key as it is now generated from the registry name.","title":"Basic Blocks"},{"location":"blocks/#advanced-blocks","text":"Of course, the above only allows for extremely basic blocks. If you want to add functionality, like player interaction, a custom class is required. However, the Block class has many methods and unfortunately not every single one can be documented here. See the rest of the pages in this section for things you can do with blocks.","title":"Advanced Blocks"},{"location":"blocks/#registering-a-block","text":"Blocks must be registered to function. Important A block in the level and a \u201cblock\u201d in an inventory are very different things. A block in the level is represented by an BlockState , and its behavior defined by an instance of Block . Meanwhile, an item in an inventory is an ItemStack , controlled by an Item . As a bridge between the different worlds of Block and Item , there exists the class BlockItem . BlockItem is a subclass of Item that has a field block that holds a reference to the Block it represents. BlockItem defines some of the behavior of a \u201cblock\u201d as an item, like how a right click places the block. It\u2019s possible to have a Block without an BlockItem . (E.g. minecraft:water exists a block, but not an item. It is therefore impossible to hold it in an inventory as one.) When a block is registered, only a block is registered. The block does not automatically have an BlockItem . To create a basic BlockItem for a block, one should set the registry name of the BlockItem to that of its Block . Custom subclasses of BlockItem may be used as well. Once an BlockItem has been registered for a block, Block#asItem can be used to retrieve it. Block#asItem will return Items#AIR if there is no BlockItem for the Block , so if you are not certain that there is an BlockItem for the Block you are using, check for if Block#asItem returns Items#AIR .","title":"Registering a Block"},{"location":"blocks/#optionally-registering-blocks","text":"In the past there have been several mods that have allowed users to disable blocks/items in a configuration file. However, you shouldn\u2019t do this. There is no limit on the amount of blocks that can be register, so register all blocks in your mod! If you want a block to be disabled through a configuration file, you should disable the crafting recipe.","title":"Optionally Registering Blocks"},{"location":"blocks/#further-reading","text":"For information about block properties, such as those used for vanilla blocks like fences, walls, and many more, see the section on blockstates .","title":"Further Reading"},{"location":"blocks/states/","text":"Block States Legacy Behavior In Minecraft 1.7 and previous versions, blocks which need to store placement or state data that did not have BlockEntities used metadata . Metadata was an extra number stored with the block, allowing different rotations, facings, or even completely separate behaviors within a block. However, the metadata system was confusing and limited, since it was stored as only a number alongside the block ID, and had no meaning except what was commented in the code. For example, to implement a block that can face a direction and be on either the upper or lower half of a block space (such as a stair): switch (meta) { case 0: { ... } // south and on the lower half of the block case 1: { ... } // south on the upper side of the block case 2: { ... } // north and on the lower half of the block case 3: { ... } // north and on the upper half of the block // ... etc. ... } Because the numbers carry no meaning by themselves, no one could know what they represent unless they had access to the source code and comments. Introduction of States In Minecraft 1.8 and above, the metadata system, along with the block ID system, was deprecated and eventually replaced with the block state system . The block state system abstracts out the details of the block\u2019s properties from the other behaviors of the block. Each property of a block is described by an instance of Property<?> . Examples of block properties include instruments ( EnumProperty<NoteBlockInstrument> ), facing ( DirectionProperty ), poweredness ( Property<Boolean> ), etc. Each property has the value of the type T parametrized by Property<T> . A unique pair can be constructed from the Block and a map of the Property<?> to their associated values. This unique pair is called a BlockState . The previous system of meaningless metadata values were replaced by a system of block properties, which are easier to interpret and deal with. Previously, a stone button which is facing east and is powered or held down is represented by \u201c minecraft:stone_button with metadata 9 . Now, this is represented by \u201c minecraft:stone_button[facing=east,powered=true] \u201d. Proper Usage of Block States The BlockState system is a flexible and powerful system, but it also has limitations. BlockState s are immutable, and all combinations of their properties are generated on startup of the game. This means that having a BlockState with many properties and possible values will slow down the loading of the game, and befuddle anyone trying to make sense of your block logic. Not all blocks and situations require the usage of BlockState ; only the most basic properties of a block should be put into a BlockState , and any other situation is better off with having a BlockEntity or being a separate Block . Always consider if you actually need to use blockstates for your purposes. Note A good rule of thumb is: if it has a different name, it should be a separate block . An example is making chair blocks: the direction of the chair should be a property , while the different types of wood should be separated into different blocks. An \u201cOak Chair\u201d facing east ( oak_chair[facing=east] ) is different from a \u201cSpruce Chair\u201d facing west ( spruce_chair[facing=west] ). Implementing Block States In your Block class, create or reference static final Property<?> objects for every property that your Block has. You are free to make your own Property<?> implementations, but the means to do that are not covered in this article. The vanilla code provides several convenience implementations: IntegerProperty Implements Property<Integer> . Defines a property that holds an integer value. Created by calling IntegerProperty#create(String propertyName, int minimum, int maximum) . BooleanProperty Implements Property<Boolean> . Defines a property that holds a true or false value. Created by calling BooleanProperty#create(String propertyName) . EnumProperty<E extends Enum<E>> Implements Property<E> . Defines a property that can take on the values of an Enum class. Created by calling EnumProperty#create(String propertyName, Class<E> enumClass) . It is also possible to use only a subset of the Enum values (e.g. 4 out of 16 DyeColor s). See the overloads of EnumProperty#create . DirectionProperty This is a convenience implementation of EnumProperty<Direction> Several convenience predicates are also provided. For example, to get a property that represents the cardinal directions, call DirectionProperty.create(\"<name>\", Direction.Plane.HORIZONTAL) ; to get the X directions, DirectionProperty.create(\"<name>\", Direction.Axis.X) . The class BlockStateProperties contains shared vanilla properties which should be used or referenced whenever possible, in place of creating your own properties. When you have your desired Property<> objects, override Block#createBlockStateDefinition(StateDefinition$Builder) in your Block class. In that method, call StateDefinition$Builder#add(...); with the parameters as every Property<?> you wish the block to have. Every block will also have a \u201cdefault\u201d state that is automatically chosen for you. You can change this \u201cdefault\u201d state by calling the Block#registerDefaultState(BlockState) method from your constructor. When your block is placed it will become this \u201cdefault\u201d state. An example from DoorBlock : this.registerDefaultState( this.stateDefinition.any() .setValue(FACING, Direction.NORTH) .setValue(OPEN, false) .setValue(HINGE, DoorHingeSide.LEFT) .setValue(POWERED, false) .setValue(HALF, DoubleBlockHalf.LOWER) ); If you wish to change what BlockState is used when placing your block, you can overwrite Block#getStateForPlacement(BlockPlaceContext) . This can be used to, for example, set the direction of your block depending on where the player is standing when they place it. Because BlockState s are immutable, and all combinations of their properties are generated on startup of the game, calling BlockState#setValue(Property<T>, T) will simply go to the Block \u2018s StateHolder and request the BlockState with the set of values you want. Because all possible BlockState s are generated at startup, you are free and encouraged to use the reference equality operator ( == ) to check if two BlockState s are equal. Using BlockState \u2018s You can get the value of a property by calling BlockState#getValue(Property<?>) , passing it the property you want to get the value of. If you want to get a BlockState with a different set of values, simply call BlockState#setValue(Property<T>, T) with the property and its value. You can get and place BlockState \u2018s in the level using Level#setBlockAndUpdate(BlockPos, BlockState) and Level#getBlockState(BlockState) . If you are placing a Block , call Block#defaultBlockState() to get the \u201cdefault\u201d state, and use subsequent calls to BlockState#setValue(Property<T>, T) as stated above to achieve the desired state.","title":"Block States"},{"location":"blocks/states/#block-states","text":"","title":"Block States"},{"location":"blocks/states/#legacy-behavior","text":"In Minecraft 1.7 and previous versions, blocks which need to store placement or state data that did not have BlockEntities used metadata . Metadata was an extra number stored with the block, allowing different rotations, facings, or even completely separate behaviors within a block. However, the metadata system was confusing and limited, since it was stored as only a number alongside the block ID, and had no meaning except what was commented in the code. For example, to implement a block that can face a direction and be on either the upper or lower half of a block space (such as a stair): switch (meta) { case 0: { ... } // south and on the lower half of the block case 1: { ... } // south on the upper side of the block case 2: { ... } // north and on the lower half of the block case 3: { ... } // north and on the upper half of the block // ... etc. ... } Because the numbers carry no meaning by themselves, no one could know what they represent unless they had access to the source code and comments.","title":"Legacy Behavior"},{"location":"blocks/states/#introduction-of-states","text":"In Minecraft 1.8 and above, the metadata system, along with the block ID system, was deprecated and eventually replaced with the block state system . The block state system abstracts out the details of the block\u2019s properties from the other behaviors of the block. Each property of a block is described by an instance of Property<?> . Examples of block properties include instruments ( EnumProperty<NoteBlockInstrument> ), facing ( DirectionProperty ), poweredness ( Property<Boolean> ), etc. Each property has the value of the type T parametrized by Property<T> . A unique pair can be constructed from the Block and a map of the Property<?> to their associated values. This unique pair is called a BlockState . The previous system of meaningless metadata values were replaced by a system of block properties, which are easier to interpret and deal with. Previously, a stone button which is facing east and is powered or held down is represented by \u201c minecraft:stone_button with metadata 9 . Now, this is represented by \u201c minecraft:stone_button[facing=east,powered=true] \u201d.","title":"Introduction of States"},{"location":"blocks/states/#proper-usage-of-block-states","text":"The BlockState system is a flexible and powerful system, but it also has limitations. BlockState s are immutable, and all combinations of their properties are generated on startup of the game. This means that having a BlockState with many properties and possible values will slow down the loading of the game, and befuddle anyone trying to make sense of your block logic. Not all blocks and situations require the usage of BlockState ; only the most basic properties of a block should be put into a BlockState , and any other situation is better off with having a BlockEntity or being a separate Block . Always consider if you actually need to use blockstates for your purposes. Note A good rule of thumb is: if it has a different name, it should be a separate block . An example is making chair blocks: the direction of the chair should be a property , while the different types of wood should be separated into different blocks. An \u201cOak Chair\u201d facing east ( oak_chair[facing=east] ) is different from a \u201cSpruce Chair\u201d facing west ( spruce_chair[facing=west] ).","title":"Proper Usage of Block States"},{"location":"blocks/states/#implementing-block-states","text":"In your Block class, create or reference static final Property<?> objects for every property that your Block has. You are free to make your own Property<?> implementations, but the means to do that are not covered in this article. The vanilla code provides several convenience implementations: IntegerProperty Implements Property<Integer> . Defines a property that holds an integer value. Created by calling IntegerProperty#create(String propertyName, int minimum, int maximum) . BooleanProperty Implements Property<Boolean> . Defines a property that holds a true or false value. Created by calling BooleanProperty#create(String propertyName) . EnumProperty<E extends Enum<E>> Implements Property<E> . Defines a property that can take on the values of an Enum class. Created by calling EnumProperty#create(String propertyName, Class<E> enumClass) . It is also possible to use only a subset of the Enum values (e.g. 4 out of 16 DyeColor s). See the overloads of EnumProperty#create . DirectionProperty This is a convenience implementation of EnumProperty<Direction> Several convenience predicates are also provided. For example, to get a property that represents the cardinal directions, call DirectionProperty.create(\"<name>\", Direction.Plane.HORIZONTAL) ; to get the X directions, DirectionProperty.create(\"<name>\", Direction.Axis.X) . The class BlockStateProperties contains shared vanilla properties which should be used or referenced whenever possible, in place of creating your own properties. When you have your desired Property<> objects, override Block#createBlockStateDefinition(StateDefinition$Builder) in your Block class. In that method, call StateDefinition$Builder#add(...); with the parameters as every Property<?> you wish the block to have. Every block will also have a \u201cdefault\u201d state that is automatically chosen for you. You can change this \u201cdefault\u201d state by calling the Block#registerDefaultState(BlockState) method from your constructor. When your block is placed it will become this \u201cdefault\u201d state. An example from DoorBlock : this.registerDefaultState( this.stateDefinition.any() .setValue(FACING, Direction.NORTH) .setValue(OPEN, false) .setValue(HINGE, DoorHingeSide.LEFT) .setValue(POWERED, false) .setValue(HALF, DoubleBlockHalf.LOWER) ); If you wish to change what BlockState is used when placing your block, you can overwrite Block#getStateForPlacement(BlockPlaceContext) . This can be used to, for example, set the direction of your block depending on where the player is standing when they place it. Because BlockState s are immutable, and all combinations of their properties are generated on startup of the game, calling BlockState#setValue(Property<T>, T) will simply go to the Block \u2018s StateHolder and request the BlockState with the set of values you want. Because all possible BlockState s are generated at startup, you are free and encouraged to use the reference equality operator ( == ) to check if two BlockState s are equal.","title":"Implementing Block States"},{"location":"blocks/states/#using-blockstates","text":"You can get the value of a property by calling BlockState#getValue(Property<?>) , passing it the property you want to get the value of. If you want to get a BlockState with a different set of values, simply call BlockState#setValue(Property<T>, T) with the property and its value. You can get and place BlockState \u2018s in the level using Level#setBlockAndUpdate(BlockPos, BlockState) and Level#getBlockState(BlockState) . If you are placing a Block , call Block#defaultBlockState() to get the \u201cdefault\u201d state, and use subsequent calls to BlockState#setValue(Property<T>, T) as stated above to achieve the desired state.","title":"Using BlockState's"},{"location":"concepts/events/","text":"Events Forge uses an event bus that allows mods to intercept events from various Vanilla and mod behaviors. Example: An event can be used to perform an action when a Vanilla stick is right clicked. The main event bus used for most events is located at MinecraftForge#EVENT_BUS . There is another event bus for mod specific events located at FMLJavaModLoadingContext#getModEventBus that you should only use in specific cases. More information about this bus can be found below. Every event is fired on one of these busses: most events are fired on the main forge event bus, but some are fired on the mod specific event buses. An event handler is some method that has been registered to an event bus. Creating an Event Handler Event handlers methods have a single parameter and do not return a result. The method could be static or instance depending on implementation. Event handlers can be directly registered using IEventBus#addListener for or IEventBus#addGenericListener for generic events (as denoted by subclassing GenericEvent<T> ). Either listener adder takes in a consumer representing the method reference. Generic event handlers need to specify the class of the generic as well. Event handlers must be registered within the constructor of the main mod class. // In the main mod class ExampleMod // This event is on the forge bus private void forgeEventHandler(AddReloadListenerEvent event) { // Do things here } // This event is on the mod bus private static void modEventHandler(RegistryEvent.Register<RecipeSerializer<?>> event) { // ... } // In the mod constructor forgeEventBus.addListener(this::forgeEventHandler); modEventBus.addGenericListener(RecipeSerializer.class, ExampleMod::modEventHandler); Instance Annotated Event Handlers This event handler listens for the EntityItemPickupEvent , which is, as the name states, posted to the event bus whenever an Entity picks up an item. public class MyForgeEventHandler { @SubscribeEvent public void pickupItem(EntityItemPickupEvent event) { System.out.println(\"Item picked up!\"); } } To register this event handler, use MinecraftForge.EVENT_BUS.register(...) and pass it an instance of the class the event handler is within. If you want to register this handler to the mod specific event bus, you should use FMLJavaModLoadingContext.get().getModEventBus().register(...) instead. Static Annotated Event Handlers An event handler may also be static. The handling method is still annotated with @SubscribeEvent . The only difference from an instance handler is that it is also marked static . In order to register a static event handler, an instance of the class won\u2019t do. The Class itself has to be passed in. An example: public class MyStaticForgeEventHandler { @SubscribeEvent public static void arrowNocked(ArrowNockEvent event) { System.out.println(\"Arrow nocked!\"); } } which must be registered like this: MinecraftForge.EVENT_BUS.register(MyStaticForgeEventHandler.class) . Automatically Registering Static Event Handlers A class may be annotated with the @Mod$EventBusSubscriber annotation. Such a class is automatically registered to MinecraftForge#EVENT_BUS when the @Mod class itself is constructed. This is essentially equivalent to adding MinecraftForge.EVENT_BUS.register(AnnotatedClass.class); at the end of the @Mod class\u2019s constructor. You can pass the bus you want to listen to the @Mod$EventBusSubscriber annotation. It is recommended you also specify the mod id, since the annotation process may not be able to figure it out, and the bus you are registering to, since it serves as a reminder to make sure you are on the correct one. You can also specify the Dist s or physical sides to load this event subscriber on. This can be used to not load client specific event subscribers on the dedicated server. An example for a static event listener listening to RenderLevelLastEvent which will only be called on the client: @Mod.EventBusSubscriber(modid = \"mymod\", bus = Bus.FORGE, value = Dist.CLIENT) public class MyStaticClientOnlyEventHandler { @SubscribeEvent public static void drawLast(RenderLevelLastEvent event) { System.out.println(\"Drawing!\"); } } Note This does not register an instance of the class; it registers the class itself (i.e. the event handling methods must be static). Canceling If an event can be canceled, it will be marked with the @Cancelable annotation, and the method Event#isCancelable() will return true . The cancel state of a cancelable event may be modified by calling Event#setCanceled(boolean canceled) , wherein passing the boolean value true is interpreted as canceling the event, and passing the boolean value false is interpreted as \u201cun-canceling\u201d the event. However, if the event cannot be canceled (as defined by Event#isCancelable() ), an UnsupportedOperationException will be thrown regardless of the passed boolean value, since the cancel state of a non-cancelable event event is considered immutable. Important Not all events can be canceled! Attempting to cancel an event that is not cancelable will result in an unchecked UnsupportedOperationException being thrown, which is expected to result in the game crashing! Always check that an event can be canceled using Event#isCancelable() before attempting to cancel it! Results Some events have an Event$Result . A result can be one of three things: DENY which stops the event, DEFAULT which uses the Vanilla behavior, and ALLOW which forces the action to take place, regardless if it would have originally. The result of an event can be set by calling #setResult with an Event$Result on the event. Not all events have results; an event with a result will be annotated with @HasResult . Important Different events may use results in different ways, refer to the event\u2019s JavaDoc before using the result. Priority Event handler methods (marked with @SubscribeEvent ) have a priority. You can set the priority of an event handler method by setting the priority value of the annotation. The priority can be any value of the EventPriority enum ( HIGHEST , HIGH , NORMAL , LOW , and LOWEST ). Event handlers with priority HIGHEST are executed first and from there in descending order until LOWEST events which are executed last. Sub Events Many events have different variations of themselves. These can be different but all based around one common factor (e.g. PlayerEvent ) or can be an event that has multiple phases (e.g. PotionBrewEvent ). Take note that if you listen to the parent event class, you will receive calls to your method for all subclasses. Mod Event Bus The mod event bus is primarily used for listening to lifecycle events in which mods should initialize. Each event on the mod bus is required to implement IModBusEvent . Many of these events are also ran in parallel so mods can be initialized at the same time. This does mean you can\u2019t directly execute code from other mods in these events. Use the InterModComms system for that. These are the four most commonly used lifecycle events that are called during mod initialization on the mod event bus: FMLCommonSetupEvent FMLClientSetupEvent & FMLDedicatedServerSetupEvent InterModEnqueueEvent InterModProcessEvent Note The FMLClientSetupEvent and FMLDedicatedServerSetupEvent are only called on their respective distribution. These four lifecycle events are all ran in parallel since they all are a subclass of ParallelDispatchEvent . If you want to run run code on the main thread during any ParallelDispatchEvent , you can use the #enqueueWork to do so. Next to the lifecycle events, there are a few miscellaneous events that are fired on the mod event bus where you can register, set up, or initialize various things. Most of these events are not ran in parallel in contrast to the lifecycle events. A few examples: ColorHandlerEvent ModelBakeEvent TextureStitchEvent RegistryEvent A good rule of thumb: events are fired on the mod event bus when they should be handled during initialization of a mod.","title":"Events"},{"location":"concepts/events/#events","text":"Forge uses an event bus that allows mods to intercept events from various Vanilla and mod behaviors. Example: An event can be used to perform an action when a Vanilla stick is right clicked. The main event bus used for most events is located at MinecraftForge#EVENT_BUS . There is another event bus for mod specific events located at FMLJavaModLoadingContext#getModEventBus that you should only use in specific cases. More information about this bus can be found below. Every event is fired on one of these busses: most events are fired on the main forge event bus, but some are fired on the mod specific event buses. An event handler is some method that has been registered to an event bus.","title":"Events"},{"location":"concepts/events/#creating-an-event-handler","text":"Event handlers methods have a single parameter and do not return a result. The method could be static or instance depending on implementation. Event handlers can be directly registered using IEventBus#addListener for or IEventBus#addGenericListener for generic events (as denoted by subclassing GenericEvent<T> ). Either listener adder takes in a consumer representing the method reference. Generic event handlers need to specify the class of the generic as well. Event handlers must be registered within the constructor of the main mod class. // In the main mod class ExampleMod // This event is on the forge bus private void forgeEventHandler(AddReloadListenerEvent event) { // Do things here } // This event is on the mod bus private static void modEventHandler(RegistryEvent.Register<RecipeSerializer<?>> event) { // ... } // In the mod constructor forgeEventBus.addListener(this::forgeEventHandler); modEventBus.addGenericListener(RecipeSerializer.class, ExampleMod::modEventHandler);","title":"Creating an Event Handler"},{"location":"concepts/events/#instance-annotated-event-handlers","text":"This event handler listens for the EntityItemPickupEvent , which is, as the name states, posted to the event bus whenever an Entity picks up an item. public class MyForgeEventHandler { @SubscribeEvent public void pickupItem(EntityItemPickupEvent event) { System.out.println(\"Item picked up!\"); } } To register this event handler, use MinecraftForge.EVENT_BUS.register(...) and pass it an instance of the class the event handler is within. If you want to register this handler to the mod specific event bus, you should use FMLJavaModLoadingContext.get().getModEventBus().register(...) instead.","title":"Instance Annotated Event Handlers"},{"location":"concepts/events/#static-annotated-event-handlers","text":"An event handler may also be static. The handling method is still annotated with @SubscribeEvent . The only difference from an instance handler is that it is also marked static . In order to register a static event handler, an instance of the class won\u2019t do. The Class itself has to be passed in. An example: public class MyStaticForgeEventHandler { @SubscribeEvent public static void arrowNocked(ArrowNockEvent event) { System.out.println(\"Arrow nocked!\"); } } which must be registered like this: MinecraftForge.EVENT_BUS.register(MyStaticForgeEventHandler.class) .","title":"Static Annotated Event Handlers"},{"location":"concepts/events/#automatically-registering-static-event-handlers","text":"A class may be annotated with the @Mod$EventBusSubscriber annotation. Such a class is automatically registered to MinecraftForge#EVENT_BUS when the @Mod class itself is constructed. This is essentially equivalent to adding MinecraftForge.EVENT_BUS.register(AnnotatedClass.class); at the end of the @Mod class\u2019s constructor. You can pass the bus you want to listen to the @Mod$EventBusSubscriber annotation. It is recommended you also specify the mod id, since the annotation process may not be able to figure it out, and the bus you are registering to, since it serves as a reminder to make sure you are on the correct one. You can also specify the Dist s or physical sides to load this event subscriber on. This can be used to not load client specific event subscribers on the dedicated server. An example for a static event listener listening to RenderLevelLastEvent which will only be called on the client: @Mod.EventBusSubscriber(modid = \"mymod\", bus = Bus.FORGE, value = Dist.CLIENT) public class MyStaticClientOnlyEventHandler { @SubscribeEvent public static void drawLast(RenderLevelLastEvent event) { System.out.println(\"Drawing!\"); } } Note This does not register an instance of the class; it registers the class itself (i.e. the event handling methods must be static).","title":"Automatically Registering Static Event Handlers"},{"location":"concepts/events/#canceling","text":"If an event can be canceled, it will be marked with the @Cancelable annotation, and the method Event#isCancelable() will return true . The cancel state of a cancelable event may be modified by calling Event#setCanceled(boolean canceled) , wherein passing the boolean value true is interpreted as canceling the event, and passing the boolean value false is interpreted as \u201cun-canceling\u201d the event. However, if the event cannot be canceled (as defined by Event#isCancelable() ), an UnsupportedOperationException will be thrown regardless of the passed boolean value, since the cancel state of a non-cancelable event event is considered immutable. Important Not all events can be canceled! Attempting to cancel an event that is not cancelable will result in an unchecked UnsupportedOperationException being thrown, which is expected to result in the game crashing! Always check that an event can be canceled using Event#isCancelable() before attempting to cancel it!","title":"Canceling"},{"location":"concepts/events/#results","text":"Some events have an Event$Result . A result can be one of three things: DENY which stops the event, DEFAULT which uses the Vanilla behavior, and ALLOW which forces the action to take place, regardless if it would have originally. The result of an event can be set by calling #setResult with an Event$Result on the event. Not all events have results; an event with a result will be annotated with @HasResult . Important Different events may use results in different ways, refer to the event\u2019s JavaDoc before using the result.","title":"Results"},{"location":"concepts/events/#priority","text":"Event handler methods (marked with @SubscribeEvent ) have a priority. You can set the priority of an event handler method by setting the priority value of the annotation. The priority can be any value of the EventPriority enum ( HIGHEST , HIGH , NORMAL , LOW , and LOWEST ). Event handlers with priority HIGHEST are executed first and from there in descending order until LOWEST events which are executed last.","title":"Priority"},{"location":"concepts/events/#sub-events","text":"Many events have different variations of themselves. These can be different but all based around one common factor (e.g. PlayerEvent ) or can be an event that has multiple phases (e.g. PotionBrewEvent ). Take note that if you listen to the parent event class, you will receive calls to your method for all subclasses.","title":"Sub Events"},{"location":"concepts/events/#mod-event-bus","text":"The mod event bus is primarily used for listening to lifecycle events in which mods should initialize. Each event on the mod bus is required to implement IModBusEvent . Many of these events are also ran in parallel so mods can be initialized at the same time. This does mean you can\u2019t directly execute code from other mods in these events. Use the InterModComms system for that. These are the four most commonly used lifecycle events that are called during mod initialization on the mod event bus: FMLCommonSetupEvent FMLClientSetupEvent & FMLDedicatedServerSetupEvent InterModEnqueueEvent InterModProcessEvent Note The FMLClientSetupEvent and FMLDedicatedServerSetupEvent are only called on their respective distribution. These four lifecycle events are all ran in parallel since they all are a subclass of ParallelDispatchEvent . If you want to run run code on the main thread during any ParallelDispatchEvent , you can use the #enqueueWork to do so. Next to the lifecycle events, there are a few miscellaneous events that are fired on the mod event bus where you can register, set up, or initialize various things. Most of these events are not ran in parallel in contrast to the lifecycle events. A few examples: ColorHandlerEvent ModelBakeEvent TextureStitchEvent RegistryEvent A good rule of thumb: events are fired on the mod event bus when they should be handled during initialization of a mod.","title":"Mod Event Bus"},{"location":"concepts/internationalization/","text":"Internationalization and Localization Internationalization, i18n for short, is a way of designing code so that it requires no changes to be adapted for various languages. Localization is the process of adapting displayed text to the user\u2019s language. I18n is implemented using translation keys . A translation key is a string that identifies a piece of displayable text in no specific language. For example, block.minecraft.dirt is the translation key referring to the name of the Dirt block. This way, displayable text may be referenced with no concern for a specific language. The code requires no changes to be adapted in a new language. Localization will happen in the game\u2019s locale. In a Minecraft client the locale is specified by the language settings. On a dedicated server, the only supported locale is en_us . A list of available locales can be found on the Minecraft Wiki . Language files Language files are located by assets/[namespace]/lang/[locale].json (e.g. all US English translations provided by examplemod would be within assets/examplemod/lang/en_us.json ). The file format is simply a json map from translation keys to values. The file must be encoded in UTF-8. Old .lang files can be converted to json using a converter . { \"item.examplemod.example_item\": \"Example Item Name\", \"block.examplemod.example_block\": \"Example Block Name\", \"commands.examplemod.examplecommand.error\": \"Example Command Errored!\" } Usage with Blocks and Items Block, Item and a few other Minecraft classes have built-in translation keys used to display their names. These translation keys are specified by overriding #getDescriptionId . Item also has #getDescriptionId(ItemStack) which can be overridden to provide different translation keys depending on ItemStack NBT. By default, #getDescriptionId will return block. or item. prepended to the registry name of the block or item, with the colon replaced by a dot. BlockItem s override this method to take their corresponding Block \u2018s translation key by default. For example, an item with ID examplemod:example_item effectively requires the following line in a language file: { \"item.examplemod.example_item\": \"Example Item Name\" } Note The only purpose of a translation key is internationalization. Do not use them for logic. Use registry names instead. Localization methods Warning A common issue is having the server localize for clients. The server can only localize in its own locale, which does not necessarily match the locale of connected clients. To respect the language settings of clients, the server should have clients localize text in their own locale using TranslatableComponent or other methods preserving the language neutral translation keys. net.minecraft.client.resources.language.I18n (client only) This I18n class can only be found on a Minecraft client! It is intended to be used by code that only runs on the client. Attempts to use this on a server will throw exceptions and crash. get(String, Object...) localizes in the client\u2019s locale with formatting. The first parameter is a translation key, and the rest are formatting arguments for String.format(String, Object...) . TranslatableComponent TranslatableComponent is a Component that is localized and formatted lazily. It is very useful when sending messages to players because it will be automatically localized in their own locale. The first parameter of the TranslatableComponent(String, Object...) constructor is a translation key, and the rest are used for formatting. The only supported format specifiers are %s and %1$s , %2$s , %3$s etc. Formatting arguments may be other Components s that will be inserted into the resulting formatted text with all their attributes preserved. TextComponentHelper createComponentTranslation(CommandSource, String, Object...) creates a localized and formatted BaseComponent depending on a receiver. The localization and formatting is done eagerly if the receiver is a vanilla client. If not, the localization and formatting is done lazily with a TranslatableComponent . This is only useful if the server should allow vanilla clients to connect.","title":"Internationalization"},{"location":"concepts/internationalization/#internationalization-and-localization","text":"Internationalization, i18n for short, is a way of designing code so that it requires no changes to be adapted for various languages. Localization is the process of adapting displayed text to the user\u2019s language. I18n is implemented using translation keys . A translation key is a string that identifies a piece of displayable text in no specific language. For example, block.minecraft.dirt is the translation key referring to the name of the Dirt block. This way, displayable text may be referenced with no concern for a specific language. The code requires no changes to be adapted in a new language. Localization will happen in the game\u2019s locale. In a Minecraft client the locale is specified by the language settings. On a dedicated server, the only supported locale is en_us . A list of available locales can be found on the Minecraft Wiki .","title":"Internationalization and Localization"},{"location":"concepts/internationalization/#language-files","text":"Language files are located by assets/[namespace]/lang/[locale].json (e.g. all US English translations provided by examplemod would be within assets/examplemod/lang/en_us.json ). The file format is simply a json map from translation keys to values. The file must be encoded in UTF-8. Old .lang files can be converted to json using a converter . { \"item.examplemod.example_item\": \"Example Item Name\", \"block.examplemod.example_block\": \"Example Block Name\", \"commands.examplemod.examplecommand.error\": \"Example Command Errored!\" }","title":"Language files"},{"location":"concepts/internationalization/#usage-with-blocks-and-items","text":"Block, Item and a few other Minecraft classes have built-in translation keys used to display their names. These translation keys are specified by overriding #getDescriptionId . Item also has #getDescriptionId(ItemStack) which can be overridden to provide different translation keys depending on ItemStack NBT. By default, #getDescriptionId will return block. or item. prepended to the registry name of the block or item, with the colon replaced by a dot. BlockItem s override this method to take their corresponding Block \u2018s translation key by default. For example, an item with ID examplemod:example_item effectively requires the following line in a language file: { \"item.examplemod.example_item\": \"Example Item Name\" } Note The only purpose of a translation key is internationalization. Do not use them for logic. Use registry names instead.","title":"Usage with Blocks and Items"},{"location":"concepts/internationalization/#localization-methods","text":"Warning A common issue is having the server localize for clients. The server can only localize in its own locale, which does not necessarily match the locale of connected clients. To respect the language settings of clients, the server should have clients localize text in their own locale using TranslatableComponent or other methods preserving the language neutral translation keys.","title":"Localization methods"},{"location":"concepts/internationalization/#netminecraftclientresourceslanguagei18n-client-only","text":"This I18n class can only be found on a Minecraft client! It is intended to be used by code that only runs on the client. Attempts to use this on a server will throw exceptions and crash. get(String, Object...) localizes in the client\u2019s locale with formatting. The first parameter is a translation key, and the rest are formatting arguments for String.format(String, Object...) .","title":"net.minecraft.client.resources.language.I18n (client only)"},{"location":"concepts/internationalization/#translatablecomponent","text":"TranslatableComponent is a Component that is localized and formatted lazily. It is very useful when sending messages to players because it will be automatically localized in their own locale. The first parameter of the TranslatableComponent(String, Object...) constructor is a translation key, and the rest are used for formatting. The only supported format specifiers are %s and %1$s , %2$s , %3$s etc. Formatting arguments may be other Components s that will be inserted into the resulting formatted text with all their attributes preserved.","title":"TranslatableComponent"},{"location":"concepts/internationalization/#textcomponenthelper","text":"createComponentTranslation(CommandSource, String, Object...) creates a localized and formatted BaseComponent depending on a receiver. The localization and formatting is done eagerly if the receiver is a vanilla client. If not, the localization and formatting is done lazily with a TranslatableComponent . This is only useful if the server should allow vanilla clients to connect.","title":"TextComponentHelper"},{"location":"concepts/lifecycle/","text":"Mod Lifecycle During the mod loading process, the various lifecycle events are fired on the mod-specific event bus. Many actions are performed during these events, such as registering objects , preparing for data generation , or communicating with other mods . Event listeners should be registered either using @EventBusSubscriber(bus = Bus.MOD) or in the mod constructor: @Mod.EventBusSubscriber(modid = \"mymod\", bus = Mod.EventBusSubscriber.Bus.MOD) public class MyModEventSubscriber { @SubscribeEvent static void onCommonSetup(FMLCommonSetupEvent event) { ... } } @Mod(\"mymod\") public class MyMod { public MyMod() { FMLModLoadingContext.get().getModEventBus().addListener(this::onCommonSetup); } private void onCommonSetup(FMLCommonSetupEvent event) { ... } } Warning Most of the lifecycle events are fired in parallel: all mods will concurrently receive the same event. Mods must take care to be thread-safe, like when calling other mods\u2019 APIs or accessing vanilla systems. Defer code for later execution via ParallelDispatchEvent#enqueueWork . Registry Events The registry events are fired after the mod instance construction. There are two: the NewRegistryEvent event and the RegistryEvent$Register event. These events are fired synchronously during mod loading. The NewRegistryEvent event allows modders to register their own custom registries, using the RegistryBuilder class. The RegistryEvent$Register<?> event is for registering objects into the registries. A Register event is fired for each registry. Data Generation If the game is setup to run data generators , then the GatherDataEvent will be the last event to fire. This event is for registering mods\u2019 data providers to their associated data generator. This event is also fired synchronously. Common Setup FMLCommonSetupEvent is for actions that are common to both physical client and server, such as registering capabilities . Sided Setup The sided-setup events are fired on their respective physical sides : FMLClientSetupEvent on the physical client, and FMLDedicatedServerSetupEvent for the dedicated server. This is where physical side-specific initialization should occur, such as registering client-side key bindings. InterModComms This is where messages can be sent to mods for cross-mod compatibility. There are two events: InterModEnqueueEvent and InterModProcessEvent . InterModComms is the class responsible for holding messages for mods. The methods are safe to call during the lifecycle events, as it is backed by a ConcurrentMap . During the InterModEnqueueEvent , use InterModComms#sendTo to send messages to different mods. These methods take in the mod id that will be sent the message, the key associated with the message data, and a supplier holding the message data. Additionally, the sender of the message can also be specified, but by default it will be the mod id of the caller. Then during the InterModProcessEvent , use InterModComms#getMessages to get a stream of all received messages. The mod id supplied will almost always be the mod id of the mod the method is called on. Additionally, a predicate can be specified to filter out the message keys. This will return a stream of IMCMessage s which hold the sender of the data, the receiver of the data, the data key, and the supplied data itself. Note There are two other lifecycle events: FMLConstructModEvent , fired directly after mod instance construction but before the RegistryEvent s, and FMLLoadCompleteEvent , fired after the InterModComms events, for when the mod loading process is complete.","title":"Mod Lifecycle"},{"location":"concepts/lifecycle/#mod-lifecycle","text":"During the mod loading process, the various lifecycle events are fired on the mod-specific event bus. Many actions are performed during these events, such as registering objects , preparing for data generation , or communicating with other mods . Event listeners should be registered either using @EventBusSubscriber(bus = Bus.MOD) or in the mod constructor: @Mod.EventBusSubscriber(modid = \"mymod\", bus = Mod.EventBusSubscriber.Bus.MOD) public class MyModEventSubscriber { @SubscribeEvent static void onCommonSetup(FMLCommonSetupEvent event) { ... } } @Mod(\"mymod\") public class MyMod { public MyMod() { FMLModLoadingContext.get().getModEventBus().addListener(this::onCommonSetup); } private void onCommonSetup(FMLCommonSetupEvent event) { ... } } Warning Most of the lifecycle events are fired in parallel: all mods will concurrently receive the same event. Mods must take care to be thread-safe, like when calling other mods\u2019 APIs or accessing vanilla systems. Defer code for later execution via ParallelDispatchEvent#enqueueWork .","title":"Mod Lifecycle"},{"location":"concepts/lifecycle/#registry-events","text":"The registry events are fired after the mod instance construction. There are two: the NewRegistryEvent event and the RegistryEvent$Register event. These events are fired synchronously during mod loading. The NewRegistryEvent event allows modders to register their own custom registries, using the RegistryBuilder class. The RegistryEvent$Register<?> event is for registering objects into the registries. A Register event is fired for each registry.","title":"Registry Events"},{"location":"concepts/lifecycle/#data-generation","text":"If the game is setup to run data generators , then the GatherDataEvent will be the last event to fire. This event is for registering mods\u2019 data providers to their associated data generator. This event is also fired synchronously.","title":"Data Generation"},{"location":"concepts/lifecycle/#common-setup","text":"FMLCommonSetupEvent is for actions that are common to both physical client and server, such as registering capabilities .","title":"Common Setup"},{"location":"concepts/lifecycle/#sided-setup","text":"The sided-setup events are fired on their respective physical sides : FMLClientSetupEvent on the physical client, and FMLDedicatedServerSetupEvent for the dedicated server. This is where physical side-specific initialization should occur, such as registering client-side key bindings.","title":"Sided Setup"},{"location":"concepts/lifecycle/#intermodcomms","text":"This is where messages can be sent to mods for cross-mod compatibility. There are two events: InterModEnqueueEvent and InterModProcessEvent . InterModComms is the class responsible for holding messages for mods. The methods are safe to call during the lifecycle events, as it is backed by a ConcurrentMap . During the InterModEnqueueEvent , use InterModComms#sendTo to send messages to different mods. These methods take in the mod id that will be sent the message, the key associated with the message data, and a supplier holding the message data. Additionally, the sender of the message can also be specified, but by default it will be the mod id of the caller. Then during the InterModProcessEvent , use InterModComms#getMessages to get a stream of all received messages. The mod id supplied will almost always be the mod id of the mod the method is called on. Additionally, a predicate can be specified to filter out the message keys. This will return a stream of IMCMessage s which hold the sender of the data, the receiver of the data, the data key, and the supplied data itself. Note There are two other lifecycle events: FMLConstructModEvent , fired directly after mod instance construction but before the RegistryEvent s, and FMLLoadCompleteEvent , fired after the InterModComms events, for when the mod loading process is complete.","title":"InterModComms"},{"location":"concepts/registries/","text":"Registries Registration is the process of taking the objects of a mod (such as items, blocks, sounds, etc.) and making them known to the game. Registering things is important, as without registration the game will simply not know about these objects, which will cause unexplainable behaviors and crashes. Most things that require registration in the game are handled by the Forge registries. A registry is an object similar to a map that assigns values to keys. Forge uses registries with ResourceLocation keys to register objects. This allows the ResourceLocation to act as the \u201cregistry name\u201d for objects. The registry name for an object may be accessed with #getRegistryName / #setRegistryName . The setter can only be called once; calling it twice results in an exception. Every type of registrable object has its own registry. To see all registries supported by Forge, see the ForgeRegistries class. All registry names within a registry must be unique. However, names in different registries will not collide. For example, there\u2019s a Block registry, and an Item registry. A Block and an Item may be registered with the same name example:thing without colliding; however, if two different Block s or Item s were registered with the same exact name, the second object will override the first. Methods for Registering There are two proper ways to register objects: the DeferredRegister class, and the RegistryEvent$Register lifecycle event. DeferredRegister DeferredRegister is the newer and documented way to register objects. It allows the use and convenience of static initializers while avoiding the issues associated with it. It simply maintains a list of suppliers for entries and registers the objects from those suppliers during the proper RegistryEvent$Register event. An example of a mod registering a custom block: private static final DeferredRegister<Block> BLOCKS = DeferredRegister.create(ForgeRegistries.BLOCKS, MODID); public static final RegistryObject<Block> ROCK_BLOCK = BLOCKS.register(\"rock\", () -> new Block(BlockBehaviour.Properties.of(Material.STONE))); public ExampleMod() { BLOCKS.register(FMLJavaModLoadingContext.get().getModEventBus()); } Register events The RegistryEvent s are the second and more flexible way to register objects. These events are fired after the mod constructors and before the loading of configs. The event used to register objects is RegistryEvent$Register<T> . The type parameter T should be set to the type of the object being registered. Calling #getRegistry will return the registry, upon which objects are registered with #register or #registerAll . Here is an example: (the event handler is registered on the mod event bus ) @SubscribeEvent public void registerBlocks(RegistryEvent.Register<Block> event) { event.getRegistry().registerAll(new Block(...), new Block(...), ...); } Registries that aren\u2019t Forge Registries Due to some peculiarities of vanilla code, not all registries are wrapped by Forge. These can be static registries, like RecipeType , which are safe to use. There are also dynamic registries, like ConfiguredFeature and some other worldgen registries, which are typically represented in JSON. These objects should only be registered this way if there is another registry object that requires it. DeferredRegister#create has an overload which allows modders to specify the registry key of which vanilla registry to create a RegistryObject for. The registry method and attaching to the mod event bus is the same as other DeferredRegister s. private static final DeferredRegister<RecipeType<?>> REGISTER = DeferredRegister.create(Registry.RECIPE_TYPE_REGISTRY, \"examplemod\"); // As RecipeType is an interface, an anonymous class will be created for registering // Vanilla RecipeTypes override #toString for debugging purposes, so it is omitted in this example // Assume some recipe ExampleRecipe public static final RegistryObject<RecipeType<ExampleRecipe>> EXAMPLE_RECIPE_TYPE = REGISTER.register(\"example_recipe_type\", () -> new RecipeType<>() {}); Note Some classes cannot by themselves be registered. Instead, *Type classes are registered, and used in the formers\u2019 constructors. For example, BlockEntity has BlockEntityType , and Entity has EntityType . These *Type classes are factories that simply create the containing type on demand. These factories are created through the use of their *Type$Builder classes. An example: ( REGISTER refers to a DeferredRegister<BlockEntityType> ) public static final RegistryObject<BlockEntityType<ExampleBlockEntity>> EXAMPLE_BLOCK_ENTITY = REGISTER.register( \"example_block_entity\", () -> BlockEntityType.Builder.of(ExampleBlockEntity::new, EXAMPLE_BLOCK.get()).build(null) ); Referencing Registered Objects Registered objects should not be stored in fields when they are created and registered. They are to be always newly created and registered whenever their respective RegistryEvent$Register event is fired. This is to allow dynamic loading and unloading of mods in a future version of Forge. Registered objects must always be referenced through a RegistryObject or a field with @ObjectHolder . Using RegistryObjects RegistryObject s can be used to retrieve references to registered objects once they are available. These are used by DeferredRegister to return a reference to the registered objects. Their references are updated after their corresponding registry\u2019s RegistryEvent$Register event is fired, along with the @ObjectHolder annotations. To get a RegistryObject , call RegistryObject#create with a ResourceLocation and the IForgeRegistry of the registrable object. Custom registries can also be used by giving a supplier of the object\u2019s class. Store the RegistryObject in a public static final field, and call #get whenever you need the registered object. An example of using RegistryObject : public static final RegistryObject<Item> BOW = RegistryObject.create(new ResourceLocation(\"minecraft:bow\"), ForgeRegistries.ITEMS); // assume that 'neomagicae:mana_type' is a valid registry, and 'neomagicae:coffeinum' is a valid object within that registry public static final RegistryObject<ManaType> COFFEINUM = RegistryObject.create(new ResourceLocation(\"neomagicae\", \"coffeinum\"), new ResourceLocation(\"neomagicae\", \"mana_type\"), \"neomagicae\"); Using @ObjectHolder Registered objects from registries can be injected into the public static fields by annotating classes or fields with @ObjectHolder and supplying enough information to construct a ResourceLocation to identify a specific object in a specific registry. The rules for @ObjectHolder are as follows: If the class is annotated with @ObjectHolder , its value will be the default namespace for all fields within if not explicitly defined If the class is annotated with @Mod , the modid will be the default namespace for all annotated fields within if not explicitly defined A field is considered for injection if: it has at least the modifiers public static ; one of the following conditions are true: the enclosing class has an @ObjectHolder annotation, and the field is final , and: the name value is the field\u2019s name; and the namespace value is the enclosing class\u2019s namespace An exception is thrown if the namespace value cannot be found and inherited the field is annotated with @ObjectHolder , and: the name value is explicitly defined; and the namespace value is either explicitly defined or the enclosing class\u2019s namespace the field type or one of its supertypes corresponds to a valid registry (e.g. Item or ArrowItem for the Item registry); An exception is thrown if a field does not have a corresponding registry. An exception is thrown if the resulting ResourceLocation is incomplete or invalid (non-valid characters in path) If no other errors or exceptions occur, the field will be injected If all of the above rules do not apply, no action will be taken (and a message may be logged) @ObjectHolder -annotated fields are injected with their values after their corresponding registry\u2019s RegistryEvent$Register event is fired, along with the RegistryObject s. Note If the object does not exist in the registry when it is to be injected, a debug message will be logged and no value will be injected. As these rules are rather complicated, here are some examples: @ObjectHolder(\"minecraft\") // Inheritable resource namespace: \"minecraft\" class AnnotatedHolder { public static final Block diamond_block = null; // No annotation. [public static final] is required. // Block has a corresponding registry: [Block] // Name path is the name of the field: \"diamond_block\" // Namespace is not explicitly defined. // So, namespace is inherited from class annotation: \"minecraft\" // To inject: \"minecraft:diamond_block\" from the [Block] registry @ObjectHolder(\"ambient.cave\") public static SoundEvent ambient_sound = null; // Annotation present. [public static] is required. // SoundEvent has a corresponding registry: [SoundEvent] // Name path is the value of the annotation: \"ambient.cave\" // Namespace is not explicitly defined. // So, namespace is inherited from class annotation: \"minecraft\" // To inject: \"minecraft:ambient.cave\" from the [SoundEvent] registry // Assume for the next entry that [ManaType] is a valid registry. @ObjectHolder(\"neomagicae:coffeinum\") public static final ManaType coffeinum = null; // Annotation present. [public static] is required. [final] is optional. // ManaType has a corresponding registry: [ManaType] (custom registry) // Resource location is explicitly defined: \"neomagicae:coffeinum\" // To inject: \"neomagicae:coffeinum\" from the [ManaType] registry public static final Item ENDER_PEARL = null; // No annotation. [public static final] is required. // Item has a corresponding registry: [Item]. // Name path is the name of the field: \"ENDER_PEARL\" -> \"ender_pearl\" // !! ^ Field name is valid, because they are // converted to lowercase automatically. // Namespace is not explicitly defined. // So, namespace is inherited from class annotation: \"minecraft\" // To inject: \"minecraft:ender_pearl\" from the [Item] registry @ObjectHolder(\"minecraft:arrow\") public static final ArrowItem arrow = null; // Annotation present. [public static] is required. [final] is optional. // ArrowItem does not have a corresponding registry. // ArrowItem's supertype of Item has a corresponding registry: [Item] // Resource location is explicitly defined: \"minecraft:arrow\" // To inject: \"minecraft:arrow\" from the [Item] registry public static Block bedrock = null; // No annotation, so [public static final] is required. // Therefore, the field is ignored. public static final CreativeModeTab group = null; // No annotation. [public static final] is required. // CreativeModeTab does not have a corresponding registry. // No supertypes of CreativeModeTab has a corresponding registry. // Therefore, THIS WILL PRODUCE AN EXCEPTION. } class UnannotatedHolder { // Note the lack of an @ObjectHolder annotation on this class. @ObjectHolder(\"minecraft:flame\") public static final Enchantment flame = null; // Annotation present. [public static] is required. [final] is optional. // Enchantment has corresponding registry: [Enchantment]. // Resource location is explicitly defined: \"minecraft:flame\" // To inject: \"minecraft:flame\" from the [Enchantment] registry public static final Biome ice_flat = null; // No annotation on the enclosing class. // Therefore, the field is ignored. @ObjectHolder(\"minecraft:creeper\") public static Entity creeper = null; // Annotation present. [public static] is required. // Entity does not have a corresponding registry. // No supertypes of Entity has a corresponding registry. // Therefore, THIS WILL PRODUCE AN EXCEPTION. @ObjectHolder(\"levitation\") public static final Potion levitation = null; // Annotation present. [public static] is required. [final] is optional. // Potion has a corresponding registry: [Potion]. // Name path is the value of the annotation: \"levitation\" // Namespace is not explicitly defined. // No annotation in enclosing class. // Therefore, THIS WILL PRODUCE AN EXCEPTION. } Creating Custom Forge Registries Custom registries can usually just be a simple map of key to value. This is a common style; however, it forces a hard dependency on the registry being present. It also requires that any data that needs to be synced between sides must be done manually. Custom Forge Registries provide a simple alternative for creating soft dependents along with better management and automatic syncing between sides (unless told otherwise). Since the objects also use a Forge registry, registration becomes standardized in the same way. Custom Forge Registries are created with the help of a RegistryBuilder , through either NewRegistryEvent or the DeferredRegister . The RegistryBuilder class takes various parameters (such as the registry\u2019s name, the Class of its values, and various callbacks for different events happening on the registry). New registries are registered to the RegistryManager after NewRegistryEvent finishes firing. The Class of the value of the registry must implement IForgeRegistryEntry , which defines that #setRegistryName and #getRegistryName can be called on the objects of that class. It is recommended to extend ForgeRegistryEntry , the default implementation instead of implementing the interface directly. When #setRegistryName(String) is called with a string, and that string does not have an explicit namespace, its namespace will be set to the current modid. Any newly created registry should use its associated registration method to register the associated objects. Using NewRegistryEvent When using NewRegistryEvent , calling #create with a RegistryBuilder will return a supplier-wrapped registry. The supplied registry can be accessed after NewRegistryEvent has finished posting to the mod event bus. Getting the custom registry from the supplier before NewRegistryEvent finishes firing will result in a null value. With DeferredRegister The DeferredRegister method is once again another wrapper around the above event. Once a DeferredRegister is created in a constant field using the #create overload which takes in the registry name and the mod id, the registry can be constructed via DeferredRegister#makeRegistry . This takes in the registry class along with a supplied RegistryBuilder containing any additional configurations. The method already populates #setName and #setType by default. Since this method can be returned at any time, a supplied version of an IForgeRegistry is returned instead. Getting the custom registry from the supplier before NewRegistryEvent is fired will result in a null value. Important DeferredRegister#makeRegistry must be called before the DeferredRegister is added to the mod event bus via #register . #makeRegistry also uses the #register method to create the registry during NewRegistryEvent . Handling Missing Entries There are cases where certain registry objects will cease to exist whenever a mod is updated or, more likely, removed. It is possible to specify actions to handle the missing mapping through the third of the registry events: RegistryEvent$MissingMappings . Within this event, a list of missing mappings can be obtained either by #getMappings given a mod id or all mappings via #getAllMappings . For each Mapping , one of four mapping types can be selected to handle the missing entry: Action Description IGNORE Ignores the missing entry and abandons the mapping. WARN Generates a warning in the log. FAIL Prevents the world from loading. REMAP Remaps the entry to an already registered, non-null object. If no action is specified, then the default action will occur by notifying the user about the missing entry and whether they still would like to load the world. All actions besides remapping will prevent any other registry object from taking the place of the existing id in case the associated entry ever gets added back into the game.","title":"Registries"},{"location":"concepts/registries/#registries","text":"Registration is the process of taking the objects of a mod (such as items, blocks, sounds, etc.) and making them known to the game. Registering things is important, as without registration the game will simply not know about these objects, which will cause unexplainable behaviors and crashes. Most things that require registration in the game are handled by the Forge registries. A registry is an object similar to a map that assigns values to keys. Forge uses registries with ResourceLocation keys to register objects. This allows the ResourceLocation to act as the \u201cregistry name\u201d for objects. The registry name for an object may be accessed with #getRegistryName / #setRegistryName . The setter can only be called once; calling it twice results in an exception. Every type of registrable object has its own registry. To see all registries supported by Forge, see the ForgeRegistries class. All registry names within a registry must be unique. However, names in different registries will not collide. For example, there\u2019s a Block registry, and an Item registry. A Block and an Item may be registered with the same name example:thing without colliding; however, if two different Block s or Item s were registered with the same exact name, the second object will override the first.","title":"Registries"},{"location":"concepts/registries/#methods-for-registering","text":"There are two proper ways to register objects: the DeferredRegister class, and the RegistryEvent$Register lifecycle event.","title":"Methods for Registering"},{"location":"concepts/registries/#deferredregister","text":"DeferredRegister is the newer and documented way to register objects. It allows the use and convenience of static initializers while avoiding the issues associated with it. It simply maintains a list of suppliers for entries and registers the objects from those suppliers during the proper RegistryEvent$Register event. An example of a mod registering a custom block: private static final DeferredRegister<Block> BLOCKS = DeferredRegister.create(ForgeRegistries.BLOCKS, MODID); public static final RegistryObject<Block> ROCK_BLOCK = BLOCKS.register(\"rock\", () -> new Block(BlockBehaviour.Properties.of(Material.STONE))); public ExampleMod() { BLOCKS.register(FMLJavaModLoadingContext.get().getModEventBus()); }","title":"DeferredRegister"},{"location":"concepts/registries/#register-events","text":"The RegistryEvent s are the second and more flexible way to register objects. These events are fired after the mod constructors and before the loading of configs. The event used to register objects is RegistryEvent$Register<T> . The type parameter T should be set to the type of the object being registered. Calling #getRegistry will return the registry, upon which objects are registered with #register or #registerAll . Here is an example: (the event handler is registered on the mod event bus ) @SubscribeEvent public void registerBlocks(RegistryEvent.Register<Block> event) { event.getRegistry().registerAll(new Block(...), new Block(...), ...); }","title":"Register events"},{"location":"concepts/registries/#registries-that-arent-forge-registries","text":"Due to some peculiarities of vanilla code, not all registries are wrapped by Forge. These can be static registries, like RecipeType , which are safe to use. There are also dynamic registries, like ConfiguredFeature and some other worldgen registries, which are typically represented in JSON. These objects should only be registered this way if there is another registry object that requires it. DeferredRegister#create has an overload which allows modders to specify the registry key of which vanilla registry to create a RegistryObject for. The registry method and attaching to the mod event bus is the same as other DeferredRegister s. private static final DeferredRegister<RecipeType<?>> REGISTER = DeferredRegister.create(Registry.RECIPE_TYPE_REGISTRY, \"examplemod\"); // As RecipeType is an interface, an anonymous class will be created for registering // Vanilla RecipeTypes override #toString for debugging purposes, so it is omitted in this example // Assume some recipe ExampleRecipe public static final RegistryObject<RecipeType<ExampleRecipe>> EXAMPLE_RECIPE_TYPE = REGISTER.register(\"example_recipe_type\", () -> new RecipeType<>() {}); Note Some classes cannot by themselves be registered. Instead, *Type classes are registered, and used in the formers\u2019 constructors. For example, BlockEntity has BlockEntityType , and Entity has EntityType . These *Type classes are factories that simply create the containing type on demand. These factories are created through the use of their *Type$Builder classes. An example: ( REGISTER refers to a DeferredRegister<BlockEntityType> ) public static final RegistryObject<BlockEntityType<ExampleBlockEntity>> EXAMPLE_BLOCK_ENTITY = REGISTER.register( \"example_block_entity\", () -> BlockEntityType.Builder.of(ExampleBlockEntity::new, EXAMPLE_BLOCK.get()).build(null) );","title":"Registries that aren't Forge Registries"},{"location":"concepts/registries/#referencing-registered-objects","text":"Registered objects should not be stored in fields when they are created and registered. They are to be always newly created and registered whenever their respective RegistryEvent$Register event is fired. This is to allow dynamic loading and unloading of mods in a future version of Forge. Registered objects must always be referenced through a RegistryObject or a field with @ObjectHolder .","title":"Referencing Registered Objects"},{"location":"concepts/registries/#using-registryobjects","text":"RegistryObject s can be used to retrieve references to registered objects once they are available. These are used by DeferredRegister to return a reference to the registered objects. Their references are updated after their corresponding registry\u2019s RegistryEvent$Register event is fired, along with the @ObjectHolder annotations. To get a RegistryObject , call RegistryObject#create with a ResourceLocation and the IForgeRegistry of the registrable object. Custom registries can also be used by giving a supplier of the object\u2019s class. Store the RegistryObject in a public static final field, and call #get whenever you need the registered object. An example of using RegistryObject : public static final RegistryObject<Item> BOW = RegistryObject.create(new ResourceLocation(\"minecraft:bow\"), ForgeRegistries.ITEMS); // assume that 'neomagicae:mana_type' is a valid registry, and 'neomagicae:coffeinum' is a valid object within that registry public static final RegistryObject<ManaType> COFFEINUM = RegistryObject.create(new ResourceLocation(\"neomagicae\", \"coffeinum\"), new ResourceLocation(\"neomagicae\", \"mana_type\"), \"neomagicae\");","title":"Using RegistryObjects"},{"location":"concepts/registries/#using-objectholder","text":"Registered objects from registries can be injected into the public static fields by annotating classes or fields with @ObjectHolder and supplying enough information to construct a ResourceLocation to identify a specific object in a specific registry. The rules for @ObjectHolder are as follows: If the class is annotated with @ObjectHolder , its value will be the default namespace for all fields within if not explicitly defined If the class is annotated with @Mod , the modid will be the default namespace for all annotated fields within if not explicitly defined A field is considered for injection if: it has at least the modifiers public static ; one of the following conditions are true: the enclosing class has an @ObjectHolder annotation, and the field is final , and: the name value is the field\u2019s name; and the namespace value is the enclosing class\u2019s namespace An exception is thrown if the namespace value cannot be found and inherited the field is annotated with @ObjectHolder , and: the name value is explicitly defined; and the namespace value is either explicitly defined or the enclosing class\u2019s namespace the field type or one of its supertypes corresponds to a valid registry (e.g. Item or ArrowItem for the Item registry); An exception is thrown if a field does not have a corresponding registry. An exception is thrown if the resulting ResourceLocation is incomplete or invalid (non-valid characters in path) If no other errors or exceptions occur, the field will be injected If all of the above rules do not apply, no action will be taken (and a message may be logged) @ObjectHolder -annotated fields are injected with their values after their corresponding registry\u2019s RegistryEvent$Register event is fired, along with the RegistryObject s. Note If the object does not exist in the registry when it is to be injected, a debug message will be logged and no value will be injected. As these rules are rather complicated, here are some examples: @ObjectHolder(\"minecraft\") // Inheritable resource namespace: \"minecraft\" class AnnotatedHolder { public static final Block diamond_block = null; // No annotation. [public static final] is required. // Block has a corresponding registry: [Block] // Name path is the name of the field: \"diamond_block\" // Namespace is not explicitly defined. // So, namespace is inherited from class annotation: \"minecraft\" // To inject: \"minecraft:diamond_block\" from the [Block] registry @ObjectHolder(\"ambient.cave\") public static SoundEvent ambient_sound = null; // Annotation present. [public static] is required. // SoundEvent has a corresponding registry: [SoundEvent] // Name path is the value of the annotation: \"ambient.cave\" // Namespace is not explicitly defined. // So, namespace is inherited from class annotation: \"minecraft\" // To inject: \"minecraft:ambient.cave\" from the [SoundEvent] registry // Assume for the next entry that [ManaType] is a valid registry. @ObjectHolder(\"neomagicae:coffeinum\") public static final ManaType coffeinum = null; // Annotation present. [public static] is required. [final] is optional. // ManaType has a corresponding registry: [ManaType] (custom registry) // Resource location is explicitly defined: \"neomagicae:coffeinum\" // To inject: \"neomagicae:coffeinum\" from the [ManaType] registry public static final Item ENDER_PEARL = null; // No annotation. [public static final] is required. // Item has a corresponding registry: [Item]. // Name path is the name of the field: \"ENDER_PEARL\" -> \"ender_pearl\" // !! ^ Field name is valid, because they are // converted to lowercase automatically. // Namespace is not explicitly defined. // So, namespace is inherited from class annotation: \"minecraft\" // To inject: \"minecraft:ender_pearl\" from the [Item] registry @ObjectHolder(\"minecraft:arrow\") public static final ArrowItem arrow = null; // Annotation present. [public static] is required. [final] is optional. // ArrowItem does not have a corresponding registry. // ArrowItem's supertype of Item has a corresponding registry: [Item] // Resource location is explicitly defined: \"minecraft:arrow\" // To inject: \"minecraft:arrow\" from the [Item] registry public static Block bedrock = null; // No annotation, so [public static final] is required. // Therefore, the field is ignored. public static final CreativeModeTab group = null; // No annotation. [public static final] is required. // CreativeModeTab does not have a corresponding registry. // No supertypes of CreativeModeTab has a corresponding registry. // Therefore, THIS WILL PRODUCE AN EXCEPTION. } class UnannotatedHolder { // Note the lack of an @ObjectHolder annotation on this class. @ObjectHolder(\"minecraft:flame\") public static final Enchantment flame = null; // Annotation present. [public static] is required. [final] is optional. // Enchantment has corresponding registry: [Enchantment]. // Resource location is explicitly defined: \"minecraft:flame\" // To inject: \"minecraft:flame\" from the [Enchantment] registry public static final Biome ice_flat = null; // No annotation on the enclosing class. // Therefore, the field is ignored. @ObjectHolder(\"minecraft:creeper\") public static Entity creeper = null; // Annotation present. [public static] is required. // Entity does not have a corresponding registry. // No supertypes of Entity has a corresponding registry. // Therefore, THIS WILL PRODUCE AN EXCEPTION. @ObjectHolder(\"levitation\") public static final Potion levitation = null; // Annotation present. [public static] is required. [final] is optional. // Potion has a corresponding registry: [Potion]. // Name path is the value of the annotation: \"levitation\" // Namespace is not explicitly defined. // No annotation in enclosing class. // Therefore, THIS WILL PRODUCE AN EXCEPTION. }","title":"Using @ObjectHolder"},{"location":"concepts/registries/#creating-custom-forge-registries","text":"Custom registries can usually just be a simple map of key to value. This is a common style; however, it forces a hard dependency on the registry being present. It also requires that any data that needs to be synced between sides must be done manually. Custom Forge Registries provide a simple alternative for creating soft dependents along with better management and automatic syncing between sides (unless told otherwise). Since the objects also use a Forge registry, registration becomes standardized in the same way. Custom Forge Registries are created with the help of a RegistryBuilder , through either NewRegistryEvent or the DeferredRegister . The RegistryBuilder class takes various parameters (such as the registry\u2019s name, the Class of its values, and various callbacks for different events happening on the registry). New registries are registered to the RegistryManager after NewRegistryEvent finishes firing. The Class of the value of the registry must implement IForgeRegistryEntry , which defines that #setRegistryName and #getRegistryName can be called on the objects of that class. It is recommended to extend ForgeRegistryEntry , the default implementation instead of implementing the interface directly. When #setRegistryName(String) is called with a string, and that string does not have an explicit namespace, its namespace will be set to the current modid. Any newly created registry should use its associated registration method to register the associated objects.","title":"Creating Custom Forge Registries"},{"location":"concepts/registries/#using-newregistryevent","text":"When using NewRegistryEvent , calling #create with a RegistryBuilder will return a supplier-wrapped registry. The supplied registry can be accessed after NewRegistryEvent has finished posting to the mod event bus. Getting the custom registry from the supplier before NewRegistryEvent finishes firing will result in a null value.","title":"Using NewRegistryEvent"},{"location":"concepts/registries/#with-deferredregister","text":"The DeferredRegister method is once again another wrapper around the above event. Once a DeferredRegister is created in a constant field using the #create overload which takes in the registry name and the mod id, the registry can be constructed via DeferredRegister#makeRegistry . This takes in the registry class along with a supplied RegistryBuilder containing any additional configurations. The method already populates #setName and #setType by default. Since this method can be returned at any time, a supplied version of an IForgeRegistry is returned instead. Getting the custom registry from the supplier before NewRegistryEvent is fired will result in a null value. Important DeferredRegister#makeRegistry must be called before the DeferredRegister is added to the mod event bus via #register . #makeRegistry also uses the #register method to create the registry during NewRegistryEvent .","title":"With DeferredRegister"},{"location":"concepts/registries/#handling-missing-entries","text":"There are cases where certain registry objects will cease to exist whenever a mod is updated or, more likely, removed. It is possible to specify actions to handle the missing mapping through the third of the registry events: RegistryEvent$MissingMappings . Within this event, a list of missing mappings can be obtained either by #getMappings given a mod id or all mappings via #getAllMappings . For each Mapping , one of four mapping types can be selected to handle the missing entry: Action Description IGNORE Ignores the missing entry and abandons the mapping. WARN Generates a warning in the log. FAIL Prevents the world from loading. REMAP Remaps the entry to an already registered, non-null object. If no action is specified, then the default action will occur by notifying the user about the missing entry and whether they still would like to load the world. All actions besides remapping will prevent any other registry object from taking the place of the existing id in case the associated entry ever gets added back into the game.","title":"Handling Missing Entries"},{"location":"concepts/resources/","text":"Resources A resource is extra data used by the game, and is stored in a data file, instead of being in the code. Minecraft has two primary resource systems active: one on the logical client used for visuals such as models, textures, and localization called assets , and one on the logical server used for gameplay such as recipes and loot tables called data . Resource packs control the former, while Datapacks control the latter. In the default mod development kit, assets and data directories are located under the src/main/resources directory of the project. When multiple resource packs or data packs are enabled, they are merged. Generally, files from packs at the top of the stack override those below; however, for certain files, such as localization files and tags, data is actually merged contentwise. Mods define resource and data packs in their resources directories, but they are seen as subsets of the \u201cMod Resources\u201d pack. Mod resource packs cannot be disabled, but they can be overridden by other resource packs. Mod datapacks can be disabled with the vanilla /datapack command. All resources should have snake case paths and filenames (lowercase, using \u201c_\u201d for word boundaries), which is enforced in 1.11 and above. ResourceLocation Minecraft identifies resources using ResourceLocation s. A ResourceLocation contains two parts: a namespace and a path. It generally points to the resource at assets/<namespace>/<ctx>/<path> , where ctx is a context-specific path fragment that depends on how the ResourceLocation is being used. When a ResourceLocation is written/read as from a string, it is seen as <namespace>:<path> . If the namespace and the colon are left out, then when the string is read into an ResourceLocation the namespace will always default to \"minecraft\" . A mod should put its resources into a namespace with the same name as its modid (e.g. a mod with id examplemod should place its resources in assets/examplemod and data/examplemod respectively, and ResourceLocation s pointing to those files would look like examplemod:<path> .). This is not a requirement, and in some cases it can be desirable to use a different (or even more than one) namespace. ResourceLocation s are used outside the resource system, too, as they happen to be a great way to uniquely identify objects (e.g. registries ).","title":"Resources"},{"location":"concepts/resources/#resources","text":"A resource is extra data used by the game, and is stored in a data file, instead of being in the code. Minecraft has two primary resource systems active: one on the logical client used for visuals such as models, textures, and localization called assets , and one on the logical server used for gameplay such as recipes and loot tables called data . Resource packs control the former, while Datapacks control the latter. In the default mod development kit, assets and data directories are located under the src/main/resources directory of the project. When multiple resource packs or data packs are enabled, they are merged. Generally, files from packs at the top of the stack override those below; however, for certain files, such as localization files and tags, data is actually merged contentwise. Mods define resource and data packs in their resources directories, but they are seen as subsets of the \u201cMod Resources\u201d pack. Mod resource packs cannot be disabled, but they can be overridden by other resource packs. Mod datapacks can be disabled with the vanilla /datapack command. All resources should have snake case paths and filenames (lowercase, using \u201c_\u201d for word boundaries), which is enforced in 1.11 and above.","title":"Resources"},{"location":"concepts/resources/#resourcelocation","text":"Minecraft identifies resources using ResourceLocation s. A ResourceLocation contains two parts: a namespace and a path. It generally points to the resource at assets/<namespace>/<ctx>/<path> , where ctx is a context-specific path fragment that depends on how the ResourceLocation is being used. When a ResourceLocation is written/read as from a string, it is seen as <namespace>:<path> . If the namespace and the colon are left out, then when the string is read into an ResourceLocation the namespace will always default to \"minecraft\" . A mod should put its resources into a namespace with the same name as its modid (e.g. a mod with id examplemod should place its resources in assets/examplemod and data/examplemod respectively, and ResourceLocation s pointing to those files would look like examplemod:<path> .). This is not a requirement, and in some cases it can be desirable to use a different (or even more than one) namespace. ResourceLocation s are used outside the resource system, too, as they happen to be a great way to uniquely identify objects (e.g. registries ).","title":"ResourceLocation"},{"location":"concepts/sides/","text":"Sides in Minecraft A very important concept to understand when modding Minecraft are the two sides: client and server . There are many, many common misconceptions and mistakes regarding siding, which can lead to bugs that might not crash the game, but can rather have unintended and often unpredictable effects. Different Kinds of Sides When we say \u201cclient\u201d or \u201cserver\u201d, it usually follows with a fairly intuitive understanding of what part of the game we are talking about. After all, a client is what the user interacts with, and a server is where the user connects for a multiplayer game. Easy, right? As it turns out, there can be some ambiguity even with two such terms. Here we disambiguate the four possible meanings of \u201cclient\u201d and \u201cserver\u201d: Physical client - The physical client is the entire program that runs whenever you launch Minecraft from the launcher. All threads, processes, and services that run during the game\u2019s graphical, interactable lifetime are part of the physical client. Physical server - Often known as the dedicated server, the physical server is the entire program that runs whenever you launch any sort of minecraft_server.jar that does not bring up a playable GUI. Logical server - The logical server is what runs game logic: mob spawning, weather, updating inventories, health, AI, and all other game mechanics. The logical server is present within a physical server, but it also can run inside a physical client together with a logical client, as a single player world. The logical server always runs in a thread named the Server Thread . Logical client - The logical client is what accepts input from the player and relays it to the logical server. In addition, it also receives information from the logical server and makes it available graphically to the player. The logical client runs in the Render Thread , though often several other threads are spawned to handle things like audio and chunk render batching. In the MinecraftForge codebase, the physical side is represented by an enum called Dist , while the logical side is represented by an enum called LogicalSide . Performing Side-Specific Operations Level#isClientSide This boolean check will be your most used way to check sides. Querying this field on a Level object establishes the logical side the level belongs to. That is, if this field is true , the level is currently running on the logical client. If the field is false , the level is running on the logical server. It follows that the physical server will always contain false in this field, but we cannot assume that false implies a physical server, since this field can also be false for the logical server inside a physical client (in other words, a single player world). Use this check whenever you need to determine if game logic and other mechanics should be run. For example, if you want to damage the player every time they click your block, or have your machine process dirt into diamonds, you should only do so after ensuring #isClientSide is false . Applying game logic to the logical client can cause desynchronization (ghost entities, desynchronized stats, etc.) in the best case, and crashes in the worst case. This check should be used as your go-to default. Aside from DistExecutor , rarely will you need the other ways of determining side and adjusting behavior. DistExecutor Considering the use of a single \u201cuniversal\u201d jar for client and server mods, and the separation of the physical sides into two jars, an important question comes to mind: How do we use code that is only present on one physical side? All code in net.minecraft.client is only present on the physical client. If any class you write references those names in any way, they will crash the game when that respective class is loaded in an environment where those names do not exist. A very common mistake in beginners is to call Minecraft.getInstance().<doStuff>() in block or block entity classes, which will crash any physical server as soon as the class is loaded. How do we resolve this? Luckily, FML has DistExecutor , which provides various methods to run different methods on different physical sides, or a single method only on one side. Note It is important to understand that FML checks based on the physical side. A single player world (logical server + logical client within a physical client) will always use Dist.CLIENT ! DistExecutor works by taking in a supplied supplier executing a method, effectively preventing classloading by taking advantage of the invokedynamic JVM instruction . The executed method should be static and within a different class. Additionally, if no parameters are present for the static method, a method reference should be used instead of a supplier executing a method. There are two main methods within DistExecutor : #runWhenOn and #callWhenOn . The methods take in the physical side the executing method should run on and the supplied executing method which either runs or returns a result respectively. These two methods are subdivided further into #safe* and #unsafe* variants. Safe and unsafe variants are misnomers for their purposes. The main difference is that when in a development environment, the #safe* methods will validate that the supplied executing method is a lambda returning a method reference to another class with an error being thrown otherwise. Within the production environment, #safe* and #unsafe* are functionally the same. // In a client class: ExampleClass public static void unsafeRunMethodExample(Object param1, Object param2) { // ... } public static Object safeCallMethodExample() { // ... } // In some common class DistExecutor.unsafeRunWhenOn(Dist.CLIENT, () -> ExampleClass.unsafeRunMethodExample(var1, var2)); DistExecutor.safeCallWhenOn(Dist.CLIENT, () -> ExampleClass::safeCallMethodExample); Warning Due to a change in how invokedynamic works in Java 9+, all #safe* variants of the DistExecutor methods throw the original exception wrapped within a BootstrapMethodError in the development environment. #unsafe* variants or a check to FMLEnvironment#dist should be used instead. Thread Groups If Thread.currentThread().getThreadGroup() == SidedThreadGroups.SERVER is true, it is likely the current thread is on the logical server. Otherwise, it is likely on the logical client. This is useful to retrieve the logical side when you do not have access to a Level object to check isClientSide . It guesses which logical side you are on by looking at the group of the currently running thread. Because it is a guess, this method should only be used when other options have been exhausted. In nearly every case, you should prefer checking Level#isClientSide . FMLEnvironment#dist and @OnlyIn FMLEnvironment#dist holds the physical side your code is running on. Since it is determined at startup, it does not rely on guessing to return its result. The number of use cases for this is limited, however. Annotating a method or field with the @OnlyIn(Dist) annotation indicates to the loader that the respective member should be completely stripped out of the definition not on the specified physical side. Usually, these are only seen when browsing through the decompiled Minecraft code, indicating methods that the Mojang obfuscator stripped out. There is NO reason for using this annotation directly. Use DistExecutor or a check on FMLEnvironment#dist instead. Common Mistakes Reaching Across Logical Sides Whenever you want to send information from one logical side to another, you must always use network packets. It is incredibly tempting, when in a single player scenario, to directly transfer data from the logical server to the logical client. This is actually very commonly inadvertently done through static fields. Since the logical client and logical server share the same JVM in a single player scenario, both threads writing to and reading from static fields will cause all sorts of race conditions and the classical issues associated with threading. This mistake can also be made explicitly by accessing physical client-only classes such as Minecraft from common code that runs or can run on the logical server. This mistake is easy to miss for beginners who debug in a physical client. The code will work there, but it will immediately crash on a physical server. Writing One-Sided Mods In recent versions, Minecraft Forge has removed a \u201csidedness\u201d attribute from the mods.toml. This means that your mods are expected to work whether they are loaded on the physical client or the physical server. So for one-sided mods, you would typically register your event handlers inside a DistExecutor#safeRunWhenOn or DistExecutor#unsafeRunWhenOn instead of directly calling the relevant registration methods in your mod constructor. Basically, if your mod is loaded on the wrong side, it should simply do nothing, listen to no events, and so on. A one-sided mod by nature should not register blocks, items, \u2026 since they would need to be available on the other side, too. Additionally, if your mod is one-sided, it typically does not forbid the user from joining a server that is lacking that mod. Therefore, you should register an IExtensionPoint$DisplayTest extension point to make sure that Forge does not think your mod is required on the server, which would lead to the server being shown as incompatible. For that, put something similar to this into your main mod class constructor: //Make sure the mod being absent on the other network side does not cause the client to display the server as incompatible ModLoadingContext.get().registerExtensionPoint(IExtensionPoint.DisplayTest.class, () -> new IExtensionPoint.DisplayTest(() -> NetworkConstants.IGNORESERVERONLY, (a, b) -> true)); This tells the client that it should ignore the server version being absent, and the server that it should not tell the client this mod should be present. So this snippet works both for client- and server-only-sided mods.","title":"Sides"},{"location":"concepts/sides/#sides-in-minecraft","text":"A very important concept to understand when modding Minecraft are the two sides: client and server . There are many, many common misconceptions and mistakes regarding siding, which can lead to bugs that might not crash the game, but can rather have unintended and often unpredictable effects.","title":"Sides in Minecraft"},{"location":"concepts/sides/#different-kinds-of-sides","text":"When we say \u201cclient\u201d or \u201cserver\u201d, it usually follows with a fairly intuitive understanding of what part of the game we are talking about. After all, a client is what the user interacts with, and a server is where the user connects for a multiplayer game. Easy, right? As it turns out, there can be some ambiguity even with two such terms. Here we disambiguate the four possible meanings of \u201cclient\u201d and \u201cserver\u201d: Physical client - The physical client is the entire program that runs whenever you launch Minecraft from the launcher. All threads, processes, and services that run during the game\u2019s graphical, interactable lifetime are part of the physical client. Physical server - Often known as the dedicated server, the physical server is the entire program that runs whenever you launch any sort of minecraft_server.jar that does not bring up a playable GUI. Logical server - The logical server is what runs game logic: mob spawning, weather, updating inventories, health, AI, and all other game mechanics. The logical server is present within a physical server, but it also can run inside a physical client together with a logical client, as a single player world. The logical server always runs in a thread named the Server Thread . Logical client - The logical client is what accepts input from the player and relays it to the logical server. In addition, it also receives information from the logical server and makes it available graphically to the player. The logical client runs in the Render Thread , though often several other threads are spawned to handle things like audio and chunk render batching. In the MinecraftForge codebase, the physical side is represented by an enum called Dist , while the logical side is represented by an enum called LogicalSide .","title":"Different Kinds of Sides"},{"location":"concepts/sides/#performing-side-specific-operations","text":"","title":"Performing Side-Specific Operations"},{"location":"concepts/sides/#levelisclientside","text":"This boolean check will be your most used way to check sides. Querying this field on a Level object establishes the logical side the level belongs to. That is, if this field is true , the level is currently running on the logical client. If the field is false , the level is running on the logical server. It follows that the physical server will always contain false in this field, but we cannot assume that false implies a physical server, since this field can also be false for the logical server inside a physical client (in other words, a single player world). Use this check whenever you need to determine if game logic and other mechanics should be run. For example, if you want to damage the player every time they click your block, or have your machine process dirt into diamonds, you should only do so after ensuring #isClientSide is false . Applying game logic to the logical client can cause desynchronization (ghost entities, desynchronized stats, etc.) in the best case, and crashes in the worst case. This check should be used as your go-to default. Aside from DistExecutor , rarely will you need the other ways of determining side and adjusting behavior.","title":"Level#isClientSide"},{"location":"concepts/sides/#distexecutor","text":"Considering the use of a single \u201cuniversal\u201d jar for client and server mods, and the separation of the physical sides into two jars, an important question comes to mind: How do we use code that is only present on one physical side? All code in net.minecraft.client is only present on the physical client. If any class you write references those names in any way, they will crash the game when that respective class is loaded in an environment where those names do not exist. A very common mistake in beginners is to call Minecraft.getInstance().<doStuff>() in block or block entity classes, which will crash any physical server as soon as the class is loaded. How do we resolve this? Luckily, FML has DistExecutor , which provides various methods to run different methods on different physical sides, or a single method only on one side. Note It is important to understand that FML checks based on the physical side. A single player world (logical server + logical client within a physical client) will always use Dist.CLIENT ! DistExecutor works by taking in a supplied supplier executing a method, effectively preventing classloading by taking advantage of the invokedynamic JVM instruction . The executed method should be static and within a different class. Additionally, if no parameters are present for the static method, a method reference should be used instead of a supplier executing a method. There are two main methods within DistExecutor : #runWhenOn and #callWhenOn . The methods take in the physical side the executing method should run on and the supplied executing method which either runs or returns a result respectively. These two methods are subdivided further into #safe* and #unsafe* variants. Safe and unsafe variants are misnomers for their purposes. The main difference is that when in a development environment, the #safe* methods will validate that the supplied executing method is a lambda returning a method reference to another class with an error being thrown otherwise. Within the production environment, #safe* and #unsafe* are functionally the same. // In a client class: ExampleClass public static void unsafeRunMethodExample(Object param1, Object param2) { // ... } public static Object safeCallMethodExample() { // ... } // In some common class DistExecutor.unsafeRunWhenOn(Dist.CLIENT, () -> ExampleClass.unsafeRunMethodExample(var1, var2)); DistExecutor.safeCallWhenOn(Dist.CLIENT, () -> ExampleClass::safeCallMethodExample); Warning Due to a change in how invokedynamic works in Java 9+, all #safe* variants of the DistExecutor methods throw the original exception wrapped within a BootstrapMethodError in the development environment. #unsafe* variants or a check to FMLEnvironment#dist should be used instead.","title":"DistExecutor"},{"location":"concepts/sides/#thread-groups","text":"If Thread.currentThread().getThreadGroup() == SidedThreadGroups.SERVER is true, it is likely the current thread is on the logical server. Otherwise, it is likely on the logical client. This is useful to retrieve the logical side when you do not have access to a Level object to check isClientSide . It guesses which logical side you are on by looking at the group of the currently running thread. Because it is a guess, this method should only be used when other options have been exhausted. In nearly every case, you should prefer checking Level#isClientSide .","title":"Thread Groups"},{"location":"concepts/sides/#fmlenvironmentdist-and-onlyin","text":"FMLEnvironment#dist holds the physical side your code is running on. Since it is determined at startup, it does not rely on guessing to return its result. The number of use cases for this is limited, however. Annotating a method or field with the @OnlyIn(Dist) annotation indicates to the loader that the respective member should be completely stripped out of the definition not on the specified physical side. Usually, these are only seen when browsing through the decompiled Minecraft code, indicating methods that the Mojang obfuscator stripped out. There is NO reason for using this annotation directly. Use DistExecutor or a check on FMLEnvironment#dist instead.","title":"FMLEnvironment#dist and @OnlyIn"},{"location":"concepts/sides/#common-mistakes","text":"","title":"Common Mistakes"},{"location":"concepts/sides/#reaching-across-logical-sides","text":"Whenever you want to send information from one logical side to another, you must always use network packets. It is incredibly tempting, when in a single player scenario, to directly transfer data from the logical server to the logical client. This is actually very commonly inadvertently done through static fields. Since the logical client and logical server share the same JVM in a single player scenario, both threads writing to and reading from static fields will cause all sorts of race conditions and the classical issues associated with threading. This mistake can also be made explicitly by accessing physical client-only classes such as Minecraft from common code that runs or can run on the logical server. This mistake is easy to miss for beginners who debug in a physical client. The code will work there, but it will immediately crash on a physical server.","title":"Reaching Across Logical Sides"},{"location":"concepts/sides/#writing-one-sided-mods","text":"In recent versions, Minecraft Forge has removed a \u201csidedness\u201d attribute from the mods.toml. This means that your mods are expected to work whether they are loaded on the physical client or the physical server. So for one-sided mods, you would typically register your event handlers inside a DistExecutor#safeRunWhenOn or DistExecutor#unsafeRunWhenOn instead of directly calling the relevant registration methods in your mod constructor. Basically, if your mod is loaded on the wrong side, it should simply do nothing, listen to no events, and so on. A one-sided mod by nature should not register blocks, items, \u2026 since they would need to be available on the other side, too. Additionally, if your mod is one-sided, it typically does not forbid the user from joining a server that is lacking that mod. Therefore, you should register an IExtensionPoint$DisplayTest extension point to make sure that Forge does not think your mod is required on the server, which would lead to the server being shown as incompatible. For that, put something similar to this into your main mod class constructor: //Make sure the mod being absent on the other network side does not cause the client to display the server as incompatible ModLoadingContext.get().registerExtensionPoint(IExtensionPoint.DisplayTest.class, () -> new IExtensionPoint.DisplayTest(() -> NetworkConstants.IGNORESERVERONLY, (a, b) -> true)); This tells the client that it should ignore the server version being absent, and the server that it should not tell the client this mod should be present. So this snippet works both for client- and server-only-sided mods.","title":"Writing One-Sided Mods"},{"location":"datagen/","text":"Data Generators Data generators are a way to programmatically generate the assets and data of mods. It allows the definition of the contents of these files in the code and their automatic generation, without worrying about the specifics. The data generator system is loaded by the main class net.minecraft.data.Main . Different command-line arguments can be passed to customize which mods\u2019 data are gathered, what existing files are considered, etc. The class responsible for data generation is net.minecraft.data.DataGenerator . The default configurations in the MDK build.gradle adds the runData task for running the data generators. Existing Files All references to textures or other data files not generated for data generation must reference existing files on the system. This is to ensure that all referenced textures are in the correct places, so typos can be found and corrected. ExistingFileHelper is the class responsible for validating the existence of those data files. An instance can be retrieved from GatherDataEvent#getExistingFileHelper . The --existing <folderpath> argument allows the specified folder and its subfolders to be used when validating the existence of files. Additionally, the --existing-mod <modid> argument allows the resources of a loaded mod to be used for validation. By default, only the vanilla datapack and resources are available to the ExistingFileHelper . Generator Modes The data generator can be configured to run 4 different data generations, which are configured from the command-line parameters, and can be checked from GatherDataEvent#include*** methods. Client Assets Generates client-only files in assets : block/item models, blockstate JSONs, language files, etc. --client , #includeClient Server Data Generates server-only files in data : recipes, advancements, tags, etc. --server , #includeServer Development Tools Runs some development tools: converting SNBT to NBT and vice-versa, etc. --dev , #includeDev Reports Dumps all registered blocks, items, commands, etc. --reports , #includeReports All of the generators can be included using --all . Data Providers Data providers are the classes that actually define what data will be generated and provided. All data providers implement DataProvider . Minecraft has abstract implementations for most assets and data, so modders need only to extend and override the specified method. The GatherDataEvent is fired on the mod event bus when the data generator is being created, and the DataGenerator can be obtained from the event. Create and register data providers using DataGenerator#addProvider . Client Assets net.minecraftforge.common.data.LanguageProvider - for language strings ; override #addTranslations net.minecraftforge.common.data.SoundDefinitionsProvider - for sounds.json ; override #registerSounds net.minecraftforge.client.model.generators.ModelProvider<?> - for models ; override #registerModels ItemModelProvider - for item models BlockModelProvider - for block models net.minecraftforge.client.model.generators.BlockStateProvider - for blockstate JSONs and their block and item models; override #registerStatesAndModels Server Data net.minecraftforge.common.data.GlobalLootModifierProvider - for global loot modifiers ; override #start These classes are under the net.minecraft.data package LootTableProvider - for loot tables ; override #getTables RecipeProvider - for recipes and their unlocking advancements; override #buildCraftingRecipes TagsProvider - for tags ; override #addTags AdvancementProvider - for advancements ; override #registerAdvancements","title":"Introduction"},{"location":"datagen/#data-generators","text":"Data generators are a way to programmatically generate the assets and data of mods. It allows the definition of the contents of these files in the code and their automatic generation, without worrying about the specifics. The data generator system is loaded by the main class net.minecraft.data.Main . Different command-line arguments can be passed to customize which mods\u2019 data are gathered, what existing files are considered, etc. The class responsible for data generation is net.minecraft.data.DataGenerator . The default configurations in the MDK build.gradle adds the runData task for running the data generators.","title":"Data Generators"},{"location":"datagen/#existing-files","text":"All references to textures or other data files not generated for data generation must reference existing files on the system. This is to ensure that all referenced textures are in the correct places, so typos can be found and corrected. ExistingFileHelper is the class responsible for validating the existence of those data files. An instance can be retrieved from GatherDataEvent#getExistingFileHelper . The --existing <folderpath> argument allows the specified folder and its subfolders to be used when validating the existence of files. Additionally, the --existing-mod <modid> argument allows the resources of a loaded mod to be used for validation. By default, only the vanilla datapack and resources are available to the ExistingFileHelper .","title":"Existing Files"},{"location":"datagen/#generator-modes","text":"The data generator can be configured to run 4 different data generations, which are configured from the command-line parameters, and can be checked from GatherDataEvent#include*** methods. Client Assets Generates client-only files in assets : block/item models, blockstate JSONs, language files, etc. --client , #includeClient Server Data Generates server-only files in data : recipes, advancements, tags, etc. --server , #includeServer Development Tools Runs some development tools: converting SNBT to NBT and vice-versa, etc. --dev , #includeDev Reports Dumps all registered blocks, items, commands, etc. --reports , #includeReports All of the generators can be included using --all .","title":"Generator Modes"},{"location":"datagen/#data-providers","text":"Data providers are the classes that actually define what data will be generated and provided. All data providers implement DataProvider . Minecraft has abstract implementations for most assets and data, so modders need only to extend and override the specified method. The GatherDataEvent is fired on the mod event bus when the data generator is being created, and the DataGenerator can be obtained from the event. Create and register data providers using DataGenerator#addProvider .","title":"Data Providers"},{"location":"datagen/#client-assets","text":"net.minecraftforge.common.data.LanguageProvider - for language strings ; override #addTranslations net.minecraftforge.common.data.SoundDefinitionsProvider - for sounds.json ; override #registerSounds net.minecraftforge.client.model.generators.ModelProvider<?> - for models ; override #registerModels ItemModelProvider - for item models BlockModelProvider - for block models net.minecraftforge.client.model.generators.BlockStateProvider - for blockstate JSONs and their block and item models; override #registerStatesAndModels","title":"Client Assets"},{"location":"datagen/#server-data","text":"net.minecraftforge.common.data.GlobalLootModifierProvider - for global loot modifiers ; override #start These classes are under the net.minecraft.data package LootTableProvider - for loot tables ; override #getTables RecipeProvider - for recipes and their unlocking advancements; override #buildCraftingRecipes TagsProvider - for tags ; override #addTags AdvancementProvider - for advancements ; override #registerAdvancements","title":"Server Data"},{"location":"datagen/client/localization/","text":"Language Generation Language files can be generated for a mod by subclassing LanguageProvider and implementing #addTranslations . Each LanguageProvider subclass created represents a separate locale ( en_us represents American English, es_es represents Spanish, etc.). After implementation, the provider must be added to the DataGenerator . LanguageProvider Each language provider is simple a map of strings where each translation key is mapped to a localized name. A translation key mapping can be added using #add . Additionally, there are methods which use the translation key of a Block , Item , ItemStack , Enchantment , MobEffect , and EntityType . // In LanguageProvider#addTranslations this.addBlock(EXAMPLE_BLOCK, \"Example Block\"); this.add(\"object.examplemod.example_object\", \"Example Object\"); Tip Localized names which contain alphanumeric values not in American English can be supplied as is. The provider automatically translates the characters into their unicode equivalents to be read by the game. // Encdoded as 'Example with a d\\u00EDacritic' this.addItem(\"example.diacritic\", \"Example with a d\u00edacritic\");","title":"Language Providers"},{"location":"datagen/client/localization/#language-generation","text":"Language files can be generated for a mod by subclassing LanguageProvider and implementing #addTranslations . Each LanguageProvider subclass created represents a separate locale ( en_us represents American English, es_es represents Spanish, etc.). After implementation, the provider must be added to the DataGenerator .","title":"Language Generation"},{"location":"datagen/client/localization/#languageprovider","text":"Each language provider is simple a map of strings where each translation key is mapped to a localized name. A translation key mapping can be added using #add . Additionally, there are methods which use the translation key of a Block , Item , ItemStack , Enchantment , MobEffect , and EntityType . // In LanguageProvider#addTranslations this.addBlock(EXAMPLE_BLOCK, \"Example Block\"); this.add(\"object.examplemod.example_object\", \"Example Object\"); Tip Localized names which contain alphanumeric values not in American English can be supplied as is. The provider automatically translates the characters into their unicode equivalents to be read by the game. // Encdoded as 'Example with a d\\u00EDacritic' this.addItem(\"example.diacritic\", \"Example with a d\u00edacritic\");","title":"LanguageProvider"},{"location":"datagen/client/modelproviders/","text":"Model Generation Models can be generated for models or block states by default. Each provides a method of generating the necessary JSONs ( ModelBuilder#toJson for models and IGeneratedBlockState#toJson for block states). After implementation, the associated providers must be added to the DataGenerator . Model Files A ModelFile acts as the base for all models referenced or generated by a provider. Each model file stores the location relative to the models subdirectory and can assert whether the file exists. Existing Model Files ExistingModelFile is a subclass of ModelFile which checks via ExistingFileHelper#exists whether the model already exists within the models subdirectory. All non-generated models are usually referenced through ExistingModelFile s. Unchecked Model Files UncheckedModelFile is a subclass of ModelFile which assumes the specified model exists in some location. Note There should be no cases where an UncheckedModelFile is used to reference a model. If there is, then the associated resources are not properly being tracked by ExistingFileHelper . Model Builders A ModelBuilder represents a to-be-generated ModelFile . It contains all the data about a model: its parent, faces, textures, transformations, lighting, and loader . Tip While a complex model can be generated, it is recommended that those models be constructed using a modeling software beforehand. Then, the data provider can generate the children models with specific textures applied through the defined references in the parent complex model. The parent (via ModelBuilder#parent ) of the builder can be any ModelFile : generated or existing. Generated files are added to ModelProvider s as soon as the builder is created. The builder itself can be passed in as a parent, or the ResourceLocation can supplied alternatively. Warning If the parent is not generated before the child model when passing in a ResourceLocation , then an exception will be thrown. Each element (via ModelBuilder#element ) within a model is defined as cube using two three-dimensional points ( ElementBuilder#from and #to respectively) where each axis is limited to the values [-16,32] (between -16 and 32 inclusive). Each face ( ElementBuilder#face ) of the cube can specify when the face is culled ( FaceBuilder#cullface ), tint index ( FaceBuilder#tintindex ), texture reference from the textures keys ( FaceBuilder#texture ), UV coordinate on the texture ( FaceBuilder#uvs ), and rotation in 90 degree intervals ( FaceBuilder#rotation ). Note It recommended for block models which have elements that exceed a bound of [0,16] on any axis to separate into multiple blocks, such as for a multiblock structure, to avoid lighting and culling issues. Each cube can additionally be rotated ( ElementBuilder#rotation ) around a specified point ( RotationBuilder#origin ) for a given axis ( RotationBuilder#axis ) in 22.5 degree intervals ( RotationBuilder#angle ). The cube can scale all faces in relation to the entire model as well ( RotationBuilder#rescale ). The cube can also determine whether its shadows should be rendered ( ElementBuilder#shade ). Each model defines a list of texture keys ( ModelBuilder#texture ) which points to either a location or a reference. Each key can then be referenced in any element by prefixing using a # (a texture key of example can be referenced in an element using #example ). A location specifies where a texture is in assets/<namespace>/textures/<path>.png . A reference is used by any models parenting the current model as keys to define textures for later. The model can additionally be transformed ( ModelBuilder#transforms ) for any defined perspective (in the left hand in first person, in the gui, on the ground, etc.). For any perspective ( TransformsBuilder#transform ), the rotation ( TransformVecBuilder#rotation ), translation ( TransformVecBuilder#translation ), and scale ( TransformVecBuilder#scale ) can be set. Finally, the model can set whether to use ambient occlusion in a level ( ModelBuilder#ao ) and from what location to light and shade the model from ModelBuilder#guiLight . BlockModelBuilder A BlockModelBuilder represents a block model to-be-generated. There is no additional functionality compared to a ModelBuilder . ItemModelBuilder An ItemModelBuilder represents an item model to-be-generated. In addition to the ModelBuilder , overrides ( OverrideBuilder#override ) can be generated. Each override applied to a model can apply conditions which represent for a given property that must be above the specified value ( OverrideBuilder#predicate ). If the conditions are met, then the specified model ( OverrideBuilder#model ) will be rendered instead of this model. Model Providers The ModelProvider subclasses are responsible for generating the constructed ModelBuilder s. The provider takes in the generator, mod id, subdirectory in the models folder to generate within, a ModelBuilder factory, and the existing file helper. Each provider subclass must implement #registerModels . The provider contains basic methods which either create the ModelBuilder or provides convenience for getting texture or model references: Method Description getBuilder Creates a new ModelBuilder within the provider\u2019s subdirectory for the given mod id. withExistingParent Creates a new ModelBuilder for the given parent. Should be used when the parent is not generated by the builder. mcLoc Creates a ResourceLocation for the path in the minecraft namespace. modLoc Creates a ResourceLocation for the path in the given mod id\u2019s namespace. Additionally, there are several helpers for easily generating common models using vanilla templates. Most are for block models with only a few being universal. Note Although the models are within a specific subdirectory, that does not mean that the model cannot be referenced by a model in another subdirectory. Usually, it is indicative of that model being used for that type of object. BlockModelProvider The BlockModelProvider is used for generating block models via BlockModelBuilder in the block folder. Block models should typically parent minecraft:block/block or one of its children models for use with item models. Note Block models and its item model counterpart are typically not generated through a direct subclass of BlockModelProvider and ItemModelProvider but through BlockStateProvider . ItemModelProvider The ItemModelProvider is used for generating block models via ItemModelBuilder in the item folder. Most item models parent item/generated and use layer0 to specify their texture, which can be done using #singleTexture . Note item/generated can support five texture layers stacked on top of each other: layer0 , layer1 , layer2 , layer3 , and layer4 . // In some ItemModelProvider#registerModels this.singleTexture(\"example_item\", // For 'assets/<modid>/models/item/example_item.json' \"item/generated\", // Set parent to 'minecraft:item/generated' \"layer0\", // For the texture key 'layer0' modLoc(\"item/example_texture\") // Set the reference to 'assets/<modid>/textures/item/example_texture.png' ); Note Item models for blocks should typically parent an existing block model instead of generating a separate model for an item. Block State Provider A BlockStateProvider is responsible for generating block state JSONs in blockstates , block models in models/block , and item models in models/item for said blocks. The provider takes in the data generator, mod id, and existing file helper. Each BlockStateProvider subclass must implement #registerStatesAndModels . The provider contains basic methods for generating block state JSONs and block models. Item models must be generated separately as a block state JSON may define multiple models to use in different contexts. There are a number of common methods, however, that that the modder should be aware of when dealing with more complex tasks: Method Description models Gets the BlockModelProvider used to generate the item block models. itemModels Gets the ItemModelProvider used to generate the item block models. modLoc Creates a ResourceLocation for the path in the given mod id\u2019s namespace. mcLoc Creates a ResourceLocation for the path in the minecraft namespace. blockTexture References a texture within textures/block which has the same name as the block. simpleBlockItem Creates an item model for a block given the associated model file. A block state JSON is made up of variants or conditions. Each variant or condition references a ConfiguredModelList : a list of ConfiguredModel s. Each configured model contains the model file (via ConfiguredModel$Builder#modelFile ), the X and Y rotation in 90 degree intervals (via #rotationX and rotationY respectively), whether the texture can rotate when the model is rotated by the block state JSON (via #uvLock ), and the weight of the model appearing compared to other models in the list (via #weight ). The builder ( ConfiguredModel#builder ) can also create an array of ConfiguredModel s by creating the next model using #nextModel and repeating the settings until #build is called. VariantBlockStateBuilder Variants can be generated using BlockStateProvider#getVariantBuilder . Each variant specifies a list of properties ( PartialBlockstate ) which when matches a BlockState in a level, will display a model chosen from the corresponding model list. An exception is thrown if there is a BlockState which is not covered by any variant defined. Only one variant can be true for any BlockState . A PartialBlockstate is typically defined using one of three methods: Method Description partialState Creates a PartialBlockstate to be defined. forAllStates Defines a function where a given BlockState can be represented by an array of ConfiguredModel s. forAllStatesExcept Defines a function similar to #forAllStates ; however, it also specifies which properties do not affect the models rendered. For a PartialBlockstate , the properties defined can be specified ( #with ). The configured models can be set ( #setModels ), appended to the existing models ( #addModels ), or built ( #modelForState and then ConfiguredModel$Builder#addModel once finished instead of #ConfiguredModel$Builder#build ). // In some BlockStateProvider#registerStatesAndModels // EXAMPLE_BLOCK_1: Has Property BlockStateProperties#AXIS this.getVariantBuilder(EXAMPLE_BLOCK_1) // Get variant builder .partialState() // Construct partial state .with(AXIS, Axis.Y) // When BlockState AXIS = Y .modelForState() // Set models when AXIS = Y .modelFile(yModelFile1) // Can show 'yModelFile1' .nextModel() // Adds another model when AXIS = Y .modelFile(yModelFile2) // Can show 'yModelFile2' .weight(2) // Will show 'yModelFile2' 2/3 of the time .addModel() // Finalizes models when AXIS = Y .with(AXIS, Axis.Z) // When BlockState AXIS = Z .modelForState() // Set models when AXIS = Z .modelFile(hModelFile) // Can show 'hModelFile' .addModel() // Finalizes models when AXIS = Z .with(AXIS, Axis.X) // When BlockState AXIS = X .modelForState() // Set models when AXIS = X .modelFile(hModelFile) // Can show 'hModelFile' .rotationY(90) // Rotates 'hModelFile' 90 degrees on the Y axis .addModel(); // Finalizes models when AXIS = X // EXAMPLE_BLOCK_2: Has Property BlockStateProperties#HORIZONTAL_FACING this.getVariantBuilder(EXAMPLE_BLOCK_2) // Get variant builder .forAllStates(state -> // For all possible states ConfiguredModel.builder() // Creates configured model builder .modelFile(modelFile) // Can show 'modelFile' .rotationY((int) state.getValue(HORIZONTAL_FACING).toYRot()) // Rotates 'modelFile' on the Y axis depending on the property .build() // Creates the array of configured models ); // EXAMPLE_BLOCK_3: Has Properties BlockStateProperties#HORIZONTAL_FACING, BlockStateProperties#WATERLOGGED this.getVariantBuilder(EXAMPLE_BLOCK_3) // Get variant builder .forAllStatesExcept(state -> // For all HORIZONTAL_FACING states ConfiguredModel.builder() // Creates configured model builder .modelFile(modelFile) // Can show 'modelFile' .rotationY((int) state.getValue(HORIZONTAL_FACING).toYRot()) // Rotates 'modelFile' on the Y axis depending on the property .build(), // Creates the array of configured models WATERLOGGED); // Ignores WATERLOGGED property MultiPartBlockStateBuilder Multiparts can be generated using BlockStateProvider#getMultipartBuilder . Each part ( MultiPartBlockStateBuilder#part ) specifies a group of conditions of properties which when matches a BlockState in a level, will display a model from the model list. All condition groups that match the BlockState will display their chosen model overlaid on each other. For any part (obtained via ConfiguredModel$Builder#addModel ), a condition can be added (via #condition ) when a property is one of the specified values. Conditions must all succeed or, when #useOr is set, at least one must succeed. Conditions can be grouped (via #nestedGroup ) as long as the current grouping only contains other groups and no single conditions. Groups of conditions can be left using #endNestedGroup and a given part can be finished via #end . // In some BlockStateProvider#registerStatesAndModels // Redstone Wire this.getMultipartBuilder(REDSTONE) // Get multipart builder .part() // Create part .modelFile(redstoneDot) // Can show 'redstoneDot' .addModel() // 'redstoneDot' is displayed when... .useOr() // At least one of these conditions are true .nestedGroup() // true when all grouped conditions are true .condition(WEST_REDSTONE, NONE) // true when WEST_REDSTONE is NONE .condition(EAST_REDSTONE, NONE) // true when EAST_REDSTONE is NONE .condition(SOUTH_REDSTONE, NONE) // true when SOUTH_REDSTONE is NONE .condition(NORTH_REDSTONE, NONE) // true when NORTH_REDSTONE is NONE .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(EAST_REDSTONE, SIDE, UP) // true when EAST_REDSTONE is SIDE or UP .condition(NORTH_REDSTONE, SIDE, UP) // true when NORTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(EAST_REDSTONE, SIDE, UP) // true when EAST_REDSTONE is SIDE or UP .condition(SOUTH_REDSTONE, SIDE, UP) // true when SOUTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(WEST_REDSTONE, SIDE, UP) // true when WEST_REDSTONE is SIDE or UP .condition(SOUTH_REDSTONE, SIDE, UP) // true when SOUTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(WEST_REDSTONE, SIDE, UP) // true when WEST_REDSTONE is SIDE or UP .condition(NORTH_REDSTONE, SIDE, UP) // true when NORTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .end() // Finish part .part() // Create part .modelFile(redstoneSide0) // Can show 'redstoneSide0' .addModel() // 'redstoneSide0' is displayed when... .condition(NORTH_REDSTONE, SIDE, UP) // NORTH_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneSideAlt0) // Can show 'redstoneSideAlt0' .addModel() // 'redstoneSideAlt0' is displayed when... .condition(SOUTH_REDSTONE, SIDE, UP) // SOUTH_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneSideAlt1) // Can show 'redstoneSideAlt1' .rotationY(270) // Rotates 'redstoneSideAlt1' 270 degrees on the Y axis .addModel() // 'redstoneSideAlt1' is displayed when... .condition(EAST_REDSTONE, SIDE, UP) // EAST_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneSide1) // Can show 'redstoneSide1' .rotationY(270) // Rotates 'redstoneSide1' 270 degrees on the Y axis .addModel() // 'redstoneSide1' is displayed when... .condition(WEST_REDSTONE, SIDE, UP) // WEST_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .addModel() // 'redstoneUp' is displayed when... .condition(NORTH_REDSTONE, UP) // NORTH_REDSTONE is UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .rotationY(90) // Rotates 'redstoneUp' 90 degrees on the Y axis .addModel() // 'redstoneUp' is displayed when... .condition(EAST_REDSTONE, UP) // EAST_REDSTONE is UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .rotationY(180) // Rotates 'redstoneUp' 180 degrees on the Y axis .addModel() // 'redstoneUp' is displayed when... .condition(SOUTH_REDSTONE, UP) // SOUTH_REDSTONE is UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .rotationY(270) // Rotates 'redstoneUp' 270 degrees on the Y axis .addModel() // 'redstoneUp' is displayed when... .condition(WEST_REDSTONE, UP) // WEST_REDSTONE is UP .end(); // Finish part Model Loader Builders Custom model loaders can also be generated for a given ModelBuilder . Custom model loaders subclass CustomLoaderBuilder and can be applied to a ModelBuilder via #customLoader . The factory method passed in creates a new loader builder to which configurations can be made. After all the changes have been finished, the custom loader can return back to the ModelBuilder via CustomLoaderBuilder#end . Model Builder Factory Method Description DynamicBucketModelBuilder #begin Generates a bucket model for the specified fluid. CompositeModelBuilder #begin Generates a model composed of models. ItemLayersModelBuilder #begin Generates a Forge implementation of an item/generated model. SeparatePerspectiveModelBuilder #begin Generates a model which changes based on the specified perspective . OBJLoaderBuilder #begin Generates an OBJ model . MultiLayerModelBuilder #begin Generates a model made up of models in different rendering layers. // For some BlockModelBuilder builder builder.customLoader(OBJLoaderBuilder::begin) // Custom loader 'forge:obj' .modelLocation(modLoc(\"models/block/model.obj\")) // Set the OBJ model location .flipV(true) // Flips the V coordinate in the supplied .mtl texture .end() // Finish custom loader configuration .texture(\"particle\", mcLoc(\"block/dirt\")) // Set particle texture to dirt .texture(\"texture0\", mcLoc(\"block/dirt\")); // Set 'texture0' texture to dirt Custom Model Loader Builders Custom loader builders can be created by extending CustomLoaderBuilder . The constructor can still have a protected visibility with the ResourceLocation hardcoded to the loader id registered via ModelLoaderRegistry#registerLoader . The builder can then be initialized via a static factory method or the constructor if made public . public class ExampleLoaderBuilder<T extends ModelBuilder<T>> extends CustomLoaderBuilder<T> { public static <T extends ModelBuilder<T>> ExampleLoaderBuilder<T> begin(T parent, ExistingFileHelper existingFileHelper) { return new ExampleLoaderBuilder<>(parent, existingFileHelper); } protected ExampleLoaderBuilder(T parent, ExistingFileHelper existingFileHelper) { super(new ResourceLocation(MOD_ID, \"example_loader\"), parent, existingFileHelper); } } Afterwards, any configurations specified by the loader should be added as chainable methods. // In ExampleLoaderBuilder public ExampleLoaderBuilder<T> exampleInt(int example) { // Set int return this; } public ExampleLoaderBuilder<T> exampleString(String example) { // Set string return this; } If any additional configuration is specified, #toJson should be overridden to write the additional properties. // In ExampleLoaderBuilder @Override public JsonObject toJson(JsonObject json) { json = super.toJson(json); // Handle base loader properties // Encode custom loader properties return json; } Custom Model Providers Custom model providers require a ModelBuilder subclass, which defines the base of the model to generate, and a ModelProvider subclass, which generates the models. The ModelBuilder subclass contains any special properties to which can be applied specifically to those types of models (item models can have overrides). If any additional properties are added, #toJson needs to be overridden to write the additional information. public class ExampleModelBuilder extends ModelBuilder<ExampleModelBuilder> { // ... } The ModelProvider subclass requires no special logic. The constructor should hardcode the subdirectory within the models folder and the ModelBuilder to represent the to-be-generated models. public class ExampleModelProvider extends ModelProvider<ExampleModelBuilder> { public ExampleModelProvider(DataGenerator generator, String modid, ExistingFileHelper existingFileHelper) { // Models will be generated to 'assets/<modid>/models/example' if no modid is specified in '#getBuilder' super(generator, modid, \"example\", ExampleModelBuilder::new, existingFileHelper); } } Custom Model Consumers Custom model consumers like BlockStateProvider can be created by manually generating the models themselves. The ModelProvider subclass used to generate the models should be specified and made available. public class ExampleModelConsumerProvider implements IDataProvider { public ExampleModelConsumerProvider(DataGenerator generator, String modid, ExistingFileHelper existingFileHelper) { this.example = new ExampleModelProvider(generator, modid, existingFileHelper); } } Once the data provider is running, the models within the ModelProvider subclass can be generated using ModelProvider#generateAll . // In ExampleModelConsumerProvider @Override public void run(HashCache cache) throws IOException { // Populate the model provider this.example.generateAll(cache); // Generate the models // ... }","title":"Model Providers"},{"location":"datagen/client/modelproviders/#model-generation","text":"Models can be generated for models or block states by default. Each provides a method of generating the necessary JSONs ( ModelBuilder#toJson for models and IGeneratedBlockState#toJson for block states). After implementation, the associated providers must be added to the DataGenerator .","title":"Model Generation"},{"location":"datagen/client/modelproviders/#model-files","text":"A ModelFile acts as the base for all models referenced or generated by a provider. Each model file stores the location relative to the models subdirectory and can assert whether the file exists.","title":"Model Files"},{"location":"datagen/client/modelproviders/#existing-model-files","text":"ExistingModelFile is a subclass of ModelFile which checks via ExistingFileHelper#exists whether the model already exists within the models subdirectory. All non-generated models are usually referenced through ExistingModelFile s.","title":"Existing Model Files"},{"location":"datagen/client/modelproviders/#unchecked-model-files","text":"UncheckedModelFile is a subclass of ModelFile which assumes the specified model exists in some location. Note There should be no cases where an UncheckedModelFile is used to reference a model. If there is, then the associated resources are not properly being tracked by ExistingFileHelper .","title":"Unchecked Model Files"},{"location":"datagen/client/modelproviders/#model-builders","text":"A ModelBuilder represents a to-be-generated ModelFile . It contains all the data about a model: its parent, faces, textures, transformations, lighting, and loader . Tip While a complex model can be generated, it is recommended that those models be constructed using a modeling software beforehand. Then, the data provider can generate the children models with specific textures applied through the defined references in the parent complex model. The parent (via ModelBuilder#parent ) of the builder can be any ModelFile : generated or existing. Generated files are added to ModelProvider s as soon as the builder is created. The builder itself can be passed in as a parent, or the ResourceLocation can supplied alternatively. Warning If the parent is not generated before the child model when passing in a ResourceLocation , then an exception will be thrown. Each element (via ModelBuilder#element ) within a model is defined as cube using two three-dimensional points ( ElementBuilder#from and #to respectively) where each axis is limited to the values [-16,32] (between -16 and 32 inclusive). Each face ( ElementBuilder#face ) of the cube can specify when the face is culled ( FaceBuilder#cullface ), tint index ( FaceBuilder#tintindex ), texture reference from the textures keys ( FaceBuilder#texture ), UV coordinate on the texture ( FaceBuilder#uvs ), and rotation in 90 degree intervals ( FaceBuilder#rotation ). Note It recommended for block models which have elements that exceed a bound of [0,16] on any axis to separate into multiple blocks, such as for a multiblock structure, to avoid lighting and culling issues. Each cube can additionally be rotated ( ElementBuilder#rotation ) around a specified point ( RotationBuilder#origin ) for a given axis ( RotationBuilder#axis ) in 22.5 degree intervals ( RotationBuilder#angle ). The cube can scale all faces in relation to the entire model as well ( RotationBuilder#rescale ). The cube can also determine whether its shadows should be rendered ( ElementBuilder#shade ). Each model defines a list of texture keys ( ModelBuilder#texture ) which points to either a location or a reference. Each key can then be referenced in any element by prefixing using a # (a texture key of example can be referenced in an element using #example ). A location specifies where a texture is in assets/<namespace>/textures/<path>.png . A reference is used by any models parenting the current model as keys to define textures for later. The model can additionally be transformed ( ModelBuilder#transforms ) for any defined perspective (in the left hand in first person, in the gui, on the ground, etc.). For any perspective ( TransformsBuilder#transform ), the rotation ( TransformVecBuilder#rotation ), translation ( TransformVecBuilder#translation ), and scale ( TransformVecBuilder#scale ) can be set. Finally, the model can set whether to use ambient occlusion in a level ( ModelBuilder#ao ) and from what location to light and shade the model from ModelBuilder#guiLight .","title":"Model Builders"},{"location":"datagen/client/modelproviders/#blockmodelbuilder","text":"A BlockModelBuilder represents a block model to-be-generated. There is no additional functionality compared to a ModelBuilder .","title":"BlockModelBuilder"},{"location":"datagen/client/modelproviders/#itemmodelbuilder","text":"An ItemModelBuilder represents an item model to-be-generated. In addition to the ModelBuilder , overrides ( OverrideBuilder#override ) can be generated. Each override applied to a model can apply conditions which represent for a given property that must be above the specified value ( OverrideBuilder#predicate ). If the conditions are met, then the specified model ( OverrideBuilder#model ) will be rendered instead of this model.","title":"ItemModelBuilder"},{"location":"datagen/client/modelproviders/#model-providers","text":"The ModelProvider subclasses are responsible for generating the constructed ModelBuilder s. The provider takes in the generator, mod id, subdirectory in the models folder to generate within, a ModelBuilder factory, and the existing file helper. Each provider subclass must implement #registerModels . The provider contains basic methods which either create the ModelBuilder or provides convenience for getting texture or model references: Method Description getBuilder Creates a new ModelBuilder within the provider\u2019s subdirectory for the given mod id. withExistingParent Creates a new ModelBuilder for the given parent. Should be used when the parent is not generated by the builder. mcLoc Creates a ResourceLocation for the path in the minecraft namespace. modLoc Creates a ResourceLocation for the path in the given mod id\u2019s namespace. Additionally, there are several helpers for easily generating common models using vanilla templates. Most are for block models with only a few being universal. Note Although the models are within a specific subdirectory, that does not mean that the model cannot be referenced by a model in another subdirectory. Usually, it is indicative of that model being used for that type of object.","title":"Model Providers"},{"location":"datagen/client/modelproviders/#blockmodelprovider","text":"The BlockModelProvider is used for generating block models via BlockModelBuilder in the block folder. Block models should typically parent minecraft:block/block or one of its children models for use with item models. Note Block models and its item model counterpart are typically not generated through a direct subclass of BlockModelProvider and ItemModelProvider but through BlockStateProvider .","title":"BlockModelProvider"},{"location":"datagen/client/modelproviders/#itemmodelprovider","text":"The ItemModelProvider is used for generating block models via ItemModelBuilder in the item folder. Most item models parent item/generated and use layer0 to specify their texture, which can be done using #singleTexture . Note item/generated can support five texture layers stacked on top of each other: layer0 , layer1 , layer2 , layer3 , and layer4 . // In some ItemModelProvider#registerModels this.singleTexture(\"example_item\", // For 'assets/<modid>/models/item/example_item.json' \"item/generated\", // Set parent to 'minecraft:item/generated' \"layer0\", // For the texture key 'layer0' modLoc(\"item/example_texture\") // Set the reference to 'assets/<modid>/textures/item/example_texture.png' ); Note Item models for blocks should typically parent an existing block model instead of generating a separate model for an item.","title":"ItemModelProvider"},{"location":"datagen/client/modelproviders/#block-state-provider","text":"A BlockStateProvider is responsible for generating block state JSONs in blockstates , block models in models/block , and item models in models/item for said blocks. The provider takes in the data generator, mod id, and existing file helper. Each BlockStateProvider subclass must implement #registerStatesAndModels . The provider contains basic methods for generating block state JSONs and block models. Item models must be generated separately as a block state JSON may define multiple models to use in different contexts. There are a number of common methods, however, that that the modder should be aware of when dealing with more complex tasks: Method Description models Gets the BlockModelProvider used to generate the item block models. itemModels Gets the ItemModelProvider used to generate the item block models. modLoc Creates a ResourceLocation for the path in the given mod id\u2019s namespace. mcLoc Creates a ResourceLocation for the path in the minecraft namespace. blockTexture References a texture within textures/block which has the same name as the block. simpleBlockItem Creates an item model for a block given the associated model file. A block state JSON is made up of variants or conditions. Each variant or condition references a ConfiguredModelList : a list of ConfiguredModel s. Each configured model contains the model file (via ConfiguredModel$Builder#modelFile ), the X and Y rotation in 90 degree intervals (via #rotationX and rotationY respectively), whether the texture can rotate when the model is rotated by the block state JSON (via #uvLock ), and the weight of the model appearing compared to other models in the list (via #weight ). The builder ( ConfiguredModel#builder ) can also create an array of ConfiguredModel s by creating the next model using #nextModel and repeating the settings until #build is called.","title":"Block State Provider"},{"location":"datagen/client/modelproviders/#variantblockstatebuilder","text":"Variants can be generated using BlockStateProvider#getVariantBuilder . Each variant specifies a list of properties ( PartialBlockstate ) which when matches a BlockState in a level, will display a model chosen from the corresponding model list. An exception is thrown if there is a BlockState which is not covered by any variant defined. Only one variant can be true for any BlockState . A PartialBlockstate is typically defined using one of three methods: Method Description partialState Creates a PartialBlockstate to be defined. forAllStates Defines a function where a given BlockState can be represented by an array of ConfiguredModel s. forAllStatesExcept Defines a function similar to #forAllStates ; however, it also specifies which properties do not affect the models rendered. For a PartialBlockstate , the properties defined can be specified ( #with ). The configured models can be set ( #setModels ), appended to the existing models ( #addModels ), or built ( #modelForState and then ConfiguredModel$Builder#addModel once finished instead of #ConfiguredModel$Builder#build ). // In some BlockStateProvider#registerStatesAndModels // EXAMPLE_BLOCK_1: Has Property BlockStateProperties#AXIS this.getVariantBuilder(EXAMPLE_BLOCK_1) // Get variant builder .partialState() // Construct partial state .with(AXIS, Axis.Y) // When BlockState AXIS = Y .modelForState() // Set models when AXIS = Y .modelFile(yModelFile1) // Can show 'yModelFile1' .nextModel() // Adds another model when AXIS = Y .modelFile(yModelFile2) // Can show 'yModelFile2' .weight(2) // Will show 'yModelFile2' 2/3 of the time .addModel() // Finalizes models when AXIS = Y .with(AXIS, Axis.Z) // When BlockState AXIS = Z .modelForState() // Set models when AXIS = Z .modelFile(hModelFile) // Can show 'hModelFile' .addModel() // Finalizes models when AXIS = Z .with(AXIS, Axis.X) // When BlockState AXIS = X .modelForState() // Set models when AXIS = X .modelFile(hModelFile) // Can show 'hModelFile' .rotationY(90) // Rotates 'hModelFile' 90 degrees on the Y axis .addModel(); // Finalizes models when AXIS = X // EXAMPLE_BLOCK_2: Has Property BlockStateProperties#HORIZONTAL_FACING this.getVariantBuilder(EXAMPLE_BLOCK_2) // Get variant builder .forAllStates(state -> // For all possible states ConfiguredModel.builder() // Creates configured model builder .modelFile(modelFile) // Can show 'modelFile' .rotationY((int) state.getValue(HORIZONTAL_FACING).toYRot()) // Rotates 'modelFile' on the Y axis depending on the property .build() // Creates the array of configured models ); // EXAMPLE_BLOCK_3: Has Properties BlockStateProperties#HORIZONTAL_FACING, BlockStateProperties#WATERLOGGED this.getVariantBuilder(EXAMPLE_BLOCK_3) // Get variant builder .forAllStatesExcept(state -> // For all HORIZONTAL_FACING states ConfiguredModel.builder() // Creates configured model builder .modelFile(modelFile) // Can show 'modelFile' .rotationY((int) state.getValue(HORIZONTAL_FACING).toYRot()) // Rotates 'modelFile' on the Y axis depending on the property .build(), // Creates the array of configured models WATERLOGGED); // Ignores WATERLOGGED property","title":"VariantBlockStateBuilder"},{"location":"datagen/client/modelproviders/#multipartblockstatebuilder","text":"Multiparts can be generated using BlockStateProvider#getMultipartBuilder . Each part ( MultiPartBlockStateBuilder#part ) specifies a group of conditions of properties which when matches a BlockState in a level, will display a model from the model list. All condition groups that match the BlockState will display their chosen model overlaid on each other. For any part (obtained via ConfiguredModel$Builder#addModel ), a condition can be added (via #condition ) when a property is one of the specified values. Conditions must all succeed or, when #useOr is set, at least one must succeed. Conditions can be grouped (via #nestedGroup ) as long as the current grouping only contains other groups and no single conditions. Groups of conditions can be left using #endNestedGroup and a given part can be finished via #end . // In some BlockStateProvider#registerStatesAndModels // Redstone Wire this.getMultipartBuilder(REDSTONE) // Get multipart builder .part() // Create part .modelFile(redstoneDot) // Can show 'redstoneDot' .addModel() // 'redstoneDot' is displayed when... .useOr() // At least one of these conditions are true .nestedGroup() // true when all grouped conditions are true .condition(WEST_REDSTONE, NONE) // true when WEST_REDSTONE is NONE .condition(EAST_REDSTONE, NONE) // true when EAST_REDSTONE is NONE .condition(SOUTH_REDSTONE, NONE) // true when SOUTH_REDSTONE is NONE .condition(NORTH_REDSTONE, NONE) // true when NORTH_REDSTONE is NONE .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(EAST_REDSTONE, SIDE, UP) // true when EAST_REDSTONE is SIDE or UP .condition(NORTH_REDSTONE, SIDE, UP) // true when NORTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(EAST_REDSTONE, SIDE, UP) // true when EAST_REDSTONE is SIDE or UP .condition(SOUTH_REDSTONE, SIDE, UP) // true when SOUTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(WEST_REDSTONE, SIDE, UP) // true when WEST_REDSTONE is SIDE or UP .condition(SOUTH_REDSTONE, SIDE, UP) // true when SOUTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .nestedGroup() // true when all grouped conditions are true .condition(WEST_REDSTONE, SIDE, UP) // true when WEST_REDSTONE is SIDE or UP .condition(NORTH_REDSTONE, SIDE, UP) // true when NORTH_REDSTONE is SIDE or UP .endNestedGroup() // End group .end() // Finish part .part() // Create part .modelFile(redstoneSide0) // Can show 'redstoneSide0' .addModel() // 'redstoneSide0' is displayed when... .condition(NORTH_REDSTONE, SIDE, UP) // NORTH_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneSideAlt0) // Can show 'redstoneSideAlt0' .addModel() // 'redstoneSideAlt0' is displayed when... .condition(SOUTH_REDSTONE, SIDE, UP) // SOUTH_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneSideAlt1) // Can show 'redstoneSideAlt1' .rotationY(270) // Rotates 'redstoneSideAlt1' 270 degrees on the Y axis .addModel() // 'redstoneSideAlt1' is displayed when... .condition(EAST_REDSTONE, SIDE, UP) // EAST_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneSide1) // Can show 'redstoneSide1' .rotationY(270) // Rotates 'redstoneSide1' 270 degrees on the Y axis .addModel() // 'redstoneSide1' is displayed when... .condition(WEST_REDSTONE, SIDE, UP) // WEST_REDSTONE is SIDE or UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .addModel() // 'redstoneUp' is displayed when... .condition(NORTH_REDSTONE, UP) // NORTH_REDSTONE is UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .rotationY(90) // Rotates 'redstoneUp' 90 degrees on the Y axis .addModel() // 'redstoneUp' is displayed when... .condition(EAST_REDSTONE, UP) // EAST_REDSTONE is UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .rotationY(180) // Rotates 'redstoneUp' 180 degrees on the Y axis .addModel() // 'redstoneUp' is displayed when... .condition(SOUTH_REDSTONE, UP) // SOUTH_REDSTONE is UP .end() // Finish part .part() // Create part .modelFile(redstoneUp) // Can show 'redstoneUp' .rotationY(270) // Rotates 'redstoneUp' 270 degrees on the Y axis .addModel() // 'redstoneUp' is displayed when... .condition(WEST_REDSTONE, UP) // WEST_REDSTONE is UP .end(); // Finish part","title":"MultiPartBlockStateBuilder"},{"location":"datagen/client/modelproviders/#model-loader-builders","text":"Custom model loaders can also be generated for a given ModelBuilder . Custom model loaders subclass CustomLoaderBuilder and can be applied to a ModelBuilder via #customLoader . The factory method passed in creates a new loader builder to which configurations can be made. After all the changes have been finished, the custom loader can return back to the ModelBuilder via CustomLoaderBuilder#end . Model Builder Factory Method Description DynamicBucketModelBuilder #begin Generates a bucket model for the specified fluid. CompositeModelBuilder #begin Generates a model composed of models. ItemLayersModelBuilder #begin Generates a Forge implementation of an item/generated model. SeparatePerspectiveModelBuilder #begin Generates a model which changes based on the specified perspective . OBJLoaderBuilder #begin Generates an OBJ model . MultiLayerModelBuilder #begin Generates a model made up of models in different rendering layers. // For some BlockModelBuilder builder builder.customLoader(OBJLoaderBuilder::begin) // Custom loader 'forge:obj' .modelLocation(modLoc(\"models/block/model.obj\")) // Set the OBJ model location .flipV(true) // Flips the V coordinate in the supplied .mtl texture .end() // Finish custom loader configuration .texture(\"particle\", mcLoc(\"block/dirt\")) // Set particle texture to dirt .texture(\"texture0\", mcLoc(\"block/dirt\")); // Set 'texture0' texture to dirt","title":"Model Loader Builders"},{"location":"datagen/client/modelproviders/#custom-model-loader-builders","text":"Custom loader builders can be created by extending CustomLoaderBuilder . The constructor can still have a protected visibility with the ResourceLocation hardcoded to the loader id registered via ModelLoaderRegistry#registerLoader . The builder can then be initialized via a static factory method or the constructor if made public . public class ExampleLoaderBuilder<T extends ModelBuilder<T>> extends CustomLoaderBuilder<T> { public static <T extends ModelBuilder<T>> ExampleLoaderBuilder<T> begin(T parent, ExistingFileHelper existingFileHelper) { return new ExampleLoaderBuilder<>(parent, existingFileHelper); } protected ExampleLoaderBuilder(T parent, ExistingFileHelper existingFileHelper) { super(new ResourceLocation(MOD_ID, \"example_loader\"), parent, existingFileHelper); } } Afterwards, any configurations specified by the loader should be added as chainable methods. // In ExampleLoaderBuilder public ExampleLoaderBuilder<T> exampleInt(int example) { // Set int return this; } public ExampleLoaderBuilder<T> exampleString(String example) { // Set string return this; } If any additional configuration is specified, #toJson should be overridden to write the additional properties. // In ExampleLoaderBuilder @Override public JsonObject toJson(JsonObject json) { json = super.toJson(json); // Handle base loader properties // Encode custom loader properties return json; }","title":"Custom Model Loader Builders"},{"location":"datagen/client/modelproviders/#custom-model-providers","text":"Custom model providers require a ModelBuilder subclass, which defines the base of the model to generate, and a ModelProvider subclass, which generates the models. The ModelBuilder subclass contains any special properties to which can be applied specifically to those types of models (item models can have overrides). If any additional properties are added, #toJson needs to be overridden to write the additional information. public class ExampleModelBuilder extends ModelBuilder<ExampleModelBuilder> { // ... } The ModelProvider subclass requires no special logic. The constructor should hardcode the subdirectory within the models folder and the ModelBuilder to represent the to-be-generated models. public class ExampleModelProvider extends ModelProvider<ExampleModelBuilder> { public ExampleModelProvider(DataGenerator generator, String modid, ExistingFileHelper existingFileHelper) { // Models will be generated to 'assets/<modid>/models/example' if no modid is specified in '#getBuilder' super(generator, modid, \"example\", ExampleModelBuilder::new, existingFileHelper); } }","title":"Custom Model Providers"},{"location":"datagen/client/modelproviders/#custom-model-consumers","text":"Custom model consumers like BlockStateProvider can be created by manually generating the models themselves. The ModelProvider subclass used to generate the models should be specified and made available. public class ExampleModelConsumerProvider implements IDataProvider { public ExampleModelConsumerProvider(DataGenerator generator, String modid, ExistingFileHelper existingFileHelper) { this.example = new ExampleModelProvider(generator, modid, existingFileHelper); } } Once the data provider is running, the models within the ModelProvider subclass can be generated using ModelProvider#generateAll . // In ExampleModelConsumerProvider @Override public void run(HashCache cache) throws IOException { // Populate the model provider this.example.generateAll(cache); // Generate the models // ... }","title":"Custom Model Consumers"},{"location":"datagen/client/sounds/","text":"Sound Definition Generation The sounds.json file can be generated for a mod by subclassing SoundDefinitionsProvider and implementing #registerSounds . After implementation, the provider must be added to the DataGenerator . Adding a Sound A sound definition can be generated by specifying the sound name and definition via #add . The sound name can either be provided from a SoundEvent , ResourceLocation , or string. Warning The sound name supplied will always assume the namespace is the mod id supplied to the constructor of the provider. There is no validation performed on the namespace of the sound name! SoundDefinition The SoundDefinition can be created using #definition . The definition contains the data to define a sound instance. A definition specifies a few methods: Method Description with Adds a sound(s) which may be played when the definition is selected. subtitle Sets the translation key of the definition. replace When true , removes the sounds already defined by other sounds.json for this definition instead of appending to it. SoundDefinition$Sound A sound supplied to the SoundDefinition can be specified using SoundDefinitionsProvider#sound . These methods take in the reference of the sound and a SoundType if specified. The SoundType can be one of two values: Sound Type Definition SOUND Specifies a reference to the sound located at assets/<namespace>/sounds/<path>.ogg . EVENT Specifies a reference to the name of another sound defined by the sounds.json . Each Sound created from SoundDefinitionsProvider#sound can specify additional configurations on how to load and play the sound provided: Method Description volume Sets the volume scale of the sound, must be greater than 0 . pitch Sets the pitch scale of the sound, must be greater than 0 . weight Sets the likelihood of the sound getting played when the sound is selected. stream When true , reads the sound from file instead of loading the sound into memory. Recommended for long sounds: background music, music discs, etc. attenuationDistance Sets the number of blocks the sound can be heard from. preload When true , immediately loads the sound into memory as soon as the resource pack is loaded. // In some SoundDefinitionsProvider#registerSounds this.add(EXAMPLE_SOUND_EVENT, definition() .subtitle(\"sound.examplemod.example_sound\") // Set translation key .with( sound(new ResourceLocation(MODID, \"example_sound_1\")) // Set first sound .weight(4) // Has a 4 / 5 = 80% chance of playing .volume(0.5), // Scales all volumes called on this sound by half sound(new ResourceLocation(MODID, \"example_sound_2\")) // Set second sound .stream() // Streams the sound ) ); this.add(EXAMPLE_SOUND_EVENT_2, definition() .subtitle(\"sound.examplemod.example_sound\") // Set translation key .with( sound(EXAMPLE_SOUND_EVENT.getLocation(), SoundType.EVENT) // Adds sounds from 'EXAMPLE_SOUND_EVENT' .pitch(0.5) // Scales all pitches called on this sound by half ) );","title":"Sound Providers"},{"location":"datagen/client/sounds/#sound-definition-generation","text":"The sounds.json file can be generated for a mod by subclassing SoundDefinitionsProvider and implementing #registerSounds . After implementation, the provider must be added to the DataGenerator .","title":"Sound Definition Generation"},{"location":"datagen/client/sounds/#adding-a-sound","text":"A sound definition can be generated by specifying the sound name and definition via #add . The sound name can either be provided from a SoundEvent , ResourceLocation , or string. Warning The sound name supplied will always assume the namespace is the mod id supplied to the constructor of the provider. There is no validation performed on the namespace of the sound name!","title":"Adding a Sound"},{"location":"datagen/client/sounds/#sounddefinition","text":"The SoundDefinition can be created using #definition . The definition contains the data to define a sound instance. A definition specifies a few methods: Method Description with Adds a sound(s) which may be played when the definition is selected. subtitle Sets the translation key of the definition. replace When true , removes the sounds already defined by other sounds.json for this definition instead of appending to it.","title":"SoundDefinition"},{"location":"datagen/client/sounds/#sounddefinitionsound","text":"A sound supplied to the SoundDefinition can be specified using SoundDefinitionsProvider#sound . These methods take in the reference of the sound and a SoundType if specified. The SoundType can be one of two values: Sound Type Definition SOUND Specifies a reference to the sound located at assets/<namespace>/sounds/<path>.ogg . EVENT Specifies a reference to the name of another sound defined by the sounds.json . Each Sound created from SoundDefinitionsProvider#sound can specify additional configurations on how to load and play the sound provided: Method Description volume Sets the volume scale of the sound, must be greater than 0 . pitch Sets the pitch scale of the sound, must be greater than 0 . weight Sets the likelihood of the sound getting played when the sound is selected. stream When true , reads the sound from file instead of loading the sound into memory. Recommended for long sounds: background music, music discs, etc. attenuationDistance Sets the number of blocks the sound can be heard from. preload When true , immediately loads the sound into memory as soon as the resource pack is loaded. // In some SoundDefinitionsProvider#registerSounds this.add(EXAMPLE_SOUND_EVENT, definition() .subtitle(\"sound.examplemod.example_sound\") // Set translation key .with( sound(new ResourceLocation(MODID, \"example_sound_1\")) // Set first sound .weight(4) // Has a 4 / 5 = 80% chance of playing .volume(0.5), // Scales all volumes called on this sound by half sound(new ResourceLocation(MODID, \"example_sound_2\")) // Set second sound .stream() // Streams the sound ) ); this.add(EXAMPLE_SOUND_EVENT_2, definition() .subtitle(\"sound.examplemod.example_sound\") // Set translation key .with( sound(EXAMPLE_SOUND_EVENT.getLocation(), SoundType.EVENT) // Adds sounds from 'EXAMPLE_SOUND_EVENT' .pitch(0.5) // Scales all pitches called on this sound by half ) );","title":"SoundDefinition$Sound"},{"location":"datagen/server/advancements/","text":"Advancement Generation Advancements can be generated for a mod by subclassing AdvancementProvider and overriding #registerAdvancements . Advancements can either be created and supplied manually or, for convenience, created using Advancement$Builder . After implementation, the provider must be added to the DataGenerator . Advancement$Builder Advancement$Builder is a convenience implementation for creating Advancement s to generate. It allows the definition of the parent advancement, the display information, the rewards when the advancement has been completed, and the requirements to unlock the advancement. Only the requirements need to be specified to create an Advancement . Although not required, there are a number of methods that are important to know of: Method Description parent Sets the advancement which this advancement is directly linked to. Can either specify the name of the advancement or the advancement itself if its generated by the modder. display Sets the information to display to the chat, toast, and advancement screen. rewards Sets the rewards obtained when this advancement is completed. addCriterion Adds a condition to the advancement. requirements Specifies if the conditions must all return true or at least one must return true. An additional overload can be used to mix-and-match those operations. Once an Advancement$Builder is ready to be built, the #save method should be called which takes in the writer, the registry name of the advancement, and the file helper used to check whether the supplied parent exists. // In AdvancementProvider#registerAdvancements(writer, fileHelper) Advancement example = Advancement.Builder.advancement() .addCriterion(\"example_criterion\", triggerInstance) // How the advancement is unlocked .save(writer, name, fileHelper); // Add data to builder }","title":"Advancement Providers"},{"location":"datagen/server/advancements/#advancement-generation","text":"Advancements can be generated for a mod by subclassing AdvancementProvider and overriding #registerAdvancements . Advancements can either be created and supplied manually or, for convenience, created using Advancement$Builder . After implementation, the provider must be added to the DataGenerator .","title":"Advancement Generation"},{"location":"datagen/server/advancements/#advancementbuilder","text":"Advancement$Builder is a convenience implementation for creating Advancement s to generate. It allows the definition of the parent advancement, the display information, the rewards when the advancement has been completed, and the requirements to unlock the advancement. Only the requirements need to be specified to create an Advancement . Although not required, there are a number of methods that are important to know of: Method Description parent Sets the advancement which this advancement is directly linked to. Can either specify the name of the advancement or the advancement itself if its generated by the modder. display Sets the information to display to the chat, toast, and advancement screen. rewards Sets the rewards obtained when this advancement is completed. addCriterion Adds a condition to the advancement. requirements Specifies if the conditions must all return true or at least one must return true. An additional overload can be used to mix-and-match those operations. Once an Advancement$Builder is ready to be built, the #save method should be called which takes in the writer, the registry name of the advancement, and the file helper used to check whether the supplied parent exists. // In AdvancementProvider#registerAdvancements(writer, fileHelper) Advancement example = Advancement.Builder.advancement() .addCriterion(\"example_criterion\", triggerInstance) // How the advancement is unlocked .save(writer, name, fileHelper); // Add data to builder }","title":"Advancement$Builder"},{"location":"datagen/server/glm/","text":"Global Loot Modifier Generation Global Loot Modifiers (GLMs) can be generated for a mod by subclassing GlobalLootModifierProvider and implementing #start . Each GLM can be added generated by calling #add and specifying the name of the modifier, the serializer of the modifier , and the modifier instance to be serialized. After implementation, the provider must be added to the DataGenerator . // In some GlobalLootModifierProvider#start this.add(\"example_modifier\", EXAMPLE_MODIFIER_SERIALIZER, new ExampleModifier( new LootItemCondition[] { WeatherCheck.weather().setRaining(true).build() // Executes when raining }, \"val1\", 10, Items.DIRT ));","title":"Global Loot Modifier Providers"},{"location":"datagen/server/glm/#global-loot-modifier-generation","text":"Global Loot Modifiers (GLMs) can be generated for a mod by subclassing GlobalLootModifierProvider and implementing #start . Each GLM can be added generated by calling #add and specifying the name of the modifier, the serializer of the modifier , and the modifier instance to be serialized. After implementation, the provider must be added to the DataGenerator . // In some GlobalLootModifierProvider#start this.add(\"example_modifier\", EXAMPLE_MODIFIER_SERIALIZER, new ExampleModifier( new LootItemCondition[] { WeatherCheck.weather().setRaining(true).build() // Executes when raining }, \"val1\", 10, Items.DIRT ));","title":"Global Loot Modifier Generation"},{"location":"datagen/server/loottables/","text":"Loot Table Generation Loot tables can be generated for a mod by subclassing LootTableProvider with a few modifications. After implementation, the provider must be added to the DataGenerator . The LootTableProvider Subclass LootTableProvider is simplified into two methods: #getTables , which collect the table builders, and #validate , which checks whether the generated loot tables are valid. Both of these methods need to be overridden to use LootTableProvider . #validate can be simplified to call LootTables#validate for every single table. It initially fails since it expects the tables defined within BuiltInLootTables to be generated as well. // In some LootTableProvider subclass @Override protected void validate(Map<ResourceLocation, LootTable> tables, ValidationContext ctx) { tables.forEach((name, table) -> LootTables.validate(ctx, name, table)); } #getTables defines a list of factory methods for table builders for a given LootContextParamSet . Each table builder consumes a writer used to generate the given table for a specific name. To simplify understanding: // In some LootTableProvider subclass @Override protected List< // Get a list Pair< // of pairs Supplier< // for a factory Consumer< // which takes in BiConsumer< // a writer of ResourceLocation, // the name of the table LootTable.Builder // and the table to generate > > >, LootContextParamSet // with a given parameter set > > getTables() { // Return table builders here } Table Builders Each table builder has a method which takes in the writer to generate a table. This is typically done implementing a Consumer<BiConsumer<ResourceLocation, LootTable.Builder>> . public class ExampleLoot implements Consumer<BiConsumer<ResourceLocation, LootTable.Builder>> { // Used to create a factory method for the wrapping Supplier public ExampleLoot() {} // The method used to generate the loot tables @Override public void accept(BiConsumer<ResourceLocation, LootTable.Builder> writer) { // Generate loot tables here by calling writer#accept } } The table can then be added to LootTableProvider#getTables for any available LootContextParamSet : // In some LootTableProvider subclass @Override protected List<Pair<Supplier<Consumer<BiConsumer<ResourceLocation, LootTable.Builder>>>, LootContextParamSet>> getTables() { return ImmutableList.of( Pair.of(ExampleLoot::new, LootContextParamSets.EMPTY) // Loot table builder for the 'empty' parameter set //... ); } BlockLoot and EntityLoot Subclasses For LootContextParamSets#BLOCK and #ENTITY , there are special types ( BlockLoot and EntityLoot respectively) which provide additional helper methods for creating and validating that there are loot tables. To use them, all registered objects must be supplied to either BlockLoot#getKnownBlocks and EntityLoot#getKnownEntities respectively. These methods are to make sure all objects within the iterable has a loot table. Tip If DeferredRegister is being used to register a mod\u2019s objects, then the #getKnown* methods can be supplied the entries via DeferredRegister#getEntities : // In some BlockLoot subclass for some DeferredRegister BLOCK_REGISTRAR @Override protected Iterable<Block> getKnownBlocks() { return BLOCK_REGISTRAR.getEntries() // Get all registered entries .stream() // Stream the wrapped objects .flatMap(RegistryObject::stream) // Get the object if available ::iterator; // Create the iterable } Loot Table Builders To generate loot tables, they are accepted by the LootTableProvider as a LootTable$Builder . Afterwards, the specified LootContextParamSet is set and then built via #build . Before being built, the builder can specify entries, conditions, and modifiers which affect how the loot table functions. Note The functionality of loot tables is so expansive that it will not be covered by this documentation in its entirety. Instead, a brief description of each component will be mentioned. The specific subtypes of each component can be found using an IDE. Their implementations will be left as an exercise to the reader. LootTable Loot tables are the base object and can be transformed into the required LootTable$Builder using LootTable#lootTable . The loot table can be built with a list of pools (via #withPool ) applied in the order they are specified along with functions (via #apply ) to modify the resulting items of those pools. LootPool Loot pools represents a group to perform operations and can generate a LootPool$Builder using LootPool#lootPool . Each loot pool can specify the entries (via #add ) which define the operations in the pool, the conditions (via #when ) which define if the operations in the pool should be performed, and functions (via #apply ) to modify the resulting items of the entries. Each pool can be executed as many times as specified (via #setRolls ). Additionally, bonus executions can be specified (via #setBonusRolls ) which is modified by the luck of the executor. LootPoolEntryContainer Loot entries define the operations to occur when selected, typically generating items. Each entry has an associated, registered LootPoolEntryType . They also have their own associated builders which subtype LootPoolEntryContainer$Builder . Multiple entries can execute at the same time (via #append ) or sequentially until one fails (via #then ). Additionally, entries can default to another entry on failure (via #otherwise ). LootItemCondition Loot conditions define requirements which need to be met for some operation to execute. Each condition has an associated, registered LootItemConditionType . They also have their own associated builders which subtype LootItemCondition$Builder . By default, all loot conditions specified must return true for an operation to execute. Loot conditions can also be specified such that only one must return true instead (via #or ). Additionally, the resulting output of a condition can be inverted (via #invert ). LootItemFunction Loot functions modify the result of an execution before passing it to the output. Each function has an associated, registered LootItemFunctionType . They also have their own associated builders which subtype LootItemFunction$Builder . NbtProvider NBT providers are a special type of functions defined by CopyNbtFunction . They define where to pull tag information from. Each provider has an associated, registered LootNbtProviderType . NumberProvider Number providers determine how many times a loot pool executes. Each provider has an associated, registered LootNumberProviderType . ScoreboardNameProvider Scoreboard providers are a special type of number providers defined by ScoreboardValue . They define the name of the scoreboard to pull the number of rolls to execute from. Each provider has an associated, registered LootScoreProviderType .","title":"Loot Table Providers"},{"location":"datagen/server/loottables/#loot-table-generation","text":"Loot tables can be generated for a mod by subclassing LootTableProvider with a few modifications. After implementation, the provider must be added to the DataGenerator .","title":"Loot Table Generation"},{"location":"datagen/server/loottables/#the-loottableprovider-subclass","text":"LootTableProvider is simplified into two methods: #getTables , which collect the table builders, and #validate , which checks whether the generated loot tables are valid. Both of these methods need to be overridden to use LootTableProvider . #validate can be simplified to call LootTables#validate for every single table. It initially fails since it expects the tables defined within BuiltInLootTables to be generated as well. // In some LootTableProvider subclass @Override protected void validate(Map<ResourceLocation, LootTable> tables, ValidationContext ctx) { tables.forEach((name, table) -> LootTables.validate(ctx, name, table)); } #getTables defines a list of factory methods for table builders for a given LootContextParamSet . Each table builder consumes a writer used to generate the given table for a specific name. To simplify understanding: // In some LootTableProvider subclass @Override protected List< // Get a list Pair< // of pairs Supplier< // for a factory Consumer< // which takes in BiConsumer< // a writer of ResourceLocation, // the name of the table LootTable.Builder // and the table to generate > > >, LootContextParamSet // with a given parameter set > > getTables() { // Return table builders here }","title":"The LootTableProvider Subclass"},{"location":"datagen/server/loottables/#table-builders","text":"Each table builder has a method which takes in the writer to generate a table. This is typically done implementing a Consumer<BiConsumer<ResourceLocation, LootTable.Builder>> . public class ExampleLoot implements Consumer<BiConsumer<ResourceLocation, LootTable.Builder>> { // Used to create a factory method for the wrapping Supplier public ExampleLoot() {} // The method used to generate the loot tables @Override public void accept(BiConsumer<ResourceLocation, LootTable.Builder> writer) { // Generate loot tables here by calling writer#accept } } The table can then be added to LootTableProvider#getTables for any available LootContextParamSet : // In some LootTableProvider subclass @Override protected List<Pair<Supplier<Consumer<BiConsumer<ResourceLocation, LootTable.Builder>>>, LootContextParamSet>> getTables() { return ImmutableList.of( Pair.of(ExampleLoot::new, LootContextParamSets.EMPTY) // Loot table builder for the 'empty' parameter set //... ); }","title":"Table Builders"},{"location":"datagen/server/loottables/#blockloot-and-entityloot-subclasses","text":"For LootContextParamSets#BLOCK and #ENTITY , there are special types ( BlockLoot and EntityLoot respectively) which provide additional helper methods for creating and validating that there are loot tables. To use them, all registered objects must be supplied to either BlockLoot#getKnownBlocks and EntityLoot#getKnownEntities respectively. These methods are to make sure all objects within the iterable has a loot table. Tip If DeferredRegister is being used to register a mod\u2019s objects, then the #getKnown* methods can be supplied the entries via DeferredRegister#getEntities : // In some BlockLoot subclass for some DeferredRegister BLOCK_REGISTRAR @Override protected Iterable<Block> getKnownBlocks() { return BLOCK_REGISTRAR.getEntries() // Get all registered entries .stream() // Stream the wrapped objects .flatMap(RegistryObject::stream) // Get the object if available ::iterator; // Create the iterable }","title":"BlockLoot and EntityLoot Subclasses"},{"location":"datagen/server/loottables/#loot-table-builders","text":"To generate loot tables, they are accepted by the LootTableProvider as a LootTable$Builder . Afterwards, the specified LootContextParamSet is set and then built via #build . Before being built, the builder can specify entries, conditions, and modifiers which affect how the loot table functions. Note The functionality of loot tables is so expansive that it will not be covered by this documentation in its entirety. Instead, a brief description of each component will be mentioned. The specific subtypes of each component can be found using an IDE. Their implementations will be left as an exercise to the reader.","title":"Loot Table Builders"},{"location":"datagen/server/loottables/#loottable","text":"Loot tables are the base object and can be transformed into the required LootTable$Builder using LootTable#lootTable . The loot table can be built with a list of pools (via #withPool ) applied in the order they are specified along with functions (via #apply ) to modify the resulting items of those pools.","title":"LootTable"},{"location":"datagen/server/loottables/#lootpool","text":"Loot pools represents a group to perform operations and can generate a LootPool$Builder using LootPool#lootPool . Each loot pool can specify the entries (via #add ) which define the operations in the pool, the conditions (via #when ) which define if the operations in the pool should be performed, and functions (via #apply ) to modify the resulting items of the entries. Each pool can be executed as many times as specified (via #setRolls ). Additionally, bonus executions can be specified (via #setBonusRolls ) which is modified by the luck of the executor.","title":"LootPool"},{"location":"datagen/server/loottables/#lootpoolentrycontainer","text":"Loot entries define the operations to occur when selected, typically generating items. Each entry has an associated, registered LootPoolEntryType . They also have their own associated builders which subtype LootPoolEntryContainer$Builder . Multiple entries can execute at the same time (via #append ) or sequentially until one fails (via #then ). Additionally, entries can default to another entry on failure (via #otherwise ).","title":"LootPoolEntryContainer"},{"location":"datagen/server/loottables/#lootitemcondition","text":"Loot conditions define requirements which need to be met for some operation to execute. Each condition has an associated, registered LootItemConditionType . They also have their own associated builders which subtype LootItemCondition$Builder . By default, all loot conditions specified must return true for an operation to execute. Loot conditions can also be specified such that only one must return true instead (via #or ). Additionally, the resulting output of a condition can be inverted (via #invert ).","title":"LootItemCondition"},{"location":"datagen/server/loottables/#lootitemfunction","text":"Loot functions modify the result of an execution before passing it to the output. Each function has an associated, registered LootItemFunctionType . They also have their own associated builders which subtype LootItemFunction$Builder .","title":"LootItemFunction"},{"location":"datagen/server/loottables/#nbtprovider","text":"NBT providers are a special type of functions defined by CopyNbtFunction . They define where to pull tag information from. Each provider has an associated, registered LootNbtProviderType .","title":"NbtProvider"},{"location":"datagen/server/loottables/#numberprovider","text":"Number providers determine how many times a loot pool executes. Each provider has an associated, registered LootNumberProviderType .","title":"NumberProvider"},{"location":"datagen/server/loottables/#scoreboardnameprovider","text":"Scoreboard providers are a special type of number providers defined by ScoreboardValue . They define the name of the scoreboard to pull the number of rolls to execute from. Each provider has an associated, registered LootScoreProviderType .","title":"ScoreboardNameProvider"},{"location":"datagen/server/recipes/","text":"Recipe Generation Recipes can be generated for a mod by subclassing RecipeProvider and overriding #buildCraftingRecipes . A recipe is supplied for data generation once a FinishedRecipe view is accepted by the consumer. FinishedRecipe s can either be created and supplied manually or, for convenience, created using a RecipeBuilder . After implementation, the provider must be added to the DataGenerator . RecipeBuilder RecipeBuilder is a convenience implementation for creating FinishedRecipe s to generate. It provides basic definitions for unlocking, grouping, saving, and getting the result of a recipe. This is done through #unlockedBy , #group , #save , and #getResult respectively. Important ItemStack outputs in recipes are not supported within vanilla recipe builders for RecipeProvider . A FinishedRecipe must be built in a different manner for existing vanilla recipe serializers to generate this data. Warning The item results being generated must have a valid CreativeModeTab specified; otherwise, a NullPointerException will be thrown. If no category accurately represents the item and no tab should be created, set the #tab property during item initialization to CreativeModeTab#TAB_SEARCH . All recipe builders except for [ SpecialRecipeBuilder ] require an advancement criteria to be specified. All recipes generate a criteria unlocking the recipe if the player has used the recipe previously. However, an additional criteria must be specified that allows the player to obtain the recipe without any prior knowledge. If any of the criteria specified is true, then the played will obtain the recipe for the recipe book. Tip Recipe criteria commonly use InventoryChangeTrigger to unlock their recipe when certain items are present in the user\u2019s inventory. ShapedRecipeBuilder ShapedRecipeBuilder is used to generate shaped recipes. The builder can be initialized via #shaped . The recipe group, input symbol pattern, symbol definition of ingredients, and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) ShapedRecipeBuilder builder = ShapedRecipeBuilder.shaped(result) .pattern(\"a a\") // Create recipe pattern .define('a', item) // Define what the symbol represents .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder Additional Validation Checks Shaped recipes have some additional validation checks performed before building: A pattern must be defined and take in more than one item. All pattern rows must be the same width. A symbol cannot be defined more than once. The space character ( ' ' ) is reserved for representing no item in a slot and, as such, cannot be defined. A pattern must use all symbols defined by the user. A criteria besides from using the recipe must be specified to unlock the recipe. ShapelessRecipeBuilder ShapelessRecipeBuilder is used to generate shapeless recipes. The builder can be initialized via #shapeless . The recipe group, input ingredients, and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) ShapelessRecipeBuilder builder = ShapelessRecipeBuilder.shapeless(result) .requires(item) // Add item to the recipe .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder SimpleCookingRecipeBuilder SimpleCookingRecipeBuilder is used to generate smelting, blasting, smoking, and campfire cooking recipes. Additionally, custom cooking recipes using the SimpleCookingSerializer can also be data generated using this builder. The builder can be initialized via #smelting , #blasting , #smoking , #campfireCooking , or #cooking respectively. The recipe group and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) SimpleCookingRecipeBuilder builder = SimpleCookingRecipeBuilder.smelting(input, result, experience, cookingTime) .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder SingleItemRecipeBuilder SingleItemRecipeBuilder is used to generate stonecutting recipes. Additionally, custom single item recipes using a serializer like SingleItemRecipe$Serializer can also be data generated using this builder. The builder can be initialized via #stonecutting or through the constructor respectively. The recipe group and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) SingleItemRecipeBuilder builder = SingleItemRecipeBuilder.stonecutting(input, result) .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder Non- RecipeBuilder Builders Some recipe builders do not implement RecipeBuilder due to lacking features used by all previously mentioned recipes. UpgradeRecipeBuilder UpgradeRecipeBuilder is used to generate smithing recipes. Additionally, custom upgrade recipes using a serializer like UpgradeRecipe$Serializer can also be data generated using this builder. The builder can be initialized via #smithing or through the constructor respectively. The recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) UpgradeRecipeBuilder builder = UpgradeRecipeBuilder.smithing(base, addition, result) .unlocks(\"criteria\", criteria) // How the recipe is unlocked .save(writer, name); // Add data to builder SpecialRecipeBuilder SpecialRecipeBuilder is used to generate empty JSONs for dynamic recipes that cannot easily be constrained to the recipe JSON format (dying armor, firework, etc.). The builder can be initialized via #special . // In RecipeProvider#buildCraftingRecipes(writer) SpecialRecipeBuilder.special(dynamicRecipeSerializer) .save(writer, name); // Add data to builder Conditional Recipes Conditional recipes can also be data generated via ConditionalRecipe$Builder . The builder can be obtained using #builder . Conditions for each recipe can be specified by first calling #addCondition and then calling #addRecipe after all conditions have been specified. This process can be repeated as many times as the programmer would like. After all recipes have been specified, advancements can be added for each recipe at the end using #generateAdvancement . Alternatively, the conditional advancement can be set using #setAdvancement . // In RecipeProvider#buildCraftingRecipes(writer) ConditionalRecipe.builder() // Add the conditions for the recipe .addCondition(...) // Add recipe to return when conditions are true .addRecipe(...) // Add the next conditions for the next recipe .addCondition(...) // Add next recipe to return when the next conditions are true .addRecipe(...) // Create conditional advancement which uses the conditions // and unlocking advancement in the recipes above .generateAdvancement() .build(writer, name); IConditionBuilder To simplify adding conditions to conditional recipes without having to construct the instances of each condition instance manually, the extended RecipeProvider can implement IConditionBuilder . The interface adds methods to easily construct condition instances. // In ConditionalRecipe$Builder#addCondition ( // If either 'examplemod:example_item' // OR 'examplemod:example_item2' exists // AND // NOT FALSE // Methods are defined by IConditionBuilder and( or( itemExists(\"examplemod\", \"example_item\"), itemExists(\"examplemod\", \"example_item2\") ), not( FALSE() ) ) ) Custom Recipe Serializers Custom recipe serializers can be data generated by creating a builder that can construct a FinishedRecipe . The finished recipe encodes the recipe data and its unlocking advancement, when present, to JSON. Additionally, the name and serializer of the recipe is also specified to know where to write to and what can decode the object when loading. Once a FinishedRecipe is constructed, it simply needs to be passed to the Consumer supplied by RecipeProvider#buildCraftingRecipes . Tip FinishedRecipe s are flexible enough that any object transformation can be data generated, not just items.","title":"Recipe Providers"},{"location":"datagen/server/recipes/#recipe-generation","text":"Recipes can be generated for a mod by subclassing RecipeProvider and overriding #buildCraftingRecipes . A recipe is supplied for data generation once a FinishedRecipe view is accepted by the consumer. FinishedRecipe s can either be created and supplied manually or, for convenience, created using a RecipeBuilder . After implementation, the provider must be added to the DataGenerator .","title":"Recipe Generation"},{"location":"datagen/server/recipes/#recipebuilder","text":"RecipeBuilder is a convenience implementation for creating FinishedRecipe s to generate. It provides basic definitions for unlocking, grouping, saving, and getting the result of a recipe. This is done through #unlockedBy , #group , #save , and #getResult respectively. Important ItemStack outputs in recipes are not supported within vanilla recipe builders for RecipeProvider . A FinishedRecipe must be built in a different manner for existing vanilla recipe serializers to generate this data. Warning The item results being generated must have a valid CreativeModeTab specified; otherwise, a NullPointerException will be thrown. If no category accurately represents the item and no tab should be created, set the #tab property during item initialization to CreativeModeTab#TAB_SEARCH . All recipe builders except for [ SpecialRecipeBuilder ] require an advancement criteria to be specified. All recipes generate a criteria unlocking the recipe if the player has used the recipe previously. However, an additional criteria must be specified that allows the player to obtain the recipe without any prior knowledge. If any of the criteria specified is true, then the played will obtain the recipe for the recipe book. Tip Recipe criteria commonly use InventoryChangeTrigger to unlock their recipe when certain items are present in the user\u2019s inventory.","title":"RecipeBuilder"},{"location":"datagen/server/recipes/#shapedrecipebuilder","text":"ShapedRecipeBuilder is used to generate shaped recipes. The builder can be initialized via #shaped . The recipe group, input symbol pattern, symbol definition of ingredients, and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) ShapedRecipeBuilder builder = ShapedRecipeBuilder.shaped(result) .pattern(\"a a\") // Create recipe pattern .define('a', item) // Define what the symbol represents .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder","title":"ShapedRecipeBuilder"},{"location":"datagen/server/recipes/#additional-validation-checks","text":"Shaped recipes have some additional validation checks performed before building: A pattern must be defined and take in more than one item. All pattern rows must be the same width. A symbol cannot be defined more than once. The space character ( ' ' ) is reserved for representing no item in a slot and, as such, cannot be defined. A pattern must use all symbols defined by the user. A criteria besides from using the recipe must be specified to unlock the recipe.","title":"Additional Validation Checks"},{"location":"datagen/server/recipes/#shapelessrecipebuilder","text":"ShapelessRecipeBuilder is used to generate shapeless recipes. The builder can be initialized via #shapeless . The recipe group, input ingredients, and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) ShapelessRecipeBuilder builder = ShapelessRecipeBuilder.shapeless(result) .requires(item) // Add item to the recipe .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder","title":"ShapelessRecipeBuilder"},{"location":"datagen/server/recipes/#simplecookingrecipebuilder","text":"SimpleCookingRecipeBuilder is used to generate smelting, blasting, smoking, and campfire cooking recipes. Additionally, custom cooking recipes using the SimpleCookingSerializer can also be data generated using this builder. The builder can be initialized via #smelting , #blasting , #smoking , #campfireCooking , or #cooking respectively. The recipe group and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) SimpleCookingRecipeBuilder builder = SimpleCookingRecipeBuilder.smelting(input, result, experience, cookingTime) .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder","title":"SimpleCookingRecipeBuilder"},{"location":"datagen/server/recipes/#singleitemrecipebuilder","text":"SingleItemRecipeBuilder is used to generate stonecutting recipes. Additionally, custom single item recipes using a serializer like SingleItemRecipe$Serializer can also be data generated using this builder. The builder can be initialized via #stonecutting or through the constructor respectively. The recipe group and the recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) SingleItemRecipeBuilder builder = SingleItemRecipeBuilder.stonecutting(input, result) .unlockedBy(\"criteria\", criteria) // How the recipe is unlocked .save(writer); // Add data to builder","title":"SingleItemRecipeBuilder"},{"location":"datagen/server/recipes/#non-recipebuilder-builders","text":"Some recipe builders do not implement RecipeBuilder due to lacking features used by all previously mentioned recipes.","title":"Non-RecipeBuilder Builders"},{"location":"datagen/server/recipes/#upgraderecipebuilder","text":"UpgradeRecipeBuilder is used to generate smithing recipes. Additionally, custom upgrade recipes using a serializer like UpgradeRecipe$Serializer can also be data generated using this builder. The builder can be initialized via #smithing or through the constructor respectively. The recipe unlock criteria can be specified before saving. // In RecipeProvider#buildCraftingRecipes(writer) UpgradeRecipeBuilder builder = UpgradeRecipeBuilder.smithing(base, addition, result) .unlocks(\"criteria\", criteria) // How the recipe is unlocked .save(writer, name); // Add data to builder","title":"UpgradeRecipeBuilder"},{"location":"datagen/server/recipes/#specialrecipebuilder","text":"SpecialRecipeBuilder is used to generate empty JSONs for dynamic recipes that cannot easily be constrained to the recipe JSON format (dying armor, firework, etc.). The builder can be initialized via #special . // In RecipeProvider#buildCraftingRecipes(writer) SpecialRecipeBuilder.special(dynamicRecipeSerializer) .save(writer, name); // Add data to builder","title":"SpecialRecipeBuilder"},{"location":"datagen/server/recipes/#conditional-recipes","text":"Conditional recipes can also be data generated via ConditionalRecipe$Builder . The builder can be obtained using #builder . Conditions for each recipe can be specified by first calling #addCondition and then calling #addRecipe after all conditions have been specified. This process can be repeated as many times as the programmer would like. After all recipes have been specified, advancements can be added for each recipe at the end using #generateAdvancement . Alternatively, the conditional advancement can be set using #setAdvancement . // In RecipeProvider#buildCraftingRecipes(writer) ConditionalRecipe.builder() // Add the conditions for the recipe .addCondition(...) // Add recipe to return when conditions are true .addRecipe(...) // Add the next conditions for the next recipe .addCondition(...) // Add next recipe to return when the next conditions are true .addRecipe(...) // Create conditional advancement which uses the conditions // and unlocking advancement in the recipes above .generateAdvancement() .build(writer, name);","title":"Conditional Recipes"},{"location":"datagen/server/recipes/#iconditionbuilder","text":"To simplify adding conditions to conditional recipes without having to construct the instances of each condition instance manually, the extended RecipeProvider can implement IConditionBuilder . The interface adds methods to easily construct condition instances. // In ConditionalRecipe$Builder#addCondition ( // If either 'examplemod:example_item' // OR 'examplemod:example_item2' exists // AND // NOT FALSE // Methods are defined by IConditionBuilder and( or( itemExists(\"examplemod\", \"example_item\"), itemExists(\"examplemod\", \"example_item2\") ), not( FALSE() ) ) )","title":"IConditionBuilder"},{"location":"datagen/server/recipes/#custom-recipe-serializers","text":"Custom recipe serializers can be data generated by creating a builder that can construct a FinishedRecipe . The finished recipe encodes the recipe data and its unlocking advancement, when present, to JSON. Additionally, the name and serializer of the recipe is also specified to know where to write to and what can decode the object when loading. Once a FinishedRecipe is constructed, it simply needs to be passed to the Consumer supplied by RecipeProvider#buildCraftingRecipes . Tip FinishedRecipe s are flexible enough that any object transformation can be data generated, not just items.","title":"Custom Recipe Serializers"},{"location":"datagen/server/tags/","text":"Tag Generation Tags can be generated for a mod by subclassing TagsProvider and implementing #addTags . After implementation, the provider must be added to the DataGenerator . TagsProvider The tags provider has two methods used for generating tags: creating a tag with objects and other tags via #tag , or using tags from other object types to generate the tag data via #getOrCreateRawBuilder . Note Typically, a provider will not call #getOrCreateRawBuilder directly unless a registry contains a representation of objects from a different registry (blocks have item representations to obtain the blocks in the inventory). When #tag is called, a TagAppender is created which acts as a chainable consumer of elements to add to the tag: Method Description add Adds an object to a tag. addOptional Adds an object to a tag through its name. If the object is not present, then the object will be skipped when loading. addTag Adds a tag to a tag. All elements within the inner tag are now a part of the outer tag. addOptionalTag Adds a tag to a tag through its name. If the tag is not present, then the tag will be skipped when loading. replace When true , all previously loaded entries added to this tag from other datapacks will be discarded. If a datapack is loaded after this one, then it will still append the entries to the tag. remove Removes an object or tag from a tag. // In some TagProvider#addTags this.tag(EXAMPLE_TAG) .add(EXAMPLE_OBJECT) // Adds an object to the tag .addOptional(new ResourceLocation(\"othermod\", \"other_object\")) // Adds an object from another mod to the tag this.tag(EXAMPLE_TAG_2) .addTag(EXAMPLE_TAG) // Adds a tag to the tag .remove(EXAMPLE_OBJECT) // Removes an object from this tag Important If the mod\u2019s tags softly depends on another mod\u2019s tags (the other mod may or may not be present at runtime), the other mods\u2019 tags should be referenced using the optional methods. Existing Providers Minecraft contains a few tag providers for certain registries that can be subclassed instead. Additionally, some providers contain additional helper methods to more easily create tags. Registry Object Type Tag Provider Block BlockTagsProvider Item ItemTagsProvider EntityType EntityTypeTagsProvider Fluid FluidTagsProvider GameEvent GameEventTagsProvider Biome BiomeTagsProvider ConfiguredStructureFeature ConfiguredStructureTagsProvider ItemTagsProvider#copy Blocks have item representations to obtain them in the inventory. As such, many of the block tags can also be an item tag. To easily generate item tags to have the same entries as block tags, the #copy method can be used which takes in the block tag to copy from and the item tag to copy to. //In ItemTagsProvider#addTags this.copy(EXAMPLE_BLOCK_TAG, EXAMPLE_ITEM_TAG); Custom Tag Providers A custom tag provider can be created via a TagsProvider subclass which takes in the Registry to generate tags for. public RecipeTypeTagsProvider(DataGenerator generator, ExistingFileHelper fileHelper) { super(generator, Registry.RECIPE_TYPE, MOD_ID, fileHelper); } Forge Registry Tag Providers If a registry is wrapped by Forge or created by a mod , a provider can be created via a ForgeRegistryTagsProvider subclass instead: public MotiveTagsProvider(DataGenerator generator, ExistingFileHelper fileHelper) { super(generator, ForgeRegistries.PAINTING_TYPES, MOD_ID, fileHelper); }","title":"Tag Providers"},{"location":"datagen/server/tags/#tag-generation","text":"Tags can be generated for a mod by subclassing TagsProvider and implementing #addTags . After implementation, the provider must be added to the DataGenerator .","title":"Tag Generation"},{"location":"datagen/server/tags/#tagsprovider","text":"The tags provider has two methods used for generating tags: creating a tag with objects and other tags via #tag , or using tags from other object types to generate the tag data via #getOrCreateRawBuilder . Note Typically, a provider will not call #getOrCreateRawBuilder directly unless a registry contains a representation of objects from a different registry (blocks have item representations to obtain the blocks in the inventory). When #tag is called, a TagAppender is created which acts as a chainable consumer of elements to add to the tag: Method Description add Adds an object to a tag. addOptional Adds an object to a tag through its name. If the object is not present, then the object will be skipped when loading. addTag Adds a tag to a tag. All elements within the inner tag are now a part of the outer tag. addOptionalTag Adds a tag to a tag through its name. If the tag is not present, then the tag will be skipped when loading. replace When true , all previously loaded entries added to this tag from other datapacks will be discarded. If a datapack is loaded after this one, then it will still append the entries to the tag. remove Removes an object or tag from a tag. // In some TagProvider#addTags this.tag(EXAMPLE_TAG) .add(EXAMPLE_OBJECT) // Adds an object to the tag .addOptional(new ResourceLocation(\"othermod\", \"other_object\")) // Adds an object from another mod to the tag this.tag(EXAMPLE_TAG_2) .addTag(EXAMPLE_TAG) // Adds a tag to the tag .remove(EXAMPLE_OBJECT) // Removes an object from this tag Important If the mod\u2019s tags softly depends on another mod\u2019s tags (the other mod may or may not be present at runtime), the other mods\u2019 tags should be referenced using the optional methods.","title":"TagsProvider"},{"location":"datagen/server/tags/#existing-providers","text":"Minecraft contains a few tag providers for certain registries that can be subclassed instead. Additionally, some providers contain additional helper methods to more easily create tags. Registry Object Type Tag Provider Block BlockTagsProvider Item ItemTagsProvider EntityType EntityTypeTagsProvider Fluid FluidTagsProvider GameEvent GameEventTagsProvider Biome BiomeTagsProvider ConfiguredStructureFeature ConfiguredStructureTagsProvider","title":"Existing Providers"},{"location":"datagen/server/tags/#itemtagsprovidercopy","text":"Blocks have item representations to obtain them in the inventory. As such, many of the block tags can also be an item tag. To easily generate item tags to have the same entries as block tags, the #copy method can be used which takes in the block tag to copy from and the item tag to copy to. //In ItemTagsProvider#addTags this.copy(EXAMPLE_BLOCK_TAG, EXAMPLE_ITEM_TAG);","title":"ItemTagsProvider#copy"},{"location":"datagen/server/tags/#custom-tag-providers","text":"A custom tag provider can be created via a TagsProvider subclass which takes in the Registry to generate tags for. public RecipeTypeTagsProvider(DataGenerator generator, ExistingFileHelper fileHelper) { super(generator, Registry.RECIPE_TYPE, MOD_ID, fileHelper); }","title":"Custom Tag Providers"},{"location":"datagen/server/tags/#forge-registry-tag-providers","text":"If a registry is wrapped by Forge or created by a mod , a provider can be created via a ForgeRegistryTagsProvider subclass instead: public MotiveTagsProvider(DataGenerator generator, ExistingFileHelper fileHelper) { super(generator, ForgeRegistries.PAINTING_TYPES, MOD_ID, fileHelper); }","title":"Forge Registry Tag Providers"},{"location":"datastorage/capabilities/","text":"The Capability System Capabilities allow exposing features in a dynamic and flexible way without having to resort to directly implementing many interfaces. In general terms, each capability provides a feature in the form of an interface, a default implementation which can be requested, and a storage handler for at least this default implementation. The storage handler can support other implementations, but this is up to the capability implementor, so look it up in their documentation before trying to use the default storage with non-default implementations. Forge adds capability support to BlockEntities, Entities, ItemStacks, Levels, and LevelChunks, which can be exposed either by attaching them through an event or by overriding the capability methods in your own implementations of the objects. This will be explained in more detail in the following sections. Forge-provided Capabilities Forge provides three capabilities: IItemHandler , IFluidHandler and IEnergyStorage IItemHandler exposes an interface for handling inventory slots. It can be applied to BlockEntities (chests, machines, etc.), Entities (extra player slots, mob/creature inventories/bags), or ItemStacks (portable backpacks and such). It replaces the old IInventory and ISidedInventory with an automation-friendly system. IFluidHandler exposes an interface for handling fluid inventories. It can also be applied to BlockEntities, Entities, or ItemStacks. It replaces the old IFluidHandler with a more consistent and automation-friendly system. IEnergyStorage exposes an interface for handling energy containers. It can be applied to BlockEntities, Entities, or ItemStacks. It is based on the RedstoneFlux API by TeamCoFH. Using an Existing Capability As mentioned earlier, BlockEntities, Entities, and ItemStacks implement the capability provider feature through the ICapabilityProvider interface. This interface adds the method #getCapability , which can be used to query the capabilities present in the associated provider objects. In order to obtain a capability, you will need to refer it by its unique instance. In the case of the IItemHandler , this capability is primarily stored in CapabilityItemHandler#ITEM_HANDLER_CAPABILITY , but it is possible to get other instance references by using CapabilityManager#get static Capability<IItemHandler> ITEM_HANDLER_CAPABILITY = CapabilityManager.get(new CapabilityToken<>(){}); When called, CapabilityManager#get provides a non-null capability for your associated type. The anonymous CapabilityToken allows Forge to keep a soft dependency system while still having the necessary generic information to get the correct capability. Important Even if you have a non-null capability available to you at all times, it does not mean the capability itself is usable or registered yet. This can be checked via Capability#isRegistered . The #getCapability method has a second parameter, of type Direction , which can be used to request the specific instance for that one face. If passed null , it can be assumed that the request comes either from within the block or from some place where the side has no meaning, such as a different dimension. In this case a general capability instance that does not care about sides will be requested instead. The return type of #getCapability will correspond to a LazyOptional of the type declared in the capability passed to the method. For the Item Handler capability, this is LazyOptional<IItemHandler> . If the capability is not available for a particular provider, it will return an empty LazyOptional instead. Exposing a Capability In order to expose a capability, you will first need an instance of the underlying capability type. Note that you should assign a separate instance to each object that keeps the capability, since the capability will most probably be tied to the containing object. In the case of IItemHandler , the default implementation uses the ItemStackHandler class, which has an optional argument in the constructor, to specify a number of slots. However, relying on the existence of these default implementations should be avoided, as the purpose of the capability system is to prevent loading errors in contexts where the capability is not present, so instantiation should be protected behind a check testing if the capability has been registered (see the remarks about CapabilityManager#get in the previous section). Once you have your own instance of the capability interface, you will want to notify users of the capability system that you expose this capability and provide a LazyOptional of the interface reference. This is done by overriding the #getCapability method, and comparing the capability instance with the capability you are exposing. If your machine has different slots based on which side is being queried, you can test this with the side parameter. For Entities and ItemStacks, this parameter can be ignored, but it is still possible to have side as a context, such as different armor slots on a player ( Direction#UP exposing the player\u2019s helmet slot), or about the surrounding blocks in the inventory ( Direction#WEST exposing the input slot of a furnace). Do not forget to fall back to super , otherwise existing attached capabilities will stop working. Capabilities must be invalidated at the end of the provider\u2019s lifecycle via LazyOptional#invalidate . For owned BlockEntities and Entities, the LazyOptional can be invalidated within #invalidateCaps . For non-owned providers, a runnable supplying the invalidation should be passed into AttachCapabilitiesEvent#addListener . // Somewhere in your BlockEntity subclass LazyOptional<IItemHandler> inventoryHandlerLazyOptional; // Supplied instance (e.g. () -> inventoryHandler) // Ensure laziness as initialization should only happen when needed inventoryHandlerLazyOptional = LazyOptional.of(inventoryHandlerSupplier); @Override public <T> LazyOptional<T> getCapability(Capability<T> cap, Direction side) { if (cap == CapabilityItemHandler.ITEM_HANDLER_CAPABILITY) { return inventoryHandlerLazyOptional.cast(); } return super.getCapability(cap, side); } @Override public void invalidateCaps() { super.invalidateCaps(); inventoryHandlerLazyOptional.invalidate(); } Item s are a special case since their capability providers are stored on an ItemStack . Instead, a provider should be attached through Item#initCapabilities . This should hold your capabilities for the lifecycle of the stack. It is strongly suggested that direct checks in code are used to test for capabilities instead of attempting to rely on maps or other data structures, since capability tests can be done by many objects every tick, and they need to be as fast as possible in order to avoid slowing down the game. Attaching Capabilities As mentioned, attaching capabilities to existing providers, Level s, and LevelChunk s can be done using AttachCapabilitiesEvent . The same event is used for all objects that can provide capabilities. AttachCapabilitiesEvent has 5 valid generic types providing the following events: AttachCapabilitiesEvent<Entity> : Fires only for entities. AttachCapabilitiesEvent<BlockEntity> : Fires only for block entities. AttachCapabilitiesEvent<ItemStack> : Fires only for item stacks. AttachCapabilitiesEvent<Level> : Fires only for levels. AttachCapabilitiesEvent<LevelChunk> : Fires only for level chunks. The generic type cannot be more specific than the above types. For example: If you want to attach capabilities to Player , you have to subscribe to the AttachCapabilitiesEvent<Entity> , and then determine that the provided object is an Player before attaching the capability. In all cases, the event has a method #addCapability which can be used to attach capabilities to the target object. Instead of adding capabilities themselves to the list, you add capability providers, which have the chance to return capabilities only from certain sides. While the provider only needs to implement ICapabilityProvider , if the capability needs to store data persistently, it is possible to implement ICapabilitySerializable<T extends Tag> which, on top of returning the capabilities, will provide tag save/load functions. For information on how to implement ICapabilityProvider , refer to the Exposing a Capability section. Creating Your Own Capability In general terms, a capability is registered through the event RegisterCapabilitiesEvent on the mod event bus via the #register method. @SubscribeEvent public void registerCaps(RegisterCapabilitiesEvent event) { event.register(IExampleCapability.class); } Persisting LevelChunk and BlockEntity capabilities Unlike Levels, Entities, and ItemStacks, LevelChunks and BlockEntities are only written to disk when they have been marked as dirty. A capability implementation with persistent state for a LevelChunk or a BlockEntity should therefore ensure that whenever its state changes, its owner is marked as dirty. ItemStackHandler , commonly used for inventories in BlockEntities, has an overridable method void onContentsChanged(int slot) designed to be used to mark the BlockEntity as dirty. public class MyBlockEntity extends BlockEntity { private final IItemHandler inventory = new ItemStackHandler(...) { @Override protected void onContentsChanged(int slot) { super.onContentsChanged(slot); setChanged(); } } // ... } Synchronizing Data with Clients By default, capability data is not sent to clients. In order to change this, the mods have to manage their own synchronization code using packets. There are three different situations in which you may want to send synchronization packets, all of them optional: When the entity spawns in the level, or the block is placed, you may want to share the initialization-assigned values with the clients. When the stored data changes, you may want to notify some or all of the watching clients. When a new client starts viewing the entity or block, you may want to notify it of the existing data. Refer to the Networking page for more information on implementing network packets. Persisting across Player Deaths By default, the capability data does not persist on death. In order to change this, the data has to be manually copied when the player entity is cloned during the respawn process. This can be done via PlayerEvent$Clone by reading the data from the original entity and assigning it to the new entity. In this event, the #isWasDeath method can be used to distinguish between respawning after death and returning from the End. This is important because the data will already exist when returning from the End, so care has to be taken to not duplicate values in this case. Migrating from IExtendedEntityProperties Although the Capability system can do everything IEEPs (IExtendedEntityProperties) did and more, the two concepts don\u2019t fully match 1:1. This section will explain how to convert existing IEEPs into Capabilities. This is a quick list of IEEP concepts and their Capability equivalent: Property name/id ( String ): Capability key ( ResourceLocation ) Registration ( EntityConstructing ): Attaching ( AttachCapabilitiesEvent<Entity> ), the real registration of the Capability happens during FMLCommonSetupEvent . Tag read/write methods: Does not happen automatically. Attach an ICapabilitySerializable in the event and run the read/write methods from the serializeNBT / deserializeNBT . Quick conversion guide: Convert the IEEP key/id string into a ResourceLocation (which will use your MODID as a namespace). In your handler class (not the class that implements your capability interface), create a field that will hold the Capability instance. Change the EntityConstructing event to AttachCapabilitiesEvent , and instead of querying the IEEP, you will want to attach an ICapabilityProvider (probably ICapabilitySerializable , which allows saving/loading from a tag). Create a registration method if you don\u2019t have one (you may have one where you registered your IEEP\u2019s event handlers) and in it, run the capability registration function.","title":"Capabilities"},{"location":"datastorage/capabilities/#the-capability-system","text":"Capabilities allow exposing features in a dynamic and flexible way without having to resort to directly implementing many interfaces. In general terms, each capability provides a feature in the form of an interface, a default implementation which can be requested, and a storage handler for at least this default implementation. The storage handler can support other implementations, but this is up to the capability implementor, so look it up in their documentation before trying to use the default storage with non-default implementations. Forge adds capability support to BlockEntities, Entities, ItemStacks, Levels, and LevelChunks, which can be exposed either by attaching them through an event or by overriding the capability methods in your own implementations of the objects. This will be explained in more detail in the following sections.","title":"The Capability System"},{"location":"datastorage/capabilities/#forge-provided-capabilities","text":"Forge provides three capabilities: IItemHandler , IFluidHandler and IEnergyStorage IItemHandler exposes an interface for handling inventory slots. It can be applied to BlockEntities (chests, machines, etc.), Entities (extra player slots, mob/creature inventories/bags), or ItemStacks (portable backpacks and such). It replaces the old IInventory and ISidedInventory with an automation-friendly system. IFluidHandler exposes an interface for handling fluid inventories. It can also be applied to BlockEntities, Entities, or ItemStacks. It replaces the old IFluidHandler with a more consistent and automation-friendly system. IEnergyStorage exposes an interface for handling energy containers. It can be applied to BlockEntities, Entities, or ItemStacks. It is based on the RedstoneFlux API by TeamCoFH.","title":"Forge-provided Capabilities"},{"location":"datastorage/capabilities/#using-an-existing-capability","text":"As mentioned earlier, BlockEntities, Entities, and ItemStacks implement the capability provider feature through the ICapabilityProvider interface. This interface adds the method #getCapability , which can be used to query the capabilities present in the associated provider objects. In order to obtain a capability, you will need to refer it by its unique instance. In the case of the IItemHandler , this capability is primarily stored in CapabilityItemHandler#ITEM_HANDLER_CAPABILITY , but it is possible to get other instance references by using CapabilityManager#get static Capability<IItemHandler> ITEM_HANDLER_CAPABILITY = CapabilityManager.get(new CapabilityToken<>(){}); When called, CapabilityManager#get provides a non-null capability for your associated type. The anonymous CapabilityToken allows Forge to keep a soft dependency system while still having the necessary generic information to get the correct capability. Important Even if you have a non-null capability available to you at all times, it does not mean the capability itself is usable or registered yet. This can be checked via Capability#isRegistered . The #getCapability method has a second parameter, of type Direction , which can be used to request the specific instance for that one face. If passed null , it can be assumed that the request comes either from within the block or from some place where the side has no meaning, such as a different dimension. In this case a general capability instance that does not care about sides will be requested instead. The return type of #getCapability will correspond to a LazyOptional of the type declared in the capability passed to the method. For the Item Handler capability, this is LazyOptional<IItemHandler> . If the capability is not available for a particular provider, it will return an empty LazyOptional instead.","title":"Using an Existing Capability"},{"location":"datastorage/capabilities/#exposing-a-capability","text":"In order to expose a capability, you will first need an instance of the underlying capability type. Note that you should assign a separate instance to each object that keeps the capability, since the capability will most probably be tied to the containing object. In the case of IItemHandler , the default implementation uses the ItemStackHandler class, which has an optional argument in the constructor, to specify a number of slots. However, relying on the existence of these default implementations should be avoided, as the purpose of the capability system is to prevent loading errors in contexts where the capability is not present, so instantiation should be protected behind a check testing if the capability has been registered (see the remarks about CapabilityManager#get in the previous section). Once you have your own instance of the capability interface, you will want to notify users of the capability system that you expose this capability and provide a LazyOptional of the interface reference. This is done by overriding the #getCapability method, and comparing the capability instance with the capability you are exposing. If your machine has different slots based on which side is being queried, you can test this with the side parameter. For Entities and ItemStacks, this parameter can be ignored, but it is still possible to have side as a context, such as different armor slots on a player ( Direction#UP exposing the player\u2019s helmet slot), or about the surrounding blocks in the inventory ( Direction#WEST exposing the input slot of a furnace). Do not forget to fall back to super , otherwise existing attached capabilities will stop working. Capabilities must be invalidated at the end of the provider\u2019s lifecycle via LazyOptional#invalidate . For owned BlockEntities and Entities, the LazyOptional can be invalidated within #invalidateCaps . For non-owned providers, a runnable supplying the invalidation should be passed into AttachCapabilitiesEvent#addListener . // Somewhere in your BlockEntity subclass LazyOptional<IItemHandler> inventoryHandlerLazyOptional; // Supplied instance (e.g. () -> inventoryHandler) // Ensure laziness as initialization should only happen when needed inventoryHandlerLazyOptional = LazyOptional.of(inventoryHandlerSupplier); @Override public <T> LazyOptional<T> getCapability(Capability<T> cap, Direction side) { if (cap == CapabilityItemHandler.ITEM_HANDLER_CAPABILITY) { return inventoryHandlerLazyOptional.cast(); } return super.getCapability(cap, side); } @Override public void invalidateCaps() { super.invalidateCaps(); inventoryHandlerLazyOptional.invalidate(); } Item s are a special case since their capability providers are stored on an ItemStack . Instead, a provider should be attached through Item#initCapabilities . This should hold your capabilities for the lifecycle of the stack. It is strongly suggested that direct checks in code are used to test for capabilities instead of attempting to rely on maps or other data structures, since capability tests can be done by many objects every tick, and they need to be as fast as possible in order to avoid slowing down the game.","title":"Exposing a Capability"},{"location":"datastorage/capabilities/#attaching-capabilities","text":"As mentioned, attaching capabilities to existing providers, Level s, and LevelChunk s can be done using AttachCapabilitiesEvent . The same event is used for all objects that can provide capabilities. AttachCapabilitiesEvent has 5 valid generic types providing the following events: AttachCapabilitiesEvent<Entity> : Fires only for entities. AttachCapabilitiesEvent<BlockEntity> : Fires only for block entities. AttachCapabilitiesEvent<ItemStack> : Fires only for item stacks. AttachCapabilitiesEvent<Level> : Fires only for levels. AttachCapabilitiesEvent<LevelChunk> : Fires only for level chunks. The generic type cannot be more specific than the above types. For example: If you want to attach capabilities to Player , you have to subscribe to the AttachCapabilitiesEvent<Entity> , and then determine that the provided object is an Player before attaching the capability. In all cases, the event has a method #addCapability which can be used to attach capabilities to the target object. Instead of adding capabilities themselves to the list, you add capability providers, which have the chance to return capabilities only from certain sides. While the provider only needs to implement ICapabilityProvider , if the capability needs to store data persistently, it is possible to implement ICapabilitySerializable<T extends Tag> which, on top of returning the capabilities, will provide tag save/load functions. For information on how to implement ICapabilityProvider , refer to the Exposing a Capability section.","title":"Attaching Capabilities"},{"location":"datastorage/capabilities/#creating-your-own-capability","text":"In general terms, a capability is registered through the event RegisterCapabilitiesEvent on the mod event bus via the #register method. @SubscribeEvent public void registerCaps(RegisterCapabilitiesEvent event) { event.register(IExampleCapability.class); }","title":"Creating Your Own Capability"},{"location":"datastorage/capabilities/#persisting-levelchunk-and-blockentity-capabilities","text":"Unlike Levels, Entities, and ItemStacks, LevelChunks and BlockEntities are only written to disk when they have been marked as dirty. A capability implementation with persistent state for a LevelChunk or a BlockEntity should therefore ensure that whenever its state changes, its owner is marked as dirty. ItemStackHandler , commonly used for inventories in BlockEntities, has an overridable method void onContentsChanged(int slot) designed to be used to mark the BlockEntity as dirty. public class MyBlockEntity extends BlockEntity { private final IItemHandler inventory = new ItemStackHandler(...) { @Override protected void onContentsChanged(int slot) { super.onContentsChanged(slot); setChanged(); } } // ... }","title":"Persisting LevelChunk and BlockEntity capabilities"},{"location":"datastorage/capabilities/#synchronizing-data-with-clients","text":"By default, capability data is not sent to clients. In order to change this, the mods have to manage their own synchronization code using packets. There are three different situations in which you may want to send synchronization packets, all of them optional: When the entity spawns in the level, or the block is placed, you may want to share the initialization-assigned values with the clients. When the stored data changes, you may want to notify some or all of the watching clients. When a new client starts viewing the entity or block, you may want to notify it of the existing data. Refer to the Networking page for more information on implementing network packets.","title":"Synchronizing Data with Clients"},{"location":"datastorage/capabilities/#persisting-across-player-deaths","text":"By default, the capability data does not persist on death. In order to change this, the data has to be manually copied when the player entity is cloned during the respawn process. This can be done via PlayerEvent$Clone by reading the data from the original entity and assigning it to the new entity. In this event, the #isWasDeath method can be used to distinguish between respawning after death and returning from the End. This is important because the data will already exist when returning from the End, so care has to be taken to not duplicate values in this case.","title":"Persisting across Player Deaths"},{"location":"datastorage/capabilities/#migrating-from-iextendedentityproperties","text":"Although the Capability system can do everything IEEPs (IExtendedEntityProperties) did and more, the two concepts don\u2019t fully match 1:1. This section will explain how to convert existing IEEPs into Capabilities. This is a quick list of IEEP concepts and their Capability equivalent: Property name/id ( String ): Capability key ( ResourceLocation ) Registration ( EntityConstructing ): Attaching ( AttachCapabilitiesEvent<Entity> ), the real registration of the Capability happens during FMLCommonSetupEvent . Tag read/write methods: Does not happen automatically. Attach an ICapabilitySerializable in the event and run the read/write methods from the serializeNBT / deserializeNBT . Quick conversion guide: Convert the IEEP key/id string into a ResourceLocation (which will use your MODID as a namespace). In your handler class (not the class that implements your capability interface), create a field that will hold the Capability instance. Change the EntityConstructing event to AttachCapabilitiesEvent , and instead of querying the IEEP, you will want to attach an ICapabilityProvider (probably ICapabilitySerializable , which allows saving/loading from a tag). Create a registration method if you don\u2019t have one (you may have one where you registered your IEEP\u2019s event handlers) and in it, run the capability registration function.","title":"Migrating from IExtendedEntityProperties"},{"location":"datastorage/saveddata/","text":"Saved Data The Saved Data (SD) system is an alternative to level capabilities that can attach data per level. Declaration Each SD implementation must subtype the SavedData class. There are two important methods to be aware of: save : Allows the implementation to write NBT data to the level. setDirty : A method that must be called after changing the data, to notify the game that there are changes that need to be written. If not called, #save will not get called and the existing data will persist. Attaching to a Level Any SavedData is loaded and/or attached to a level dynamically. As such, if one is never created on a level, then it will not exist. SavedData s are created and loaded from the DimensionDataStorage , which can be accessed by either ServerChunkCache#getDataStorage or ServerLevel#getDataStorage . From there, you can get or create an instance of your SD by calling DimensionDataStorage#computeIfAbsent . This will attempt to get the current instance of the SD if present or create a new one and load all available data. DimensionDataStorage#computeIfAbsent takes in three arguments: a function to load NBT data into a SD and return it, a supplier to construct a new instance of the SD, and the name of the .dat file stored within the data folder for the implemented level. For example, if a SD was named \u201cexample\u201d within the Nether, then a file would be created at ./<level_folder>/DIM-1/data/example.dat and would be implemented like so: // In some class public ExampleSavedData create() { return new ExampleSavedData(); } public ExampleSavedData load(CompoundTag tag) { ExampleSavedData data = this.create(); // Load saved data return data; } // In some method within the class netherDataStorage.computeIfAbsent(this::load, this::create, \"example\"); To persist a SD across levels, a SD should be attached to the Overworld, which can be obtained from MinecraftServer#overworld . The Overworld is the only dimension that is never fully unloaded and as such makes it perfect to store multi-level data on.","title":"Saved Data"},{"location":"datastorage/saveddata/#saved-data","text":"The Saved Data (SD) system is an alternative to level capabilities that can attach data per level.","title":"Saved Data"},{"location":"datastorage/saveddata/#declaration","text":"Each SD implementation must subtype the SavedData class. There are two important methods to be aware of: save : Allows the implementation to write NBT data to the level. setDirty : A method that must be called after changing the data, to notify the game that there are changes that need to be written. If not called, #save will not get called and the existing data will persist.","title":"Declaration"},{"location":"datastorage/saveddata/#attaching-to-a-level","text":"Any SavedData is loaded and/or attached to a level dynamically. As such, if one is never created on a level, then it will not exist. SavedData s are created and loaded from the DimensionDataStorage , which can be accessed by either ServerChunkCache#getDataStorage or ServerLevel#getDataStorage . From there, you can get or create an instance of your SD by calling DimensionDataStorage#computeIfAbsent . This will attempt to get the current instance of the SD if present or create a new one and load all available data. DimensionDataStorage#computeIfAbsent takes in three arguments: a function to load NBT data into a SD and return it, a supplier to construct a new instance of the SD, and the name of the .dat file stored within the data folder for the implemented level. For example, if a SD was named \u201cexample\u201d within the Nether, then a file would be created at ./<level_folder>/DIM-1/data/example.dat and would be implemented like so: // In some class public ExampleSavedData create() { return new ExampleSavedData(); } public ExampleSavedData load(CompoundTag tag) { ExampleSavedData data = this.create(); // Load saved data return data; } // In some method within the class netherDataStorage.computeIfAbsent(this::load, this::create, \"example\"); To persist a SD across levels, a SD should be attached to the Overworld, which can be obtained from MinecraftServer#overworld . The Overworld is the only dimension that is never fully unloaded and as such makes it perfect to store multi-level data on.","title":"Attaching to a Level"},{"location":"forgedev/","text":"Getting Started If you have decided to contribute to Forge, you will have to take some special steps to get started with developing. A simple mod development environment will not suffice to work with Forge\u2019s codebase directly. Instead, you can use the following guide to help you with your setup and get you started with improving Forge! Forking and Cloning the Repository Like most major open source projects you will find, Forge is hosted on GitHub . If you have contributed to another project before, you will know this process already and can skip right ahead to the next section. For those who are beginners when it comes to collaboration via Git, here are two easy steps to get you started. Note This guide assumes that you already have a GitHub account set up. If you do not, visit their registration page to create an account. Furthermore, this guide is not a tutorial for git\u2019s usage. Please consult different sources first if you are struggling to get it working. Forking First of all, you have to \u201cfork\u201d the MinecraftForge repository by clicking the \u201cFork\u201d button in the upper right hand corner. If you are in an organization, select the account you want your fork to be hosted on. Forking the repository is necessary since not every GitHub user can have free access to every repository. Instead, you create a copy of the original repository to later contribute your changes via a so called Pull Request, which you will learn more about later. Cloning After forking the repository, it is time to get local access to actually make some changes. For this, you need to clone the repository onto your local machine. Using your favorite git client, simply clone your fork into a directory of your choice. As general example, here is a command line snippet that should work on all correctly configured systems and clones the repository into a directory called \u201cMinecraftForge\u201d under the current directory (note that you have to replace <User> with your username): git clone https://github.com/<User>/MinecraftForge Checking out the Correct Branch Forking and cloning the repository are the only mandatory steps to develop for Forge. However, to ease the process of creating Pull Requests for you, it is best to work with branches. It is recommended to create and check out a branch for each PR you plan to submit. This way, you can always keep around the latest changes of Forge for new PRs while you still work on older patches. After completing this step, you are ready to go and set up your development environment. Setting Up the Environment Depending on your favorite IDE, there is a different set of recommended steps you have to follow to successfully set up a development environment. Eclipse Due to the way Eclipse workspaces work, ForgeGradle can do most of the work involved to get you started with a Forge workspace. Open a terminal/command prompt and navigate to the directory of your cloned fork. Type ./gradlew setup and hit enter. Wait until ForgeGradle is done. Type ./gradlew genEclipseRuns and hit enter. Once again, wait until ForgeGradle is done. Open your Eclipse workspace and go to File -> Import -> General -> Existing Gradle Project . Browse to the repo directory for the \u201cProject root directory\u201d option in the dialog that opens. Complete the import by clicking the \u201cFinish\u201d button. That is all it takes to get you up and running with Eclipse. There is no extra steps required to get the test mods running. Simply hit \u201cRun\u201d like in any other project and select the appropriate run configuration. IntelliJ IDEA JetBrains\u2019 flagship IDE comes with great integrated support for Gradle : Forge\u2019s build system of choice. Due to some peculiarities of Minecraft mod development, however, there are additional steps required to get everything to work properly. IDEA 2021 onwards Start IntelliJ IDEA 2021. If you already have another project open, close the project with the File -> Close project option. In the projects tab of the \u201cWelcome to IntelliJ IDEA\u201d window, click the \u201cOpen\u201d button on the top right and select the MinecraftForge folder you cloned earlier. Click \u201cTrust Project\u201d if prompted. After IDEA is done importing the project and indexing its files, run the Gradle setup task. You can do this by: Open the Gradle sidebar on the right hand side of your screen, then open the forge project tree, select Tasks, then other and double-click the setup task (may also appear as MinecraftForge[Setup] ) found in Forge -> Tasks -> other -> setup . Generate the run configurations: Open the Gradle sidebar on the right hand side of your screen, then open the forge project tree, select Tasks, then other and double-click the genIntellijRuns task (may also appear as MinecraftForge[genIntellijRuns] ) found in Forge -> Tasks -> forgegradle runs -> genIntellijRuns . If you get a licensing error during build before making any changes, running the updateLicenses task may help. This task is found in Forge -> Tasks -> other as well. IDEA 2019-2020 There are a few minor differences between IDEA 2021 and these versions for setup. Import Forge\u2019s build.gradle as an IDEA project. For this, simply click Import Project from the Welcome to IntelliJ IDEA splash screen, then select the build.gradle file. After IDEA is done importing the project and indexing the files, run the Gradle setup task. Either: Open the Gradle sidebar on the right hand side of your screen, then open the forge project tree, select Tasks , then other and double-click the setup task (may also appear as MinecraftForge[Setup] . Or alternatively: Tap the CTRL key twice, and type gradle setup in the Run command window that pops up. You can then run Forge using the forge_client gradle task ( Tasks -> fg_runs -> forge_client ): right-click the task and select either Run or Debug as desired. IDEA older versions Versions older than 2016 will not work because they did not have the appropriate Gradle support nor support Forge development multi-project workspaces. IDEA 2016 - 2018 will work with extra manual steps required, but it is strongly recommended to update to IDEA 2019+ instead. cpw has uploaded a video for IDEA 2016.1 explaining very similar steps which will lead to a working setup. That is all there is to creating a Forge development environment in IntelliJ IDEA. However, you will not be able to run tests and debug mods included in Forge straight away. This takes some extra effort. Enabling test mods To enable the test mods coming with Forge, you will need to add the compiler output to the classpath. Again, cpw has put up a video explaining these steps for IDEA 2016.1. Build the test classes by selecting the src/main/test directory in your project view and then run Build -> Build module 'Forge_test' from the menu bar. Open the \u201cProject Structure\u201d window under File -> Project Structure . Head to the \u201cModules\u201d section and expand the Forge module. Select the Forge_test submodule and head to the \u201cPaths\u201d tab. Remember the path listed under the \u201cTest output path\u201d label and select the Forge_main submodule from the tree. Open the \u201cDependencies\u201d tab, hit the green plus button on the right-hand side, and select \u201cJARs or directories\u201d. Navigate to the path previously displayed as the Forge_test output path and confirm your selection. For the \u201cScope\u201d of this newly added dependency (currently \u201cCompile\u201d) choose \u201cRuntime\u201d, since the main code does not rely on the test code for compilation. Now that you have added the test mods to the classpath, you need to rebuild them each time you make a change, as they will not be built automatically. To do so, repeat step 1 from the above list or, in case you make changes to a single test mod file and want them to get rebuilt, simply hit Build -> Rebuild project or the corresponding keyboard shortcut (CTRL+F9 by default). Testing with existing mods You might want to test changes in Forge with an existing project. The video by cpw linked in the test mods section also covers this for IDEA 2016.1. Getting the mod to run requires similar steps to the test mod, but getting your project added to the workspace requires some additional work. Open the \u201cProject Structure\u201d Window under File -> Project Structure . Head to the \u201cModules\u201d section and press the green plus icon above the tree view. Select \u201cImport Module\u201d, navigate to your project\u2019s build.gradle file, and confirm your selection as well as the import settings. Close the \u201cProject Structure\u201d window by clicking the \u201cOK\u201d button. Reopen the window after IDEA is done importing the project and select your project\u2019s _main module from the tree. Open the \u201cDependencies\u201d tab, click the green plus icon on the right-hand side, and select \u201cModule dependency\u201d. In the window that just opened, select the Forge_main module. From here on, reproduce the steps from the test mods section, just with your project\u2019s _main module instead of the Forge_test one. Note You might need to remove existing dependencies from a normal development environment (mainly references to a forgeSrc JAR) or move the Forge module higher up in the dependency list. You should now be able to work with your mod using the changes you introduce to the Forge and Vanilla codebase. Making Changes and Pull Requests Once you have set up your development environment, it is time to make some changes to Forge\u2019s codebase. There are, however, some pitfalls you have to avoid when editing the project\u2019s code. The most important thing to note is that if you wish to edit Minecraft source code, you must only do so in the \u201cForge\u201d sub-project. Any changes in the \u201cClean\u201d project will mess with ForgeGradle and generating the patches. This can have disastrous consequences and might render your environment completely useless. If you wish to have a flawless experience, make sure you only edit code in the \u201cForge\u201d project! Generating Patches After you have made changes to the code base and tested them thoroughly, you may go ahead and generate patches. This is only necessary if you work on the Minecraft code base (i.e. in the \u201cForge\u201d project), but this step is vital for your changes to work elsewhere. Forge works by injecting only changed things into Vanilla Minecraft and hence needs those changes available in an appropriate format. Thankfully, ForgeGradle is capable of generating the changeset for you to commit it. To initiate the patch generation, simply run the genPatches Gradle task from your IDE or the command line. After its completion, you can commit all your changes (make sure you do not add any unnecessary files) and submit your Pull Request! Pull Requests The last step before your contribution is added to Forge is a Pull Request (PR in short). This is a formal request to incorporate your fork\u2019s changes into the live code base. Creating a PR is easy. Simply go to this GitHub page and follow the proposed steps. It is now that a good setup with branches pays off, since you are able to select precisely the changes you want to submit. Note Pull Requests are bound to rules; not every request will blindly be accepted. Follow this document to get further information and to ensure the best quality of your PR! If you want to maximize the chances of your PR getting accepted, follow these PR guidelines !","title":"Introduction"},{"location":"forgedev/#getting-started","text":"If you have decided to contribute to Forge, you will have to take some special steps to get started with developing. A simple mod development environment will not suffice to work with Forge\u2019s codebase directly. Instead, you can use the following guide to help you with your setup and get you started with improving Forge!","title":"Getting Started"},{"location":"forgedev/#forking-and-cloning-the-repository","text":"Like most major open source projects you will find, Forge is hosted on GitHub . If you have contributed to another project before, you will know this process already and can skip right ahead to the next section. For those who are beginners when it comes to collaboration via Git, here are two easy steps to get you started. Note This guide assumes that you already have a GitHub account set up. If you do not, visit their registration page to create an account. Furthermore, this guide is not a tutorial for git\u2019s usage. Please consult different sources first if you are struggling to get it working.","title":"Forking and Cloning the Repository"},{"location":"forgedev/#forking","text":"First of all, you have to \u201cfork\u201d the MinecraftForge repository by clicking the \u201cFork\u201d button in the upper right hand corner. If you are in an organization, select the account you want your fork to be hosted on. Forking the repository is necessary since not every GitHub user can have free access to every repository. Instead, you create a copy of the original repository to later contribute your changes via a so called Pull Request, which you will learn more about later.","title":"Forking"},{"location":"forgedev/#cloning","text":"After forking the repository, it is time to get local access to actually make some changes. For this, you need to clone the repository onto your local machine. Using your favorite git client, simply clone your fork into a directory of your choice. As general example, here is a command line snippet that should work on all correctly configured systems and clones the repository into a directory called \u201cMinecraftForge\u201d under the current directory (note that you have to replace <User> with your username): git clone https://github.com/<User>/MinecraftForge","title":"Cloning"},{"location":"forgedev/#checking-out-the-correct-branch","text":"Forking and cloning the repository are the only mandatory steps to develop for Forge. However, to ease the process of creating Pull Requests for you, it is best to work with branches. It is recommended to create and check out a branch for each PR you plan to submit. This way, you can always keep around the latest changes of Forge for new PRs while you still work on older patches. After completing this step, you are ready to go and set up your development environment.","title":"Checking out the Correct Branch"},{"location":"forgedev/#setting-up-the-environment","text":"Depending on your favorite IDE, there is a different set of recommended steps you have to follow to successfully set up a development environment.","title":"Setting Up the Environment"},{"location":"forgedev/#eclipse","text":"Due to the way Eclipse workspaces work, ForgeGradle can do most of the work involved to get you started with a Forge workspace. Open a terminal/command prompt and navigate to the directory of your cloned fork. Type ./gradlew setup and hit enter. Wait until ForgeGradle is done. Type ./gradlew genEclipseRuns and hit enter. Once again, wait until ForgeGradle is done. Open your Eclipse workspace and go to File -> Import -> General -> Existing Gradle Project . Browse to the repo directory for the \u201cProject root directory\u201d option in the dialog that opens. Complete the import by clicking the \u201cFinish\u201d button. That is all it takes to get you up and running with Eclipse. There is no extra steps required to get the test mods running. Simply hit \u201cRun\u201d like in any other project and select the appropriate run configuration.","title":"Eclipse"},{"location":"forgedev/#intellij-idea","text":"JetBrains\u2019 flagship IDE comes with great integrated support for Gradle : Forge\u2019s build system of choice. Due to some peculiarities of Minecraft mod development, however, there are additional steps required to get everything to work properly.","title":"IntelliJ IDEA"},{"location":"forgedev/#idea-2021-onwards","text":"Start IntelliJ IDEA 2021. If you already have another project open, close the project with the File -> Close project option. In the projects tab of the \u201cWelcome to IntelliJ IDEA\u201d window, click the \u201cOpen\u201d button on the top right and select the MinecraftForge folder you cloned earlier. Click \u201cTrust Project\u201d if prompted. After IDEA is done importing the project and indexing its files, run the Gradle setup task. You can do this by: Open the Gradle sidebar on the right hand side of your screen, then open the forge project tree, select Tasks, then other and double-click the setup task (may also appear as MinecraftForge[Setup] ) found in Forge -> Tasks -> other -> setup . Generate the run configurations: Open the Gradle sidebar on the right hand side of your screen, then open the forge project tree, select Tasks, then other and double-click the genIntellijRuns task (may also appear as MinecraftForge[genIntellijRuns] ) found in Forge -> Tasks -> forgegradle runs -> genIntellijRuns . If you get a licensing error during build before making any changes, running the updateLicenses task may help. This task is found in Forge -> Tasks -> other as well.","title":"IDEA 2021 onwards"},{"location":"forgedev/#idea-2019-2020","text":"There are a few minor differences between IDEA 2021 and these versions for setup. Import Forge\u2019s build.gradle as an IDEA project. For this, simply click Import Project from the Welcome to IntelliJ IDEA splash screen, then select the build.gradle file. After IDEA is done importing the project and indexing the files, run the Gradle setup task. Either: Open the Gradle sidebar on the right hand side of your screen, then open the forge project tree, select Tasks , then other and double-click the setup task (may also appear as MinecraftForge[Setup] . Or alternatively: Tap the CTRL key twice, and type gradle setup in the Run command window that pops up. You can then run Forge using the forge_client gradle task ( Tasks -> fg_runs -> forge_client ): right-click the task and select either Run or Debug as desired.","title":"IDEA 2019-2020"},{"location":"forgedev/#idea-older-versions","text":"Versions older than 2016 will not work because they did not have the appropriate Gradle support nor support Forge development multi-project workspaces. IDEA 2016 - 2018 will work with extra manual steps required, but it is strongly recommended to update to IDEA 2019+ instead. cpw has uploaded a video for IDEA 2016.1 explaining very similar steps which will lead to a working setup. That is all there is to creating a Forge development environment in IntelliJ IDEA. However, you will not be able to run tests and debug mods included in Forge straight away. This takes some extra effort.","title":"IDEA older versions"},{"location":"forgedev/#enabling-test-mods","text":"To enable the test mods coming with Forge, you will need to add the compiler output to the classpath. Again, cpw has put up a video explaining these steps for IDEA 2016.1. Build the test classes by selecting the src/main/test directory in your project view and then run Build -> Build module 'Forge_test' from the menu bar. Open the \u201cProject Structure\u201d window under File -> Project Structure . Head to the \u201cModules\u201d section and expand the Forge module. Select the Forge_test submodule and head to the \u201cPaths\u201d tab. Remember the path listed under the \u201cTest output path\u201d label and select the Forge_main submodule from the tree. Open the \u201cDependencies\u201d tab, hit the green plus button on the right-hand side, and select \u201cJARs or directories\u201d. Navigate to the path previously displayed as the Forge_test output path and confirm your selection. For the \u201cScope\u201d of this newly added dependency (currently \u201cCompile\u201d) choose \u201cRuntime\u201d, since the main code does not rely on the test code for compilation. Now that you have added the test mods to the classpath, you need to rebuild them each time you make a change, as they will not be built automatically. To do so, repeat step 1 from the above list or, in case you make changes to a single test mod file and want them to get rebuilt, simply hit Build -> Rebuild project or the corresponding keyboard shortcut (CTRL+F9 by default).","title":"Enabling test mods"},{"location":"forgedev/#testing-with-existing-mods","text":"You might want to test changes in Forge with an existing project. The video by cpw linked in the test mods section also covers this for IDEA 2016.1. Getting the mod to run requires similar steps to the test mod, but getting your project added to the workspace requires some additional work. Open the \u201cProject Structure\u201d Window under File -> Project Structure . Head to the \u201cModules\u201d section and press the green plus icon above the tree view. Select \u201cImport Module\u201d, navigate to your project\u2019s build.gradle file, and confirm your selection as well as the import settings. Close the \u201cProject Structure\u201d window by clicking the \u201cOK\u201d button. Reopen the window after IDEA is done importing the project and select your project\u2019s _main module from the tree. Open the \u201cDependencies\u201d tab, click the green plus icon on the right-hand side, and select \u201cModule dependency\u201d. In the window that just opened, select the Forge_main module. From here on, reproduce the steps from the test mods section, just with your project\u2019s _main module instead of the Forge_test one. Note You might need to remove existing dependencies from a normal development environment (mainly references to a forgeSrc JAR) or move the Forge module higher up in the dependency list. You should now be able to work with your mod using the changes you introduce to the Forge and Vanilla codebase.","title":"Testing with existing mods"},{"location":"forgedev/#making-changes-and-pull-requests","text":"Once you have set up your development environment, it is time to make some changes to Forge\u2019s codebase. There are, however, some pitfalls you have to avoid when editing the project\u2019s code. The most important thing to note is that if you wish to edit Minecraft source code, you must only do so in the \u201cForge\u201d sub-project. Any changes in the \u201cClean\u201d project will mess with ForgeGradle and generating the patches. This can have disastrous consequences and might render your environment completely useless. If you wish to have a flawless experience, make sure you only edit code in the \u201cForge\u201d project!","title":"Making Changes and Pull Requests"},{"location":"forgedev/#generating-patches","text":"After you have made changes to the code base and tested them thoroughly, you may go ahead and generate patches. This is only necessary if you work on the Minecraft code base (i.e. in the \u201cForge\u201d project), but this step is vital for your changes to work elsewhere. Forge works by injecting only changed things into Vanilla Minecraft and hence needs those changes available in an appropriate format. Thankfully, ForgeGradle is capable of generating the changeset for you to commit it. To initiate the patch generation, simply run the genPatches Gradle task from your IDE or the command line. After its completion, you can commit all your changes (make sure you do not add any unnecessary files) and submit your Pull Request!","title":"Generating Patches"},{"location":"forgedev/#pull-requests","text":"The last step before your contribution is added to Forge is a Pull Request (PR in short). This is a formal request to incorporate your fork\u2019s changes into the live code base. Creating a PR is easy. Simply go to this GitHub page and follow the proposed steps. It is now that a good setup with branches pays off, since you are able to select precisely the changes you want to submit. Note Pull Requests are bound to rules; not every request will blindly be accepted. Follow this document to get further information and to ensure the best quality of your PR! If you want to maximize the chances of your PR getting accepted, follow these PR guidelines !","title":"Pull Requests"},{"location":"forgedev/prguidelines/","text":"Pull Request Guidelines Mods are built on top of Forge, but there are some things that Forge does not support, and that limits what mods can do. When modders run into something like that, they can make a change to Forge to support it, and submit that change as a Pull Request on Github. To make the best use of both your and the Forge team\u2019s time, it is recommended to follow some rough guidelines when preparing a Pull Request. The following points are the most important aspects to keep in mind when it comes to writing a good Pull Request. What Exactly is Forge? At a high level, Forge is a mod compatibility layer on top of Minecraft. Early mods edited Minecraft\u2019s code directly (like coremods do now), but they ran into conflicts with each other when they edited the same things. They also ran into issues when one mod changed behavior in ways that the other mods could not anticipate (like coremods do now), causing mysterious issues and lots of headaches. By using something like Forge, mods can centralize common changes and avoid conflicts. Forge also includes supporting structures for common mod features like Capabilities, Registries, and others that allow mods to work together better. When writing a good Forge Pull Request, you also have to know what Forge is at a lower level. There are two main types of code in Forge: Minecraft patches, and Forge code. Patches Patches are applied as direct changes to Minecraft\u2019s source code, and aim to be as minimal as possible. Every time Minecraft code changes, all the Forge patches need to be looked over carefully and applied correctly to the new code. This means that large patches that change lots of things are difficult to maintain, so Forge aims to avoid those and keep patches as small as possible. In addition to making sure the code makes sense, reviews for patches will focus on minimizing the size. There are many strategies to make small patches, and reviews will often point out better methods to do things. Forge patches often insert a single line that fires an event or a code hook, which affects the code after it if the event meets some condition. This allows most of the code to exist outside of the patch, which keeps the patch small and simple. For more detailed information about creating patches, see the GitHub wiki . Forge Code Aside from the patches, Forge code is just normal Java code. It can be event code, compatibility features, or anything else that is not directly editing Minecraft code. When Minecraft updates, Forge code has to update just like everything else. However, it is much easier because it is not directly entangled in the Minecraft code. Because this code stands on its own, there is no size restriction like there is with the patches. In addition to making sure the code makes sense, reviews will focus on making the code clean: with proper formatting and Java documentation. Explain Yourself All Pull Requests need to answer the question: why is this necessary? Any code added to Forge needs to be maintained, and more code means more potential for bugs, so solid justification is needed for adding code. A common Pull Request issue is offering no explanation, or giving cryptic examples for how the Pull Request might theoretically be used. This only delays the Pull Request process. A clear explanation for the general case is good, but also give a concrete example of how your mod needs this Pull Request. Sometimes there is better way to do what you wanted, or a way to do it without a Pull Request at all. Code changes can not be accepted until those possibilities have been completely ruled out. Show that it Works The code you submit to Forge should work perfectly, and it is up to you to convince the reviewers that it does. One of the best ways to do that is to add an example mod or JUnit test to Forge that makes use of your new code and shows it working. To set up and run a Forge Environment with the example mods, see this guide . Breaking Changes in Forge Forge cannot make changes that break the mods that depend on it. This means that Pull Requests have to ensure that they do not break binary compatibility with previous Forge versions. A change that breaks binary compatibility is called a Breaking Change. There are some exceptions to this: Forge accepts Breaking Changes at the beginning of new Minecraft versions, where Minecraft itself already causes Breaking Changes for modders. Sometimes an emergency breaking change is required outside of that time window, but it is rare and can cause dependency headaches for everyone in the modded Minecraft community. Outside of those exceptional times, Pull Requests with breaking changes are not accepted. They must be adapted to support the old behavior or wait for the next Minecraft version. Be Patient, Civil, and Empathetic When submitting Pull Requests, you will often have to survive code review and make several changes before it is the best Pull Request possible. Keep in mind that code review is not judgement against you. Bugs in your code are not personal. Nobody is perfect, and that is why we are working together. Negativity will not help. Threatening to give up on your Pull Request and write a coremod instead will just make people upset and make the modded ecosystem worse. It is important that while working together you assume the best intentions of the people who are reviewing your Pull Request and not take things personally. Review If you do your best to understand the slow and perfectionistic nature of the Pull Request process, we will do our best to understand your point of view as well. After your Pull Request has been reviewed and cleaned up to the best of everyone\u2019s ability, it will be marked for a final review by Lex, who has the final say on what is included in the project or not.","title":"Pull Request Guidelines"},{"location":"forgedev/prguidelines/#pull-request-guidelines","text":"Mods are built on top of Forge, but there are some things that Forge does not support, and that limits what mods can do. When modders run into something like that, they can make a change to Forge to support it, and submit that change as a Pull Request on Github. To make the best use of both your and the Forge team\u2019s time, it is recommended to follow some rough guidelines when preparing a Pull Request. The following points are the most important aspects to keep in mind when it comes to writing a good Pull Request.","title":"Pull Request Guidelines"},{"location":"forgedev/prguidelines/#what-exactly-is-forge","text":"At a high level, Forge is a mod compatibility layer on top of Minecraft. Early mods edited Minecraft\u2019s code directly (like coremods do now), but they ran into conflicts with each other when they edited the same things. They also ran into issues when one mod changed behavior in ways that the other mods could not anticipate (like coremods do now), causing mysterious issues and lots of headaches. By using something like Forge, mods can centralize common changes and avoid conflicts. Forge also includes supporting structures for common mod features like Capabilities, Registries, and others that allow mods to work together better. When writing a good Forge Pull Request, you also have to know what Forge is at a lower level. There are two main types of code in Forge: Minecraft patches, and Forge code.","title":"What Exactly is Forge?"},{"location":"forgedev/prguidelines/#patches","text":"Patches are applied as direct changes to Minecraft\u2019s source code, and aim to be as minimal as possible. Every time Minecraft code changes, all the Forge patches need to be looked over carefully and applied correctly to the new code. This means that large patches that change lots of things are difficult to maintain, so Forge aims to avoid those and keep patches as small as possible. In addition to making sure the code makes sense, reviews for patches will focus on minimizing the size. There are many strategies to make small patches, and reviews will often point out better methods to do things. Forge patches often insert a single line that fires an event or a code hook, which affects the code after it if the event meets some condition. This allows most of the code to exist outside of the patch, which keeps the patch small and simple. For more detailed information about creating patches, see the GitHub wiki .","title":"Patches"},{"location":"forgedev/prguidelines/#forge-code","text":"Aside from the patches, Forge code is just normal Java code. It can be event code, compatibility features, or anything else that is not directly editing Minecraft code. When Minecraft updates, Forge code has to update just like everything else. However, it is much easier because it is not directly entangled in the Minecraft code. Because this code stands on its own, there is no size restriction like there is with the patches. In addition to making sure the code makes sense, reviews will focus on making the code clean: with proper formatting and Java documentation.","title":"Forge Code"},{"location":"forgedev/prguidelines/#explain-yourself","text":"All Pull Requests need to answer the question: why is this necessary? Any code added to Forge needs to be maintained, and more code means more potential for bugs, so solid justification is needed for adding code. A common Pull Request issue is offering no explanation, or giving cryptic examples for how the Pull Request might theoretically be used. This only delays the Pull Request process. A clear explanation for the general case is good, but also give a concrete example of how your mod needs this Pull Request. Sometimes there is better way to do what you wanted, or a way to do it without a Pull Request at all. Code changes can not be accepted until those possibilities have been completely ruled out.","title":"Explain Yourself"},{"location":"forgedev/prguidelines/#show-that-it-works","text":"The code you submit to Forge should work perfectly, and it is up to you to convince the reviewers that it does. One of the best ways to do that is to add an example mod or JUnit test to Forge that makes use of your new code and shows it working. To set up and run a Forge Environment with the example mods, see this guide .","title":"Show that it Works"},{"location":"forgedev/prguidelines/#breaking-changes-in-forge","text":"Forge cannot make changes that break the mods that depend on it. This means that Pull Requests have to ensure that they do not break binary compatibility with previous Forge versions. A change that breaks binary compatibility is called a Breaking Change. There are some exceptions to this: Forge accepts Breaking Changes at the beginning of new Minecraft versions, where Minecraft itself already causes Breaking Changes for modders. Sometimes an emergency breaking change is required outside of that time window, but it is rare and can cause dependency headaches for everyone in the modded Minecraft community. Outside of those exceptional times, Pull Requests with breaking changes are not accepted. They must be adapted to support the old behavior or wait for the next Minecraft version.","title":"Breaking Changes in Forge"},{"location":"forgedev/prguidelines/#be-patient-civil-and-empathetic","text":"When submitting Pull Requests, you will often have to survive code review and make several changes before it is the best Pull Request possible. Keep in mind that code review is not judgement against you. Bugs in your code are not personal. Nobody is perfect, and that is why we are working together. Negativity will not help. Threatening to give up on your Pull Request and write a coremod instead will just make people upset and make the modded ecosystem worse. It is important that while working together you assume the best intentions of the people who are reviewing your Pull Request and not take things personally.","title":"Be Patient, Civil, and Empathetic"},{"location":"forgedev/prguidelines/#review","text":"If you do your best to understand the slow and perfectionistic nature of the Pull Request process, we will do our best to understand your point of view as well. After your Pull Request has been reviewed and cleaned up to the best of everyone\u2019s ability, it will be marked for a final review by Lex, who has the final say on what is included in the project or not.","title":"Review"},{"location":"gameeffects/particles/","text":"Particles Particles are an effect within the game used as polish to better improve immersion. Their usefulness also requires great caution because of their methods of creation and reference. Creating a Particle Particles are broken up between its client only implementation to display the particle and its common implementation to reference the particle or sync data from the server. Class Side Description ParticleType BOTH The registry object of a particle\u2019s type definition used to reference the particle on either side ParticleOptions BOTH A data holder used to sync information from the network or a command to the associated client(s) ParticleProvider CLIENT A factory registered by the ParticleType used to construct a Particle from the associated ParticleOptions . Particle CLIENT The renderable logic to display on the associated client(s) ParticleType A ParticleType is the registry object defining what a particular particle type is and provides an available reference to the specific particle on both sides. As such, every ParticleType must be registered . Each ParticleType takes in two parameters: an overrideLimiter which determines whether the particle renders regardless of distance, and a ParticleOptions$Deserializer which is used to read the sent ParticleOptions on the client. As the base ParticleType is abstract, a single method needs to be implemented: #codec . This represents how to encode and decode the associated ParticleOptions of the type. Note ParticleType#codec is only used within the biome codec for vanilla implementations. In most cases, there is no need to have any particle data sent to the client. For these instances, it is easier to create a new instance of SimpleParticleType : an implementation of ParticleType and ParticleOptions which does not send any custom data to the client besides the type. Most vanilla implementations use SimpleParticleType besides redstone dust for coloring and block/item dependent particles. Important A ParticleType is not needed to make a particle spawn if only referenced on the client. However, it is necessary to use any of the prebuilt logic within ParticleEngine or spawn a particle from the server. ParticleOptions An ParticleOptions represents the data that each particle takes in. It is also used to send data from particles spawned via the server. All particle spawning methods take in a ParticleOptions such that it knows the type of the particle and the data associated with spawning one. ParticleOptions is broken down into three methods: Method Description getType Gets the type definition of the particle, or the ParticleType writeToNetwork Writes the particle data to a buffer on the server to send to the client writeToString Writes the particle data to a string These objects are either constructed on the fly as needed, or they are singletons as a result of being a SimpleParticleType . ParticleOptions$Deserializer To receive the ParticleOptions on the client, or to reference the data within a command, the particle data must be deserialized via ParticleOptions$Deserializer . Each method within ParticleOptions$Deserializer has a parity encoding method within ParticleOptions : Method ParticleOptions Encoder Description fromCommand writeToString Decodes a particle data from a string, usually from a command. fromNetwork writeToNetwork Decodes a particle data from a buffer on the client. This object, when needing to send custom particle data, is passed into the constructor of the ParticleType . Particle A Particle provides the rendering logic needed to draw said data onto the screen. To create any Particle , two methods must be implemented: Method Description render Renders the particle onto the screen. getRenderType Gets the render type of the particle. A common subclass of Particle to render textures is TextureSheetParticle . While #getRenderType needs to be implemented, whatever the texture sprite is set will be rendered at the particle\u2019s location. ParticleRenderType ParticleRenderType is a variation on RenderType which constructs the startup and teardown phase for every particle of that type and then renders them all at once via the Tesselator . There are six different render types a particle can be in. Render Type Description TERRAIN_SHEET Renders a particle whose texture is located within the available blocks. PARTICLE_SHEET_OPAQUE Renders a particle whose texture is opaque and located within the available particles. PARTICLE_SHEET_TRANSLUCENT Renders a particle whose texture is translucent and located within the available particles. PARTICLE_SHEET_LIT Same as PARTICLE_SHEET_OPAQUE except without using the particle shader. CUSTOM Provides setup for blending and depth mask but provides no rendering functionality as that would be implemented within Particle#render . NO_RENDER The particle will never render. Implementing a custom render type will be left as an exercise to the reader. ParticleProvider Finally, a particle is usually created via an ParticleProvider . A factory has a single method #createParticle which is used to create a particle given the particle data, client level, position, and movement delta. Since a Particle is not beholden to any particular ParticleType , it can be reused in different factories as necessary. An ParticleProvider must be registered by subscribing to the ParticleFactoryRegisterEvent on the mod event bus . Within the event, the factory can be registered via ParticleEngine#register by supplying an instance of the factory to the method. Important ParticleFactoryRegisterEvent should only be called on the client and thus sided off in some isolated client class, referenced by either DistExecutor or @EventBusSubscriber . ParticleDescription, SpriteSet, and SpriteParticleRegistration There are three particle render types that cannot use the above method of registration: PARTICLE_SHEET_OPAQUE , PARTICLE_SHEET_TRANSLUCENT , and PARTICLE_SHEET_LIT . This is because all three of these particle render types use a sprite set that is loaded by the ParticleEngine directly. As such, the textures supplied must be obtained and registered through a different method. This will assume your particle is a subtype of TextureSheetParticle as that is the only vanilla implementation for this logic. To add a texture to a particle, a new JSON file must be added to assets/<modid>/particles . This is known as the ParticleDescription . The name of this file will represent the registry name of the ParticleType the factory is being attached to. Each particle JSON is an object. The object stores a single key textures which holds an array of ResourceLocation s. Any <modid>:<path> texture represented here will point to a texture at assets/<modid>/textures/particle/<path>.png . { \"textures\": [ // Will point to a texture located in // assets/mymod/textures/particle/particle_texture.png \"mymod:particle_texture\", // Textures should by ordered by drawing order // e.g. particle_texture will render first, then particle_texture2 // after some time \"mymod:particle_texture2\" ] } To reference a particle texture, the subtype of TextureSheetParticle should either take in an SpriteSet or a TextureAtlasSprite obtained from SpriteSet . SpriteSet holds a list of textures which refer to the sprites as defined by our ParticleDescription . SpriteSet has two methods, both of which grab a TextureAtlasSprite in different methods. The first method takes in two integers. The backing implementation allows the sprite to have a texture change as it ages. The second method takes in a Random instance to get a random texture from the sprite set. The sprite can be set within TextureSheetParticle by using one of the helper methods that takes in the SpriteSet : #pickSprite which uses the random method of picking a texture, and #setSpriteFromAge which uses the percentage method of two integers to pick the texture. To register these particle textures, a SpriteParticleRegistration needs to be supplied to the ParticleEngine#register method. This method takes in an SpriteSet holding the associated sprite set for the particle and creates an ParticleProvider to create the particle. The simplest method of implementation can be done by implementing ParticleProvider on some class and having the constructor take in an SpriteSet . Then the SpriteSet can be passed to the particle as normal. Spawning a Particle Particles can be spawned from either level instance. However, each side has a specific way to spawn a particle. If on the ClientLevel , #addParticle can be called to spawn a particle or #addAlwaysVisibleParticle can be called to spawn a particle that is visible from any distance. If on the ServerLevel , #sendParticles can be called to send a packet to the client to spawn the particle. Calling the two ClientLevel methods on the server will result in nothing.","title":"Particles"},{"location":"gameeffects/particles/#particles","text":"Particles are an effect within the game used as polish to better improve immersion. Their usefulness also requires great caution because of their methods of creation and reference.","title":"Particles"},{"location":"gameeffects/particles/#creating-a-particle","text":"Particles are broken up between its client only implementation to display the particle and its common implementation to reference the particle or sync data from the server. Class Side Description ParticleType BOTH The registry object of a particle\u2019s type definition used to reference the particle on either side ParticleOptions BOTH A data holder used to sync information from the network or a command to the associated client(s) ParticleProvider CLIENT A factory registered by the ParticleType used to construct a Particle from the associated ParticleOptions . Particle CLIENT The renderable logic to display on the associated client(s)","title":"Creating a Particle"},{"location":"gameeffects/particles/#particletype","text":"A ParticleType is the registry object defining what a particular particle type is and provides an available reference to the specific particle on both sides. As such, every ParticleType must be registered . Each ParticleType takes in two parameters: an overrideLimiter which determines whether the particle renders regardless of distance, and a ParticleOptions$Deserializer which is used to read the sent ParticleOptions on the client. As the base ParticleType is abstract, a single method needs to be implemented: #codec . This represents how to encode and decode the associated ParticleOptions of the type. Note ParticleType#codec is only used within the biome codec for vanilla implementations. In most cases, there is no need to have any particle data sent to the client. For these instances, it is easier to create a new instance of SimpleParticleType : an implementation of ParticleType and ParticleOptions which does not send any custom data to the client besides the type. Most vanilla implementations use SimpleParticleType besides redstone dust for coloring and block/item dependent particles. Important A ParticleType is not needed to make a particle spawn if only referenced on the client. However, it is necessary to use any of the prebuilt logic within ParticleEngine or spawn a particle from the server.","title":"ParticleType"},{"location":"gameeffects/particles/#particleoptions","text":"An ParticleOptions represents the data that each particle takes in. It is also used to send data from particles spawned via the server. All particle spawning methods take in a ParticleOptions such that it knows the type of the particle and the data associated with spawning one. ParticleOptions is broken down into three methods: Method Description getType Gets the type definition of the particle, or the ParticleType writeToNetwork Writes the particle data to a buffer on the server to send to the client writeToString Writes the particle data to a string These objects are either constructed on the fly as needed, or they are singletons as a result of being a SimpleParticleType .","title":"ParticleOptions"},{"location":"gameeffects/particles/#particleoptionsdeserializer","text":"To receive the ParticleOptions on the client, or to reference the data within a command, the particle data must be deserialized via ParticleOptions$Deserializer . Each method within ParticleOptions$Deserializer has a parity encoding method within ParticleOptions : Method ParticleOptions Encoder Description fromCommand writeToString Decodes a particle data from a string, usually from a command. fromNetwork writeToNetwork Decodes a particle data from a buffer on the client. This object, when needing to send custom particle data, is passed into the constructor of the ParticleType .","title":"ParticleOptions$Deserializer"},{"location":"gameeffects/particles/#particle","text":"A Particle provides the rendering logic needed to draw said data onto the screen. To create any Particle , two methods must be implemented: Method Description render Renders the particle onto the screen. getRenderType Gets the render type of the particle. A common subclass of Particle to render textures is TextureSheetParticle . While #getRenderType needs to be implemented, whatever the texture sprite is set will be rendered at the particle\u2019s location.","title":"Particle"},{"location":"gameeffects/particles/#particlerendertype","text":"ParticleRenderType is a variation on RenderType which constructs the startup and teardown phase for every particle of that type and then renders them all at once via the Tesselator . There are six different render types a particle can be in. Render Type Description TERRAIN_SHEET Renders a particle whose texture is located within the available blocks. PARTICLE_SHEET_OPAQUE Renders a particle whose texture is opaque and located within the available particles. PARTICLE_SHEET_TRANSLUCENT Renders a particle whose texture is translucent and located within the available particles. PARTICLE_SHEET_LIT Same as PARTICLE_SHEET_OPAQUE except without using the particle shader. CUSTOM Provides setup for blending and depth mask but provides no rendering functionality as that would be implemented within Particle#render . NO_RENDER The particle will never render. Implementing a custom render type will be left as an exercise to the reader.","title":"ParticleRenderType"},{"location":"gameeffects/particles/#particleprovider","text":"Finally, a particle is usually created via an ParticleProvider . A factory has a single method #createParticle which is used to create a particle given the particle data, client level, position, and movement delta. Since a Particle is not beholden to any particular ParticleType , it can be reused in different factories as necessary. An ParticleProvider must be registered by subscribing to the ParticleFactoryRegisterEvent on the mod event bus . Within the event, the factory can be registered via ParticleEngine#register by supplying an instance of the factory to the method. Important ParticleFactoryRegisterEvent should only be called on the client and thus sided off in some isolated client class, referenced by either DistExecutor or @EventBusSubscriber .","title":"ParticleProvider"},{"location":"gameeffects/particles/#particledescription-spriteset-and-spriteparticleregistration","text":"There are three particle render types that cannot use the above method of registration: PARTICLE_SHEET_OPAQUE , PARTICLE_SHEET_TRANSLUCENT , and PARTICLE_SHEET_LIT . This is because all three of these particle render types use a sprite set that is loaded by the ParticleEngine directly. As such, the textures supplied must be obtained and registered through a different method. This will assume your particle is a subtype of TextureSheetParticle as that is the only vanilla implementation for this logic. To add a texture to a particle, a new JSON file must be added to assets/<modid>/particles . This is known as the ParticleDescription . The name of this file will represent the registry name of the ParticleType the factory is being attached to. Each particle JSON is an object. The object stores a single key textures which holds an array of ResourceLocation s. Any <modid>:<path> texture represented here will point to a texture at assets/<modid>/textures/particle/<path>.png . { \"textures\": [ // Will point to a texture located in // assets/mymod/textures/particle/particle_texture.png \"mymod:particle_texture\", // Textures should by ordered by drawing order // e.g. particle_texture will render first, then particle_texture2 // after some time \"mymod:particle_texture2\" ] } To reference a particle texture, the subtype of TextureSheetParticle should either take in an SpriteSet or a TextureAtlasSprite obtained from SpriteSet . SpriteSet holds a list of textures which refer to the sprites as defined by our ParticleDescription . SpriteSet has two methods, both of which grab a TextureAtlasSprite in different methods. The first method takes in two integers. The backing implementation allows the sprite to have a texture change as it ages. The second method takes in a Random instance to get a random texture from the sprite set. The sprite can be set within TextureSheetParticle by using one of the helper methods that takes in the SpriteSet : #pickSprite which uses the random method of picking a texture, and #setSpriteFromAge which uses the percentage method of two integers to pick the texture. To register these particle textures, a SpriteParticleRegistration needs to be supplied to the ParticleEngine#register method. This method takes in an SpriteSet holding the associated sprite set for the particle and creates an ParticleProvider to create the particle. The simplest method of implementation can be done by implementing ParticleProvider on some class and having the constructor take in an SpriteSet . Then the SpriteSet can be passed to the particle as normal.","title":"ParticleDescription, SpriteSet, and SpriteParticleRegistration"},{"location":"gameeffects/particles/#spawning-a-particle","text":"Particles can be spawned from either level instance. However, each side has a specific way to spawn a particle. If on the ClientLevel , #addParticle can be called to spawn a particle or #addAlwaysVisibleParticle can be called to spawn a particle that is visible from any distance. If on the ServerLevel , #sendParticles can be called to send a packet to the client to spawn the particle. Calling the two ClientLevel methods on the server will result in nothing.","title":"Spawning a Particle"},{"location":"gameeffects/sounds/","text":"Sounds Terminology Term Description Sound Events Something that triggers a sound effect. Examples include minecraft:block.anvil.hit or botania:spreader_fire . Sound Category The category of the sound, for example player , block or simply master . The sliders in the sound settings GUI represent these categories. Sound File The literal file on disk that is played: an .ogg file. sounds.json This JSON defines sound events, and defines which sound files they play, the subtitle, etc. Sound events are identified with ResourceLocation s. sounds.json should be located at the root of a resource namespace ( assets/<namespace>/sounds.json ), and it defines sound events in that namespace ( assets/<namespace>/sounds.json defines sound events in the namespace namespace .). A full specification is available on the vanilla wiki , but this example highlights the important parts: { \"open_chest\": { \"subtitle\": \"mymod.subtitle.open_chest\", \"sounds\": [ \"mymod:open_chest_sound_file\" ] }, \"epic_music\": { \"sounds\": [ { \"name\": \"mymod:music/epic_music\", \"stream\": true } ] } } Underneath the top-level object, each key corresponds to a sound event. Note that the namespace is not given, as it is taken from the namespace of the JSON itself. Each event specifies a localization key to be shown when subtitles are enabled. Finally, the actual sound files to be played are specified. Note that the value is an array; if multiple sound files are specified, the game will randomly choose one to play whenever the sound event is triggered. The two examples represent two different ways to specify a sound file. The wiki has precise details, but generally, long sound files such as background music or music discs should use the second form, because the \u201cstream\u201d argument tells Minecraft to not load the entire sound file into memory but to stream it from disk. The second form can also specify the volume, pitch, and weight of a sound file. In all cases, the path to a sound file for namespace namespace and path path is assets/<namespace>/sounds/<path>.ogg . Therefore mymod:open_chest_sound_file points to assets/mymod/sounds/open_chest_sound_file.ogg , and mymod:music/epic_music points to assets/mymod/sounds/music/epic_music.ogg . A sounds.json can be data generated . Creating Sound Events In order to reference sounds on the server, a SoundEvent holding a corresponding entry in sounds.json must be created. This SoundEvent must then be registered . Normally, the location used to create a sound event should be set as it\u2019s registry name. The SoundEvent acts as a reference to the sound and is passed around to play them. If a mod has an API, it should expose its SoundEvent s in the API. Note As long as a sound is registered within the sounds.json , it can still be referenced on the logical client regardless of whether there is a referencing SoundEvent . Playing Sounds Vanilla has lots of methods for playing sounds, and it is unclear which to use at times. Note that each takes a SoundEvent , the ones registered above. Additionally, the terms \u201cServer Behavior\u201d and \u201cClient Behavior\u201d refer to the respective logical side . Level playSound(Player, BlockPos, SoundEvent, SoundCategory, volume, pitch) Simply forwards to overload (2) , adding 0.5 to each coordinate of the BlockPos given. playSound(Player, double x, double y, double z, SoundEvent, SoundCategory, volume, pitch) Client Behavior : If the passed in player is the client player, plays the sound event to the client player. Server Behavior : Plays the sound event to everyone nearby except the passed in player. Player can be null . Usage : The correspondence between the behaviors implies that these two methods are to be called from some player-initiated code that will be run on both logical sides at the same time: the logical client handles playing it to the user, and the logical server handles everyone else hearing it without re-playing it to the original user. They can also be used to play any sound in general at any position server-side by calling it on the logical server and passing in a null player, thus letting everyone hear it. playLocalSound(double x, double y, double z, SoundEvent, SoundCategory, volume, pitch, distanceDelay) Client Behavior : Just plays the sound event in the client level. If distanceDelay is true , then delays the sound based on how far it is from the player. Server Behavior : Does nothing. Usage : This method only works client-side, and thus is useful for sounds sent in custom packets, or other client-only effect-type sounds. Used for thunder. ClientLevel playLocalSound(BlockPos, SoundEvent, SoundCategory, volume, pitch, distanceDelay) Simply forwards to Level \u2018s overload (3) , adding 0.5 to each coordinate of the BlockPos given. Entity playSound(SoundEvent, volume, pitch) Forwards to Level \u2018s overload (2) , passing in null as the player. Client Behavior : Does nothing. Server Behavior : Plays the sound event to everyone at this entity\u2019s position. Usage : Emitting any sound from any non-player entity server-side. Player playSound(SoundEvent, volume, pitch) (overriding the one in Entity ) Forwards to Level \u2018s overload (2) , passing in this as the player. Client Behavior : Does nothing, see override in LocalPlayer . Server Behavior : Plays the sound to everyone nearby except this player. Usage : See LocalPlayer . LocalPlayer playSound(SoundEvent, volume, pitch) (overriding the one in Player ) Forwards to Level \u2018s overload (2) , passing in this as the player. Client Behavior : Just plays the Sound Event. Server Behavior : Method is client-only. Usage : Just like the ones in Level , these two overrides in the player classes seem to be for code that runs together on both sides. The client handles playing the sound to the user, while the server handles everyone else hearing it without re-playing to the original user.","title":"Sounds"},{"location":"gameeffects/sounds/#sounds","text":"","title":"Sounds"},{"location":"gameeffects/sounds/#terminology","text":"Term Description Sound Events Something that triggers a sound effect. Examples include minecraft:block.anvil.hit or botania:spreader_fire . Sound Category The category of the sound, for example player , block or simply master . The sliders in the sound settings GUI represent these categories. Sound File The literal file on disk that is played: an .ogg file.","title":"Terminology"},{"location":"gameeffects/sounds/#soundsjson","text":"This JSON defines sound events, and defines which sound files they play, the subtitle, etc. Sound events are identified with ResourceLocation s. sounds.json should be located at the root of a resource namespace ( assets/<namespace>/sounds.json ), and it defines sound events in that namespace ( assets/<namespace>/sounds.json defines sound events in the namespace namespace .). A full specification is available on the vanilla wiki , but this example highlights the important parts: { \"open_chest\": { \"subtitle\": \"mymod.subtitle.open_chest\", \"sounds\": [ \"mymod:open_chest_sound_file\" ] }, \"epic_music\": { \"sounds\": [ { \"name\": \"mymod:music/epic_music\", \"stream\": true } ] } } Underneath the top-level object, each key corresponds to a sound event. Note that the namespace is not given, as it is taken from the namespace of the JSON itself. Each event specifies a localization key to be shown when subtitles are enabled. Finally, the actual sound files to be played are specified. Note that the value is an array; if multiple sound files are specified, the game will randomly choose one to play whenever the sound event is triggered. The two examples represent two different ways to specify a sound file. The wiki has precise details, but generally, long sound files such as background music or music discs should use the second form, because the \u201cstream\u201d argument tells Minecraft to not load the entire sound file into memory but to stream it from disk. The second form can also specify the volume, pitch, and weight of a sound file. In all cases, the path to a sound file for namespace namespace and path path is assets/<namespace>/sounds/<path>.ogg . Therefore mymod:open_chest_sound_file points to assets/mymod/sounds/open_chest_sound_file.ogg , and mymod:music/epic_music points to assets/mymod/sounds/music/epic_music.ogg . A sounds.json can be data generated .","title":"sounds.json"},{"location":"gameeffects/sounds/#creating-sound-events","text":"In order to reference sounds on the server, a SoundEvent holding a corresponding entry in sounds.json must be created. This SoundEvent must then be registered . Normally, the location used to create a sound event should be set as it\u2019s registry name. The SoundEvent acts as a reference to the sound and is passed around to play them. If a mod has an API, it should expose its SoundEvent s in the API. Note As long as a sound is registered within the sounds.json , it can still be referenced on the logical client regardless of whether there is a referencing SoundEvent .","title":"Creating Sound Events"},{"location":"gameeffects/sounds/#playing-sounds","text":"Vanilla has lots of methods for playing sounds, and it is unclear which to use at times. Note that each takes a SoundEvent , the ones registered above. Additionally, the terms \u201cServer Behavior\u201d and \u201cClient Behavior\u201d refer to the respective logical side .","title":"Playing Sounds"},{"location":"gameeffects/sounds/#level","text":"playSound(Player, BlockPos, SoundEvent, SoundCategory, volume, pitch) Simply forwards to overload (2) , adding 0.5 to each coordinate of the BlockPos given. playSound(Player, double x, double y, double z, SoundEvent, SoundCategory, volume, pitch) Client Behavior : If the passed in player is the client player, plays the sound event to the client player. Server Behavior : Plays the sound event to everyone nearby except the passed in player. Player can be null . Usage : The correspondence between the behaviors implies that these two methods are to be called from some player-initiated code that will be run on both logical sides at the same time: the logical client handles playing it to the user, and the logical server handles everyone else hearing it without re-playing it to the original user. They can also be used to play any sound in general at any position server-side by calling it on the logical server and passing in a null player, thus letting everyone hear it. playLocalSound(double x, double y, double z, SoundEvent, SoundCategory, volume, pitch, distanceDelay) Client Behavior : Just plays the sound event in the client level. If distanceDelay is true , then delays the sound based on how far it is from the player. Server Behavior : Does nothing. Usage : This method only works client-side, and thus is useful for sounds sent in custom packets, or other client-only effect-type sounds. Used for thunder.","title":"Level"},{"location":"gameeffects/sounds/#clientlevel","text":"playLocalSound(BlockPos, SoundEvent, SoundCategory, volume, pitch, distanceDelay) Simply forwards to Level \u2018s overload (3) , adding 0.5 to each coordinate of the BlockPos given.","title":"ClientLevel"},{"location":"gameeffects/sounds/#entity","text":"playSound(SoundEvent, volume, pitch) Forwards to Level \u2018s overload (2) , passing in null as the player. Client Behavior : Does nothing. Server Behavior : Plays the sound event to everyone at this entity\u2019s position. Usage : Emitting any sound from any non-player entity server-side.","title":"Entity"},{"location":"gameeffects/sounds/#player","text":"playSound(SoundEvent, volume, pitch) (overriding the one in Entity ) Forwards to Level \u2018s overload (2) , passing in this as the player. Client Behavior : Does nothing, see override in LocalPlayer . Server Behavior : Plays the sound to everyone nearby except this player. Usage : See LocalPlayer .","title":"Player"},{"location":"gameeffects/sounds/#localplayer","text":"playSound(SoundEvent, volume, pitch) (overriding the one in Player ) Forwards to Level \u2018s overload (2) , passing in this as the player. Client Behavior : Just plays the Sound Event. Server Behavior : Method is client-only. Usage : Just like the ones in Level , these two overrides in the player classes seem to be for code that runs together on both sides. The client handles playing the sound to the user, while the server handles everyone else hearing it without re-playing to the original user.","title":"LocalPlayer"},{"location":"gettingstarted/","text":"Getting Started with Forge This is a simple guide to get you from nothing to a basic mod. The rest of this documentation is about where to go from here. From Zero to Modding Obtain a Java 17 Development Kit (JDK) and a 64-bit Java Virtual Machine (JVM). Minecraft and MinecraftForge both compile against Java 17 and as such should be used for development. Using a 32-bit JVM will result in some problems when running the below gradle tasks. You can obtain one from Eclipse Adoptium . Obtain the Mod Development Kit (MDK) from Forge\u2019s files site. Extract the downloaded MDK into an empty directory. You should see a bunch of files along with an example mod placed in src/main/java for you to look at. Only a few of these files are strictly necessary for mod development, and you may reuse these files for all your projects. These files are: build.gradle gradlew.bat gradlew the gradle folder Move the files listed above to a new folder. This will be your mod project folder. Choose your IDE: Forge only explicitly supports developing with Eclipse, but there are additional run tasks for IntelliJ IDEA or Visual Studio Code environments. However, any environment, from Netbeans to vim/emacs, can be made to work. For both Intellij IDEA and Eclipse, their Gradle integration will handle the rest of the initial workspace setup. This includes downloading packages from Mojang, MinecraftForge, and a few other software sharing sites. For VSCode, the \u2018Gradle Tasks\u2019 plugin can be used to handle the initial workspace setup. For most, if not all, changes to the build.gradle file to take effect, Gradle will need to be invoked to re-evaluate the project. This can be done through \u2018Refresh\u2019 buttons in the Gradle panels of both of the previously mentioned IDEs. Generating IDE Launch/Run Configurations: For Eclipse, run the genEclipseRuns gradle task ( gradlew genEclipseRuns ). This will generate the Launch Configurations and download any required assets for the game to run. After this has finished, refresh your project. For IntelliJ, run the genIntellijRuns gradle task ( gradlew genIntellijRuns ). This will generate the Run Configurations and download any required assets for the game to run. If you encounter an error saying \u201cmodule not specified\u201d, you can either edit the configuration to select your \u201cmain\u201d module or specify it through the ideaModule property. For VSCode, run the genVSCodeRuns gradle task ( gradlew genVSCodeRuns ). This will generate the Launch Configurations and download any required assets for the game to run. Customizing Your Mod Information Edit the build.gradle file to customize how your mod is built (the file names, versions, and other things). Important Do not edit the buildscript {} section of the build.gradle file, its default text is necessary for ForgeGradle to function. Almost anything underneath the // Only edit below this line, the above code adds and enables the necessary things for Forge to be setup. marker can be changed. Many things can be removed and customized there as well. Simple build.gradle Customizations These customizations are highly recommended for all projects. To change the name of the file you build - edit the value of archivesBaseName to suit. To change your \u201cmaven coordinates\u201d - edit the value of group as well. To change the version number - edit the value of version . To update the run configurations - replace all occurrences of examplemod to the mod id of your mod. Migration to Mojang\u2019s Official Mappings Forge uses Mojang\u2019s Official Mappings, or MojMaps, for the forseeable future. The official mappings provide class, method, and field names. Parameters and javadocs are not provided by this mapping set. Currently, there is no guarantee that these mappings are legally safe; however, Forge has decided to adopt them in good faith since Mojang wants them to be used. You can read about Forge\u2019s stance here . Building and Testing Your Mod To build your mod, run gradlew build . This will output a file in build/libs with the name [archivesBaseName]-[version].jar . This file can be placed in the mods folder of a Forge enabled Minecraft setup or distributed. To test run your mod, the easiest way is to use the run configs that were generated when you set up your project. Otherwise, you can run gradlew runClient . This will launch Minecraft from the <runDir> location along with your mod\u2019s code in any source sets specified within your run configurations. The default MDK includes the main source set, so any code written within src/main/java will be applied. You can also run a dedicated server using the server run config or via gradlew runServer . This will launch the Minecraft server with its GUI. After the first run, the server will shut down immediately until the Minecraft EULA is accepted by editing run/eula.txt . Once accepted, the server will load and can be accessed via a direct connect to localhost . Note It is always advisable to test your mod in a dedicated server environment if it is intended to run there.","title":"Introduction"},{"location":"gettingstarted/#getting-started-with-forge","text":"This is a simple guide to get you from nothing to a basic mod. The rest of this documentation is about where to go from here.","title":"Getting Started with Forge"},{"location":"gettingstarted/#from-zero-to-modding","text":"Obtain a Java 17 Development Kit (JDK) and a 64-bit Java Virtual Machine (JVM). Minecraft and MinecraftForge both compile against Java 17 and as such should be used for development. Using a 32-bit JVM will result in some problems when running the below gradle tasks. You can obtain one from Eclipse Adoptium . Obtain the Mod Development Kit (MDK) from Forge\u2019s files site. Extract the downloaded MDK into an empty directory. You should see a bunch of files along with an example mod placed in src/main/java for you to look at. Only a few of these files are strictly necessary for mod development, and you may reuse these files for all your projects. These files are: build.gradle gradlew.bat gradlew the gradle folder Move the files listed above to a new folder. This will be your mod project folder. Choose your IDE: Forge only explicitly supports developing with Eclipse, but there are additional run tasks for IntelliJ IDEA or Visual Studio Code environments. However, any environment, from Netbeans to vim/emacs, can be made to work. For both Intellij IDEA and Eclipse, their Gradle integration will handle the rest of the initial workspace setup. This includes downloading packages from Mojang, MinecraftForge, and a few other software sharing sites. For VSCode, the \u2018Gradle Tasks\u2019 plugin can be used to handle the initial workspace setup. For most, if not all, changes to the build.gradle file to take effect, Gradle will need to be invoked to re-evaluate the project. This can be done through \u2018Refresh\u2019 buttons in the Gradle panels of both of the previously mentioned IDEs. Generating IDE Launch/Run Configurations: For Eclipse, run the genEclipseRuns gradle task ( gradlew genEclipseRuns ). This will generate the Launch Configurations and download any required assets for the game to run. After this has finished, refresh your project. For IntelliJ, run the genIntellijRuns gradle task ( gradlew genIntellijRuns ). This will generate the Run Configurations and download any required assets for the game to run. If you encounter an error saying \u201cmodule not specified\u201d, you can either edit the configuration to select your \u201cmain\u201d module or specify it through the ideaModule property. For VSCode, run the genVSCodeRuns gradle task ( gradlew genVSCodeRuns ). This will generate the Launch Configurations and download any required assets for the game to run.","title":"From Zero to Modding"},{"location":"gettingstarted/#customizing-your-mod-information","text":"Edit the build.gradle file to customize how your mod is built (the file names, versions, and other things). Important Do not edit the buildscript {} section of the build.gradle file, its default text is necessary for ForgeGradle to function. Almost anything underneath the // Only edit below this line, the above code adds and enables the necessary things for Forge to be setup. marker can be changed. Many things can be removed and customized there as well.","title":"Customizing Your Mod Information"},{"location":"gettingstarted/#simple-buildgradle-customizations","text":"These customizations are highly recommended for all projects. To change the name of the file you build - edit the value of archivesBaseName to suit. To change your \u201cmaven coordinates\u201d - edit the value of group as well. To change the version number - edit the value of version . To update the run configurations - replace all occurrences of examplemod to the mod id of your mod.","title":"Simple build.gradle Customizations"},{"location":"gettingstarted/#migration-to-mojangs-official-mappings","text":"Forge uses Mojang\u2019s Official Mappings, or MojMaps, for the forseeable future. The official mappings provide class, method, and field names. Parameters and javadocs are not provided by this mapping set. Currently, there is no guarantee that these mappings are legally safe; however, Forge has decided to adopt them in good faith since Mojang wants them to be used. You can read about Forge\u2019s stance here .","title":"Migration to Mojang's Official Mappings"},{"location":"gettingstarted/#building-and-testing-your-mod","text":"To build your mod, run gradlew build . This will output a file in build/libs with the name [archivesBaseName]-[version].jar . This file can be placed in the mods folder of a Forge enabled Minecraft setup or distributed. To test run your mod, the easiest way is to use the run configs that were generated when you set up your project. Otherwise, you can run gradlew runClient . This will launch Minecraft from the <runDir> location along with your mod\u2019s code in any source sets specified within your run configurations. The default MDK includes the main source set, so any code written within src/main/java will be applied. You can also run a dedicated server using the server run config or via gradlew runServer . This will launch the Minecraft server with its GUI. After the first run, the server will shut down immediately until the Minecraft EULA is accepted by editing run/eula.txt . Once accepted, the server will load and can be accessed via a direct connect to localhost . Note It is always advisable to test your mod in a dedicated server environment if it is intended to run there.","title":"Building and Testing Your Mod"},{"location":"gettingstarted/structuring/","text":"Structuring Your Mod Let us look at how to organize your mod into different files and what those files should do. Packaging Pick a unique package name. If you own a URL associated with your project, you can use it as your top level package. For example if you own \u201cexample.com\u201d, you may use com.example as your top level package. Important If you do not own a domain, do not use it for your top level package. You can use your email, a subdomain of where you host a website, or your name/username as long as it can be unique. After the top level package (if you have one), you append a unique name for your mod, such as examplemod . In our case it will end up as com.example.examplemod . The mods.toml file Important The license field in the mods.toml is required. If it is not provided, an error will occur. See your choices at https://choosealicense.com/ This file defines the metadata of your mod. Its information may be viewed by users from the main screen of the game through the \u2018Mods\u2019 button. A single info file can describe several mods. The mods.toml file is formatted as TOML , the example mods.toml file in the MDK provides comments explaining the contents of the file. It should be stored as src/main/resources/META-INF/mods.toml . A basic mods.toml , describing one mod, may look like this: # The name of the mod loader type to load - for regular FML @Mod mods it should be javafml modLoader=\"javafml\" # A version range to match for said mod loader - for regular FML @Mod it will be the forge version # Forge for 1.18 is version 38 loaderVersion=\"[38,)\" # The license for your mod. This is mandatory and allows for easier comprehension of your redistributive properties. # Review your options at https://choosealicense.com/. All rights reserved is the default copyright stance, and is thus the default here. license=\"All Rights Reserved\" # A URL to refer people to when problems occur with this mod issueTrackerURL=\"github.com/MinecraftForge/MinecraftForge/issues\" # If the mods defined in this file should show as separate resource packs showAsResourcePack=false [[mods]] modId=\"examplemod\" version=\"1.0.0.0\" displayName=\"Example Mod\" updateJSONURL=\"minecraftforge.net/versions.json\" displayURL=\"minecraftforge.net\" logoFile=\"logo.png\" credits=\"I'd like to thank my mother and father.\" authors=\"Author\" description=''' Lets you craft dirt into diamonds. This is a traditional mod that has existed for eons. It is ancient. The holy Notch created it. Jeb rainbowfied it. Dinnerbone made it upside down. Etc. ''' [[dependencies.examplemod]] modId=\"forge\" mandatory=true versionRange=\"[38,)\" ordering=\"NONE\" side=\"BOTH\" [[dependencies.examplemod]] modId=\"minecraft\" mandatory=true versionRange=\"[1.18,1.19)\" ordering=\"NONE\" side=\"BOTH\" If any string is specified as ${file.jarVersion} , Forge will replace the string with the Implementation Version specified in your jar manifest at runtime. Since the user development environment has no jar manifest to pull from, it will be NONE instead. As such, it is usually recommended to leave the version field alone. Here is a table of attributes that may be given to a mod, where mandatory means there is no default and the absence of the property causes an error. Property Type Default Description modid string mandatory The modid this file is linked to. version string mandatory The version of the mod. It should be just numbers separated by dots, ideally conforming to Forge\u2019s Semantic Versioning structure. displayName string mandatory The user-friendly name of this mod. updateJSONURL string \"\" The URL to a version JSON . displayURL string \"\" A link to the mod\u2019s homepage. logoFile string \"\" The filename of the mod\u2019s logo. It must be placed in the root resource folder, not in a subfolder. credits string \"\" A string that contains any acknowledgements you want to mention. authors string \"\" The authors of this mod. description string mandatory A description of this mod. dependencies [list] [] A list of dependencies of this mod. * All version ranges use the Maven Version Range Specification . The Mod File Generally, we will start with a file named after your mod and put into your package. This is the entry point to your mod and will contain some special indicators marking it as such. What is @Mod ? This is an annotation indicating to the Forge Mod Loader that the class is a Mod entry point. The @Mod annotation\u2019s value should match a mod id in the src/main/resources/META-INF/mods.toml file. Keeping Your Code Clean Using Sub-packages Rather than clutter up a single class and package with everything, it is recommended that you break your mod into subpackages. A common subpackage strategy has packages for common and client code, which is code that can be run on both server/client and only client, respectively. Inside the common package would go things like Items, Blocks, and Block Entities (which can each, in turn, be another subpackage). Things like Screens and Renderers would go inside the client package. Note This package style is only a suggestion, though it is a commonly used style. Feel free to use your own packaging system. By keeping your code in clean subpackages, you can grow your mod much more organically. Class Naming Schemes A common class naming scheme allows easier deciphering of what a class is, and it also makes it easier for someone developing with your mod to find things. For Example: An Item called PowerRing would be in an item package, with a class name of PowerRingItem . A Block called NotDirt would be in a block package, with a class name of NotDirtBlock . Finally, a BlockEntity for a block called SuperChewer would be a block.entity or blockentity package, with a class name of SuperChewerBlockEntity . Appending your class names with what kind of object they are makes it easier to figure out what a class is or guess the class for an object.","title":"Structuring Your Mod"},{"location":"gettingstarted/structuring/#structuring-your-mod","text":"Let us look at how to organize your mod into different files and what those files should do.","title":"Structuring Your Mod"},{"location":"gettingstarted/structuring/#packaging","text":"Pick a unique package name. If you own a URL associated with your project, you can use it as your top level package. For example if you own \u201cexample.com\u201d, you may use com.example as your top level package. Important If you do not own a domain, do not use it for your top level package. You can use your email, a subdomain of where you host a website, or your name/username as long as it can be unique. After the top level package (if you have one), you append a unique name for your mod, such as examplemod . In our case it will end up as com.example.examplemod .","title":"Packaging"},{"location":"gettingstarted/structuring/#the-modstoml-file","text":"Important The license field in the mods.toml is required. If it is not provided, an error will occur. See your choices at https://choosealicense.com/ This file defines the metadata of your mod. Its information may be viewed by users from the main screen of the game through the \u2018Mods\u2019 button. A single info file can describe several mods. The mods.toml file is formatted as TOML , the example mods.toml file in the MDK provides comments explaining the contents of the file. It should be stored as src/main/resources/META-INF/mods.toml . A basic mods.toml , describing one mod, may look like this: # The name of the mod loader type to load - for regular FML @Mod mods it should be javafml modLoader=\"javafml\" # A version range to match for said mod loader - for regular FML @Mod it will be the forge version # Forge for 1.18 is version 38 loaderVersion=\"[38,)\" # The license for your mod. This is mandatory and allows for easier comprehension of your redistributive properties. # Review your options at https://choosealicense.com/. All rights reserved is the default copyright stance, and is thus the default here. license=\"All Rights Reserved\" # A URL to refer people to when problems occur with this mod issueTrackerURL=\"github.com/MinecraftForge/MinecraftForge/issues\" # If the mods defined in this file should show as separate resource packs showAsResourcePack=false [[mods]] modId=\"examplemod\" version=\"1.0.0.0\" displayName=\"Example Mod\" updateJSONURL=\"minecraftforge.net/versions.json\" displayURL=\"minecraftforge.net\" logoFile=\"logo.png\" credits=\"I'd like to thank my mother and father.\" authors=\"Author\" description=''' Lets you craft dirt into diamonds. This is a traditional mod that has existed for eons. It is ancient. The holy Notch created it. Jeb rainbowfied it. Dinnerbone made it upside down. Etc. ''' [[dependencies.examplemod]] modId=\"forge\" mandatory=true versionRange=\"[38,)\" ordering=\"NONE\" side=\"BOTH\" [[dependencies.examplemod]] modId=\"minecraft\" mandatory=true versionRange=\"[1.18,1.19)\" ordering=\"NONE\" side=\"BOTH\" If any string is specified as ${file.jarVersion} , Forge will replace the string with the Implementation Version specified in your jar manifest at runtime. Since the user development environment has no jar manifest to pull from, it will be NONE instead. As such, it is usually recommended to leave the version field alone. Here is a table of attributes that may be given to a mod, where mandatory means there is no default and the absence of the property causes an error. Property Type Default Description modid string mandatory The modid this file is linked to. version string mandatory The version of the mod. It should be just numbers separated by dots, ideally conforming to Forge\u2019s Semantic Versioning structure. displayName string mandatory The user-friendly name of this mod. updateJSONURL string \"\" The URL to a version JSON . displayURL string \"\" A link to the mod\u2019s homepage. logoFile string \"\" The filename of the mod\u2019s logo. It must be placed in the root resource folder, not in a subfolder. credits string \"\" A string that contains any acknowledgements you want to mention. authors string \"\" The authors of this mod. description string mandatory A description of this mod. dependencies [list] [] A list of dependencies of this mod. * All version ranges use the Maven Version Range Specification .","title":"The mods.toml file"},{"location":"gettingstarted/structuring/#the-mod-file","text":"Generally, we will start with a file named after your mod and put into your package. This is the entry point to your mod and will contain some special indicators marking it as such.","title":"The Mod File"},{"location":"gettingstarted/structuring/#what-is-mod","text":"This is an annotation indicating to the Forge Mod Loader that the class is a Mod entry point. The @Mod annotation\u2019s value should match a mod id in the src/main/resources/META-INF/mods.toml file.","title":"What is @Mod?"},{"location":"gettingstarted/structuring/#keeping-your-code-clean-using-sub-packages","text":"Rather than clutter up a single class and package with everything, it is recommended that you break your mod into subpackages. A common subpackage strategy has packages for common and client code, which is code that can be run on both server/client and only client, respectively. Inside the common package would go things like Items, Blocks, and Block Entities (which can each, in turn, be another subpackage). Things like Screens and Renderers would go inside the client package. Note This package style is only a suggestion, though it is a commonly used style. Feel free to use your own packaging system. By keeping your code in clean subpackages, you can grow your mod much more organically.","title":"Keeping Your Code Clean Using Sub-packages"},{"location":"gettingstarted/structuring/#class-naming-schemes","text":"A common class naming scheme allows easier deciphering of what a class is, and it also makes it easier for someone developing with your mod to find things. For Example: An Item called PowerRing would be in an item package, with a class name of PowerRingItem . A Block called NotDirt would be in a block package, with a class name of NotDirtBlock . Finally, a BlockEntity for a block called SuperChewer would be a block.entity or blockentity package, with a class name of SuperChewerBlockEntity . Appending your class names with what kind of object they are makes it easier to figure out what a class is or guess the class for an object.","title":"Class Naming Schemes"},{"location":"gettingstarted/versioning/","text":"Versioning In general projects, Semantic Versioning is often used (which has the format MAJOR.MINOR.PATCH ). However, in the case of modding it may be more beneficial to use the format MCVERSION-MAJORMOD.MAJORAPI.MINOR.PATCH to be able to differentiate between world-breaking and API-breaking changes of a mod. Examples Here is a list of examples that can increment the various variables. MCVERSION Always matches the Minecraft version the mod is for. MAJORMOD Removing items, blocks, block entities, etc. Changing or removing previously existing mechanics. Updating to a new Minecraft version. MAJORAPI Changing the order or variables of enums. Changing return types of methods. Removing public methods altogether. MINOR Adding items, blocks, block entities, etc. Adding new mechanics. Deprecating public methods. (This is not a MAJORAPI increment since it doesn\u2019t break an API.) PATCH Bugfixes. When incrementing any variable, all lesser variables should reset to 0 . For instance, if MINOR would increment, PATCH would become 0 . If MAJORMOD would increment, all other variables would become 0 . Work In Progress If you are in the initial development stage of your mod (before any official releases), the MAJORMOD and MAJORAPI should always be 0 . Only MINOR and PATCH should be updated every time you build your mod. Once you build an official release (most of the time with a stable API), you should increment MAJORMOD to version 1.0.0.0 . For any further development stages, refer to the Prereleases and Release candidates section of this document. Multiple Minecraft Versions If the mod upgrades to a new version of Minecraft, and the old version will only receive bug fixes, the PATCH variable should be updated based on the version before the upgrade. If the mod is still in active development in both the old and the new version of Minecraft, it is advised to append the version to both build numbers. For example, if the mod is upgraded to version 3.0.0.0 due to a Minecraft version change, the old mod should also be updated to 3.0.0.0 . The old version will become, for example, version 1.7.10-3.0.0.0 , while the new version will become 1.8-3.0.0.0 . If there are no changes at all when building for a newer Minecraft version, all variables except for the Minecraft version should stay the same. Final Release When dropping support for a Minecraft version, the last build for that version should get the -final suffix. This denotes that the mod will no longer be supported for the denoted MCVERSION and that players should upgrade to a newer version of the mod to continue receiving updates and bug fixes. Pre-releases It is also possible to prerelease work-in-progress features, which means new features are released that are not quite done yet. These can be seen as a sort of \u201cbeta\u201d. These versions should be appended with -betaX , where X is the number of the prerelease. (This guide does not use -pre since, at the time of writing, it is not a valid alias for -beta .) Note that already released versions and versions before the initial release can not go into prerelease; variables (mostly MINOR , but MAJORAPI and MAJORMOD can also prerelease) should be updated accordingly before adding the -beta suffix. Versions before the initial release are simply work-in-progress builds. Release Candidates Release candidates act as prereleases before an actual version change. These versions should be appended with -rcX , where X is the number of the release candidate which should, in theory, only be increased for bugfixes. Already released versions can not receive release candidates; variables (mostly MINOR , but MAJORAPI and MAJORMOD can also prerelease) should be updated accordingly before adding the -rc suffix. When releasing a release candidate as stable build, it can either be exactly the same as the last release candidate or have a few more bug fixes.","title":"Versioning"},{"location":"gettingstarted/versioning/#versioning","text":"In general projects, Semantic Versioning is often used (which has the format MAJOR.MINOR.PATCH ). However, in the case of modding it may be more beneficial to use the format MCVERSION-MAJORMOD.MAJORAPI.MINOR.PATCH to be able to differentiate between world-breaking and API-breaking changes of a mod.","title":"Versioning"},{"location":"gettingstarted/versioning/#examples","text":"Here is a list of examples that can increment the various variables. MCVERSION Always matches the Minecraft version the mod is for. MAJORMOD Removing items, blocks, block entities, etc. Changing or removing previously existing mechanics. Updating to a new Minecraft version. MAJORAPI Changing the order or variables of enums. Changing return types of methods. Removing public methods altogether. MINOR Adding items, blocks, block entities, etc. Adding new mechanics. Deprecating public methods. (This is not a MAJORAPI increment since it doesn\u2019t break an API.) PATCH Bugfixes. When incrementing any variable, all lesser variables should reset to 0 . For instance, if MINOR would increment, PATCH would become 0 . If MAJORMOD would increment, all other variables would become 0 .","title":"Examples"},{"location":"gettingstarted/versioning/#work-in-progress","text":"If you are in the initial development stage of your mod (before any official releases), the MAJORMOD and MAJORAPI should always be 0 . Only MINOR and PATCH should be updated every time you build your mod. Once you build an official release (most of the time with a stable API), you should increment MAJORMOD to version 1.0.0.0 . For any further development stages, refer to the Prereleases and Release candidates section of this document.","title":"Work In Progress"},{"location":"gettingstarted/versioning/#multiple-minecraft-versions","text":"If the mod upgrades to a new version of Minecraft, and the old version will only receive bug fixes, the PATCH variable should be updated based on the version before the upgrade. If the mod is still in active development in both the old and the new version of Minecraft, it is advised to append the version to both build numbers. For example, if the mod is upgraded to version 3.0.0.0 due to a Minecraft version change, the old mod should also be updated to 3.0.0.0 . The old version will become, for example, version 1.7.10-3.0.0.0 , while the new version will become 1.8-3.0.0.0 . If there are no changes at all when building for a newer Minecraft version, all variables except for the Minecraft version should stay the same.","title":"Multiple Minecraft Versions"},{"location":"gettingstarted/versioning/#final-release","text":"When dropping support for a Minecraft version, the last build for that version should get the -final suffix. This denotes that the mod will no longer be supported for the denoted MCVERSION and that players should upgrade to a newer version of the mod to continue receiving updates and bug fixes.","title":"Final Release"},{"location":"gettingstarted/versioning/#pre-releases","text":"It is also possible to prerelease work-in-progress features, which means new features are released that are not quite done yet. These can be seen as a sort of \u201cbeta\u201d. These versions should be appended with -betaX , where X is the number of the prerelease. (This guide does not use -pre since, at the time of writing, it is not a valid alias for -beta .) Note that already released versions and versions before the initial release can not go into prerelease; variables (mostly MINOR , but MAJORAPI and MAJORMOD can also prerelease) should be updated accordingly before adding the -beta suffix. Versions before the initial release are simply work-in-progress builds.","title":"Pre-releases"},{"location":"gettingstarted/versioning/#release-candidates","text":"Release candidates act as prereleases before an actual version change. These versions should be appended with -rcX , where X is the number of the release candidate which should, in theory, only be increased for bugfixes. Already released versions can not receive release candidates; variables (mostly MINOR , but MAJORAPI and MAJORMOD can also prerelease) should be updated accordingly before adding the -rc suffix. When releasing a release candidate as stable build, it can either be exactly the same as the last release candidate or have a few more bug fixes.","title":"Release Candidates"},{"location":"items/","text":"Items Along with blocks, items are a key component of most mods. While blocks make up the level around you, items exist within inventories. Creating an Item Basic Items Basic items that need no special functionality (think sticks or sugar) do not need custom classes. You can create an item by instantiating the Item class with an Item$Properties object. This Item$Properties object can be made via the constructor and customized by calling its methods. For instance: Method Description tab Sets which CreativeModeTab this item is under. Must be called if this item is meant to be shown on the creative menu. Vanilla tabs can be found in the class CreativeModeTab . durability Sets the maximum damage value for this item. If it is over 0 , two item properties \u201cdamaged\u201d and \u201cdamage\u201d are added. stacksTo Sets the maximum stack size. You cannot have an item that is both damageable and stackable. setNoRepair Makes this item impossible to repair, even if it is damageable. craftRemainder Sets this item\u2019s container item, the way that lava buckets give you back an empty bucket when they are used. The above methods are chainable, meaning they return this to facilitate calling them in series. Advanced Items Setting the properties of an item as above only works for simple items. If you want more complicated items, you should subclass Item and override its methods. Registering an Item Items must be registered to function.","title":"Introduction"},{"location":"items/#items","text":"Along with blocks, items are a key component of most mods. While blocks make up the level around you, items exist within inventories.","title":"Items"},{"location":"items/#creating-an-item","text":"","title":"Creating an Item"},{"location":"items/#basic-items","text":"Basic items that need no special functionality (think sticks or sugar) do not need custom classes. You can create an item by instantiating the Item class with an Item$Properties object. This Item$Properties object can be made via the constructor and customized by calling its methods. For instance: Method Description tab Sets which CreativeModeTab this item is under. Must be called if this item is meant to be shown on the creative menu. Vanilla tabs can be found in the class CreativeModeTab . durability Sets the maximum damage value for this item. If it is over 0 , two item properties \u201cdamaged\u201d and \u201cdamage\u201d are added. stacksTo Sets the maximum stack size. You cannot have an item that is both damageable and stackable. setNoRepair Makes this item impossible to repair, even if it is damageable. craftRemainder Sets this item\u2019s container item, the way that lava buckets give you back an empty bucket when they are used. The above methods are chainable, meaning they return this to facilitate calling them in series.","title":"Basic Items"},{"location":"items/#advanced-items","text":"Setting the properties of an item as above only works for simple items. If you want more complicated items, you should subclass Item and override its methods.","title":"Advanced Items"},{"location":"items/#registering-an-item","text":"Items must be registered to function.","title":"Registering an Item"},{"location":"items/bewlr/","text":"BlockEntityWithoutLevelRenderer BlockEntityWithoutLevelRenderer is a method to handle dynamic rendering on items. This system is much simpler than the old ItemStack system, which required a BlockEntity , and did not allow access to the ItemStack . Using BlockEntityWithoutLevelRenderer BlockEntityWithoutLevelRenderer allows you to render your item using public void renderByItem(ItemStack itemStack, TransformType transformType, PoseStack poseStack, MultiBufferSource bufferSource, int combinedLight, int combinedOverlay) . In order to use an BEWLR, the Item must first satisfy the condition that its model returns true for BakedModel#isCustomRenderer . Once that returns true, the Item\u2019s BEWLR will be accessed for rendering. If it does not have one, it will use the default ItemRenderer#getBlockEntityRenderer . To set the BEWLR for an Item, an anonymous instance of IItemRenderProperties must be consumed within Item#initializeClient . Within the anonymous instance, IItemRenderProperties#getItemStackRenderer should be overridden to return the instance of your BEWLR: // In your item class @Override public void initializeClient(Consumer<IItemRenderProperties> consumer) { consumer.accept(new IItemRenderProperties() { @Override public BlockEntityWithoutLevelRenderer getItemStackRenderer() { return myBEWLRInstance; } }); } Important Each mod should only have one instance of a custom BEWLR. That is it, no additional setup is necessary to use a BEWLR.","title":"BlockEntityWithoutLevelRenderer"},{"location":"items/bewlr/#blockentitywithoutlevelrenderer","text":"BlockEntityWithoutLevelRenderer is a method to handle dynamic rendering on items. This system is much simpler than the old ItemStack system, which required a BlockEntity , and did not allow access to the ItemStack .","title":"BlockEntityWithoutLevelRenderer"},{"location":"items/bewlr/#using-blockentitywithoutlevelrenderer","text":"BlockEntityWithoutLevelRenderer allows you to render your item using public void renderByItem(ItemStack itemStack, TransformType transformType, PoseStack poseStack, MultiBufferSource bufferSource, int combinedLight, int combinedOverlay) . In order to use an BEWLR, the Item must first satisfy the condition that its model returns true for BakedModel#isCustomRenderer . Once that returns true, the Item\u2019s BEWLR will be accessed for rendering. If it does not have one, it will use the default ItemRenderer#getBlockEntityRenderer . To set the BEWLR for an Item, an anonymous instance of IItemRenderProperties must be consumed within Item#initializeClient . Within the anonymous instance, IItemRenderProperties#getItemStackRenderer should be overridden to return the instance of your BEWLR: // In your item class @Override public void initializeClient(Consumer<IItemRenderProperties> consumer) { consumer.accept(new IItemRenderProperties() { @Override public BlockEntityWithoutLevelRenderer getItemStackRenderer() { return myBEWLRInstance; } }); } Important Each mod should only have one instance of a custom BEWLR. That is it, no additional setup is necessary to use a BEWLR.","title":"Using BlockEntityWithoutLevelRenderer"},{"location":"legacy/","text":"Documentation for Legacy Versions Forge has existed for years, and you can still easily access builds of Forge for Minecraft versions as old as Minecraft 1.1. There are significant differences between each and every version, and it would be an impossible task to support so many different versions. Therefore, Forge uses an LTS system where a previous major Minecraft version is deemed as \u201cLTS\u201d (Long Term Support). Only the latest version and any current LTS versions will have easily accessible documentation and be included in the version dropdown in the sidebar. However, some older versions were LTS once or the latest version at some point and had documentation written. Links to old sites with documentation for those versions can be found here. Important These old documentation sites are for reference purposes only. Do not ask for help with old versions on the Forge discord or the Forge forums. You will not receive support when you are using older versions. List of Previously Documented versions Unfortunately, not all versions were used for a significant amount of time, and the documentation for that version may be incomplete. Whenever a new version is released, the documentation from the previous version is copied and adjusted over time to include new and updated information. When a version wasn\u2019t supported for long, the information was never updated. The accuracy percentages represent how much of the information that should have been updated was actually updated. Version Accuracy Link 1.12.x 100% https://mcforge.readthedocs.io/en/1.12.x/ 1.13.x 10% https://mcforge.readthedocs.io/en/1.13.x/ 1.14.x 10% https://mcforge.readthedocs.io/en/1.14.x/ 1.15.x 85% https://mcforge.readthedocs.io/en/1.15.x/ 1.16.x 85% https://mcforge.readthedocs.io/en/1.16.x/ 1.17.x 85% https://mcforge.readthedocs.io/en/1.17.x/ RetroGradle RetroGradle is an archival initiative to update the older ForgeGradle 1.x to 2.3 toolchains and their Minecraft versions to use the modern ForgeGradle 4.x and above toolchain. The goal is to preserve all past released versions of Minecraft Forge by moving them to a verifiably working and modern toolchain which is data-driven and not hardcoded for version-specific workflows. If any developer wishes to contribute to this archival effort, please visit The Forge Project discord server and ask for directions to the designated channel. Please note that this initiative only aims to preserve these old versions for the benefit of the community, not to support developing mods for these old, unsupported versions. There will not be any support for using or developing for unsupported versions.","title":"Introduction"},{"location":"legacy/#documentation-for-legacy-versions","text":"Forge has existed for years, and you can still easily access builds of Forge for Minecraft versions as old as Minecraft 1.1. There are significant differences between each and every version, and it would be an impossible task to support so many different versions. Therefore, Forge uses an LTS system where a previous major Minecraft version is deemed as \u201cLTS\u201d (Long Term Support). Only the latest version and any current LTS versions will have easily accessible documentation and be included in the version dropdown in the sidebar. However, some older versions were LTS once or the latest version at some point and had documentation written. Links to old sites with documentation for those versions can be found here. Important These old documentation sites are for reference purposes only. Do not ask for help with old versions on the Forge discord or the Forge forums. You will not receive support when you are using older versions.","title":"Documentation for Legacy Versions"},{"location":"legacy/#list-of-previously-documented-versions","text":"Unfortunately, not all versions were used for a significant amount of time, and the documentation for that version may be incomplete. Whenever a new version is released, the documentation from the previous version is copied and adjusted over time to include new and updated information. When a version wasn\u2019t supported for long, the information was never updated. The accuracy percentages represent how much of the information that should have been updated was actually updated. Version Accuracy Link 1.12.x 100% https://mcforge.readthedocs.io/en/1.12.x/ 1.13.x 10% https://mcforge.readthedocs.io/en/1.13.x/ 1.14.x 10% https://mcforge.readthedocs.io/en/1.14.x/ 1.15.x 85% https://mcforge.readthedocs.io/en/1.15.x/ 1.16.x 85% https://mcforge.readthedocs.io/en/1.16.x/ 1.17.x 85% https://mcforge.readthedocs.io/en/1.17.x/","title":"List of Previously Documented versions"},{"location":"legacy/#retrogradle","text":"RetroGradle is an archival initiative to update the older ForgeGradle 1.x to 2.3 toolchains and their Minecraft versions to use the modern ForgeGradle 4.x and above toolchain. The goal is to preserve all past released versions of Minecraft Forge by moving them to a verifiably working and modern toolchain which is data-driven and not hardcoded for version-specific workflows. If any developer wishes to contribute to this archival effort, please visit The Forge Project discord server and ask for directions to the designated channel. Please note that this initiative only aims to preserve these old versions for the benefit of the community, not to support developing mods for these old, unsupported versions. There will not be any support for using or developing for unsupported versions.","title":"RetroGradle"},{"location":"legacy/porting/","text":"Porting to Minecraft 1.18 Here you can find a list of primers on how to port from old versions to the current version. Some versions are lumped together since that particular version never saw much usage. From -> To Primer 1.12 -> 1.13/1.14 Primer by williewillus 1.14 -> 1.15 Primer by williewillus 1.15 -> 1.16 Primer by 50ap5ud5 1.16 -> 1.17 Primer by 50ap5ud5","title":"Porting to This Version"},{"location":"legacy/porting/#porting-to-minecraft-118","text":"Here you can find a list of primers on how to port from old versions to the current version. Some versions are lumped together since that particular version never saw much usage. From -> To Primer 1.12 -> 1.13/1.14 Primer by williewillus 1.14 -> 1.15 Primer by williewillus 1.15 -> 1.16 Primer by 50ap5ud5 1.16 -> 1.17 Primer by 50ap5ud5","title":"Porting to Minecraft 1.18"},{"location":"misc/config/","text":"Configuration Configurations define settings and consumer preferences that can be applied to a mod instance. Forge uses a configuration system using TOML files and read with NightConfig . Creating a Configuration A configuration can be created using a subtype of IConfigSpec . Forge implements the type via ForgeConfigSpec and enables its construction through ForgeConfigSpec$Builder . The builder can separate the config values into sections via Builder#push to create a section and Builder#pop to leave a section. Afterwards, the configuration can be built using one of two methods: Method Description build Creates the ForgeConfigSpec . configure Creates a pair of the class holding the config values and the ForgeConfigSpec . Note ForgeConfigSpec$Builder#configure is typically used with a static block and a class that takes in ForgeConfigSpec$Builder as part of its constructor to attach and hold the values: // In some config class ExampleConfig(ForgeConfigSpec.Builder builder) { // Define values here in final fields } // Somewhere the constructor is accessible static { Pair<ExampleConfig, ForgeConfigSpec> pair = new ForgeConfigSpec.Builder() .configure(ExampleConfig::new); // Store pair values in some constant field } Each config value can be supplied with additional context to provide additional behavior. Contexts must be defined before the config value is fully built: Method Description comment Provides a description of what the config value does. Can provide multiple strings for a multiline comment. translation Provides a translation key for the name of the config value. worldRestart The world must be restarted before the config value can be changed. ConfigValue Config values can be built with the provided contexts (if defined) using any of the #define methods. All config value methods take in at least two components: A path representing the name of the variable: a . separated string representing the sections the config value is in The default value when no valid configuration is present The ConfigValue specific methods take in two additional components: A validator to make sure the deserialized object is valid A class representing the data type of the config value // For some ForgeConfigSpec$Builder builder ConfigValue<T> value = builder.comment(\"Comment\") .define(\"config_value_name\", defaultValue); The values themselves can be obtained using ConfigValue#get . The values are additionally cached to prevent multiple readings from files. Additional Config Value Types Range Values Description: Value must be between the defined bounds Class Type: Comparable<T> Method Name: #defineInRange Additional Components: The minimum and maximum the config value may be A class representing the data type of the config value Note DoubleValue s, IntValue s, and LongValue s are range values which specify the class as Double , Integer , and Long respectively. Whitelisted Values Description: Value must be in supplied collection Class Type: T Method Name: #defineInList Additional Components: A collection of the allowed values the configuration can be List Values Description: Value is a list of entries Class Type: List<T> Method Name: #defineList , #defineListAllowEmpty if list can be empty Additional Components: A validator to make sure a deserialized element from the list is valid Enum Values Description: An enum value in the supplied collection Class Type: Enum<T> Method Name: #defineEnum Additional Components: A getter to convert a string or integer into an enum A collection of the allowed values the configuration can be Boolean Values Description: A boolean value Class Type: Boolean Method Name: #define Registering a Configuration Once a ForgeConfigSpec has been built, it must be registered to allow Forge to load, track, and sync the configuration settings as required. Configurations should be registered in the mod constructor via ModLoadingContext#registerConfig . A configuration can be registered with a given type representing the side the config belongs to, the ForgeConfigSpec , and optionally a specific file name for the configuration. // In the mod constructor with a ForgeConfigSpec CONFIG ModLoadingContext.get().registerConfig(Type.COMMON, CONFIG); Here is a list of the available configuration types: Type Loaded Synced to Client Client Location Server Location Default File Suffix CLIENT Client Side Only No .minecraft/config N/A -client COMMON On Both Sides No .minecraft/config <server_folder>/config -common SERVER Server Side Only Yes .minecraft/saves/<level_name>/serverconfig <server_folder>/world/serverconfig -server Tip Forge documents the config types within their codebase. Configuration Events Operations that occur whenever a config is loaded or reloaded can be done using the ModConfigEvent$Loading and ModConfigEvent$Reloading events. The events must be registered to the mod event bus. Warning These events are called for all configurations for the mod; the ModConfig object provided should be used to denote which configuration is being loaded or reloaded.","title":"Configuration"},{"location":"misc/config/#configuration","text":"Configurations define settings and consumer preferences that can be applied to a mod instance. Forge uses a configuration system using TOML files and read with NightConfig .","title":"Configuration"},{"location":"misc/config/#creating-a-configuration","text":"A configuration can be created using a subtype of IConfigSpec . Forge implements the type via ForgeConfigSpec and enables its construction through ForgeConfigSpec$Builder . The builder can separate the config values into sections via Builder#push to create a section and Builder#pop to leave a section. Afterwards, the configuration can be built using one of two methods: Method Description build Creates the ForgeConfigSpec . configure Creates a pair of the class holding the config values and the ForgeConfigSpec . Note ForgeConfigSpec$Builder#configure is typically used with a static block and a class that takes in ForgeConfigSpec$Builder as part of its constructor to attach and hold the values: // In some config class ExampleConfig(ForgeConfigSpec.Builder builder) { // Define values here in final fields } // Somewhere the constructor is accessible static { Pair<ExampleConfig, ForgeConfigSpec> pair = new ForgeConfigSpec.Builder() .configure(ExampleConfig::new); // Store pair values in some constant field } Each config value can be supplied with additional context to provide additional behavior. Contexts must be defined before the config value is fully built: Method Description comment Provides a description of what the config value does. Can provide multiple strings for a multiline comment. translation Provides a translation key for the name of the config value. worldRestart The world must be restarted before the config value can be changed.","title":"Creating a Configuration"},{"location":"misc/config/#configvalue","text":"Config values can be built with the provided contexts (if defined) using any of the #define methods. All config value methods take in at least two components: A path representing the name of the variable: a . separated string representing the sections the config value is in The default value when no valid configuration is present The ConfigValue specific methods take in two additional components: A validator to make sure the deserialized object is valid A class representing the data type of the config value // For some ForgeConfigSpec$Builder builder ConfigValue<T> value = builder.comment(\"Comment\") .define(\"config_value_name\", defaultValue); The values themselves can be obtained using ConfigValue#get . The values are additionally cached to prevent multiple readings from files.","title":"ConfigValue"},{"location":"misc/config/#additional-config-value-types","text":"Range Values Description: Value must be between the defined bounds Class Type: Comparable<T> Method Name: #defineInRange Additional Components: The minimum and maximum the config value may be A class representing the data type of the config value Note DoubleValue s, IntValue s, and LongValue s are range values which specify the class as Double , Integer , and Long respectively. Whitelisted Values Description: Value must be in supplied collection Class Type: T Method Name: #defineInList Additional Components: A collection of the allowed values the configuration can be List Values Description: Value is a list of entries Class Type: List<T> Method Name: #defineList , #defineListAllowEmpty if list can be empty Additional Components: A validator to make sure a deserialized element from the list is valid Enum Values Description: An enum value in the supplied collection Class Type: Enum<T> Method Name: #defineEnum Additional Components: A getter to convert a string or integer into an enum A collection of the allowed values the configuration can be Boolean Values Description: A boolean value Class Type: Boolean Method Name: #define","title":"Additional Config Value Types"},{"location":"misc/config/#registering-a-configuration","text":"Once a ForgeConfigSpec has been built, it must be registered to allow Forge to load, track, and sync the configuration settings as required. Configurations should be registered in the mod constructor via ModLoadingContext#registerConfig . A configuration can be registered with a given type representing the side the config belongs to, the ForgeConfigSpec , and optionally a specific file name for the configuration. // In the mod constructor with a ForgeConfigSpec CONFIG ModLoadingContext.get().registerConfig(Type.COMMON, CONFIG); Here is a list of the available configuration types: Type Loaded Synced to Client Client Location Server Location Default File Suffix CLIENT Client Side Only No .minecraft/config N/A -client COMMON On Both Sides No .minecraft/config <server_folder>/config -common SERVER Server Side Only Yes .minecraft/saves/<level_name>/serverconfig <server_folder>/world/serverconfig -server Tip Forge documents the config types within their codebase.","title":"Registering a Configuration"},{"location":"misc/config/#configuration-events","text":"Operations that occur whenever a config is loaded or reloaded can be done using the ModConfigEvent$Loading and ModConfigEvent$Reloading events. The events must be registered to the mod event bus. Warning These events are called for all configurations for the mod; the ModConfig object provided should be used to denote which configuration is being loaded or reloaded.","title":"Configuration Events"},{"location":"misc/debugprofiler/","text":"Debug Profiler Minecraft provides a Debug Profiler that provides system data, current game settings, JVM data, level data, and sided tick information to find time consuming code. Considering things like TickEvent s and ticking BlockEntities , this can be very useful for modders and server owners that want to find a lag source. Using the Debug Profiler The Debug Profiler is very simple to use. It requires the debug keybind F3 + L to start the profiler. After 10 seconds, it will automatically stop; however, it can be stopped earlier by pressing the keybind again. Note Naturally, you can only profile code paths that are actually being reached. Entities and BlockEntities that you want to profile must exist in the level to show up in the results. After you have stopped the debugger, it will create a new zip within the debug/profiling subdirectory in your run directory. The file name will be formatted with the date and time as yyyy-mm-dd_hh_mi_ss-WorldName-VersionNumber.zip Reading a Profiling result Within each sided folder ( client and server ), you will find a profiling.txt file containing the result data. At the top, it first tells you how long in milliseconds it was running and how many ticks ran in that time. Below that, you will find information similar to the snippet below: [00] levels - 96.70%/96.70% [01] | Level Name - 99.76%/96.47% [02] | | tick - 99.31%/95.81% [03] | | | entities - 47.72%/45.72% [04] | | | | regular - 98.32%/44.95% [04] | | | | blockEntities - 0.90%/0.41% [05] | | | | | unspecified - 64.26%/0.26% [05] | | | | | minecraft:furnace - 33.35%/0.14% [05] | | | | | minecraft:chest - 2.39%/0.01% Here is a small explanation of what each part means [02] tick 99.31% 95.81% The Depth of the section The Name of the Section The percentage of time it took in relation to it\u2019s parent. For Layer 0, it is the percentage of the time a tick takes. For Layer 1, it is the percentage of the time its parent takes. The second percentage tells you how much time it took from the entire tick. Profiling your own code The Debug Profiler has basic support for Entity and BlockEntity . If you would like to profile something else, you may need to manually create your sections like so: ProfilerFiller#push(yourSectionName : String); //The code you want to profile ProfilerFiller#pop(); You can obtain the ProfilerFiller instance from a Level , MinecraftServer , or Minecraft instance. Now you just need to search the results file for your section name.","title":"Debug Profiler"},{"location":"misc/debugprofiler/#debug-profiler","text":"Minecraft provides a Debug Profiler that provides system data, current game settings, JVM data, level data, and sided tick information to find time consuming code. Considering things like TickEvent s and ticking BlockEntities , this can be very useful for modders and server owners that want to find a lag source.","title":"Debug Profiler"},{"location":"misc/debugprofiler/#using-the-debug-profiler","text":"The Debug Profiler is very simple to use. It requires the debug keybind F3 + L to start the profiler. After 10 seconds, it will automatically stop; however, it can be stopped earlier by pressing the keybind again. Note Naturally, you can only profile code paths that are actually being reached. Entities and BlockEntities that you want to profile must exist in the level to show up in the results. After you have stopped the debugger, it will create a new zip within the debug/profiling subdirectory in your run directory. The file name will be formatted with the date and time as yyyy-mm-dd_hh_mi_ss-WorldName-VersionNumber.zip","title":"Using the Debug Profiler"},{"location":"misc/debugprofiler/#reading-a-profiling-result","text":"Within each sided folder ( client and server ), you will find a profiling.txt file containing the result data. At the top, it first tells you how long in milliseconds it was running and how many ticks ran in that time. Below that, you will find information similar to the snippet below: [00] levels - 96.70%/96.70% [01] | Level Name - 99.76%/96.47% [02] | | tick - 99.31%/95.81% [03] | | | entities - 47.72%/45.72% [04] | | | | regular - 98.32%/44.95% [04] | | | | blockEntities - 0.90%/0.41% [05] | | | | | unspecified - 64.26%/0.26% [05] | | | | | minecraft:furnace - 33.35%/0.14% [05] | | | | | minecraft:chest - 2.39%/0.01% Here is a small explanation of what each part means [02] tick 99.31% 95.81% The Depth of the section The Name of the Section The percentage of time it took in relation to it\u2019s parent. For Layer 0, it is the percentage of the time a tick takes. For Layer 1, it is the percentage of the time its parent takes. The second percentage tells you how much time it took from the entire tick.","title":"Reading a Profiling result"},{"location":"misc/debugprofiler/#profiling-your-own-code","text":"The Debug Profiler has basic support for Entity and BlockEntity . If you would like to profile something else, you may need to manually create your sections like so: ProfilerFiller#push(yourSectionName : String); //The code you want to profile ProfilerFiller#pop(); You can obtain the ProfilerFiller instance from a Level , MinecraftServer , or Minecraft instance. Now you just need to search the results file for your section name.","title":"Profiling your own code"},{"location":"misc/gametest/","text":"Game Tests Game Tests are a way to run in-game unit tests. The system was designed to be scalable and in parallel to run large numbers of different tests efficiently. Testing object interactions and behaviors are simply a few of the many applications of this framework. Creating a Game Test A standard Game Test follows three basic steps: A structure, or template, is loaded holding the scene on which the interaction or behavior is tested. A method conducts the logic to perform on the scene. The method logic executes. If a successful state is reached, then the test succeeds. Otherwise, the test fails and the result is stored within a lectern adjacent to the scene. As such, to create a Game Test, there must be an existing template holding the initial start state of the scene and a method which provides the logic of execution. The Test Method A Game Test method is a Consumer<GameTestHelper> reference, meaning it takes in a GameTestHelper and returns nothing. For a Game Test method to be recognized, it must have a @GameTest annotation: public class ExampleGameTests { @GameTest public static void exampleTest(GameTestHelper helper) { // Do stuff } } The @GameTest annotation also contains members which configure how the game test should run. // In some class @GameTest( setupTicks = 20L, // The test spends 20 ticks to set up for execution required = false // The failure is logged but does not affect the execution of the batch ) public static void exampleConfiguredTest(GameTestHelper helper) { // Do stuff } Relative Positioning All GameTestHelper methods translate relative coordinates within the structure template scene to its absolute coordinates using the structure block\u2019s current location. To allow for easy conversion between relative and absolute positioning, GameTestHelper#absolutePos and GameTestHelper#relativePos can be used respectively. The relative position of a structure template can be obtained in-game by loading the structure via the test command , placing the player at the wanted location, and finally running the /test pos command. This will grab the coordinates of the player relative to the closest structure within 200 blocks of the player. The command will export the relative position as a copyable text component in the chat to be used as a final local variable. Tip The local variable generated by /test pos can specify its reference name by appending it to the end of the command: /test pos <var> # Exports 'final BlockPos <var> = new BlockPos(...);' Successful Completion A Game Test method is responsible for one thing: marking the test was successful on a valid completion. If no success state was achieved before the timeout is reached (as defined by GameTest#timeoutTicks ), then the test automatically fails. There are many abstracted methods within GameTestHelper which can be used to define a successful state; however, four are extremely important to be aware of. Method Description #succeed The test is marked as successful. #succeedIf The supplied Runnable is tested immediately and succeeds if no GameTestAssertException is thrown. If the test does not succeed on the immediate tick, then it is marked as a failure. #succeedWhen The supplied Runnable is tested every tick until timeout and succeeds if the check on one of the ticks does not throw a GameTestAssertException . #succeedOnTickWhen The supplied Runnable is tested on the specified tick and will succeed if no GameTestAssertException is thrown. If the Runnable succeeds on any other tick, then it is marked as a failure. Important Game Tests are executed every tick until the test is marked as a success. As such, methods which schedule success on a given tick must be careful to always fail on any previous tick. Scheduling Actions Not all actions will occur when a test begins. Actions can be scheduled to occur at specific times or intervals: Method Description #runAtTickTime The action is ran on the specified tick. #runAfterDelay The action is ran x ticks after the current tick. #onEachTick The action is ran every tick. Assertions At any time during a Game Test, an assertion can be made to check if a given condition is true. There are numerous assertion methods within GameTestHelper ; however, it simplifies to throwing a GameTestAssertException whenever the appropriate state is not met. Generated Test Methods If Game Test methods need to be generated dynamically, a test method generator can be created. These methods take in no parameters and return a collection of TestFunction s. For a test method generator to be recognized, it must have a @GameTestGenerator annotation: public class ExampleGameTests { @GameTestGenerator public static Collection<TestFunction> exampleTests() { // Return a collection of TestFunctions } } TestFunction A TestFunction is the boxed information held by the @GameTest annotation and the method running the test. Tip Any methods annotated using @GameTest are translated into a TestFunction using GameTestRegistry#turnMethodIntoTestFunction . That method can be used as a reference for creating TestFunction s without the use of the annotation. Batching Game Tests can be executed in batches instead of registration order. A test can be added to a batch by having the same supplied GameTest#batch string. On its own, batching does not provide anything useful. However, batching can be used to perform setup and teardown states on the current level the tests are running in. This is done by annotating a method with either @BeforeBatch for setup or @AfterBatch for takedown. The #batch methods must match the string supplied to the game test. Batch methods are Consumer<ServerLevel> references, meaning they take in a ServerLevel and return nothing: public class ExampleGameTests { @BeforeBatch(batch = \"firstBatch\") public static void beforeTest(ServerLevel level) { // Perform setup } @GameTest(batch = \"firstBatch\") public static void exampleTest2(GameTestHelper helper) { // Do stuff } } Registering a Game Test A Game Test must be registered to be ran in-game. There are two methods of doing so: via the @GameTestHolder annotation or RegisterGameTestsEvent . Both registration methods still require the test methods to be annotated with either @GameTest , @GameTestGenerator , @BeforeBatch , or @AfterBatch . GameTestHolder The @GameTestHolder annotation registers any test methods within the type (class, interface, enum, or record). @GameTestHolder contains a single method which has multiple uses. In this instance, the supplied #value must be the mod id of the mod; otherwise, the test will not run under default configurations. @GameTestHolder(MODID) public class ExampleGameTests { // ... } RegisterGameTestsEvent RegisterGameTestEvent can also register either classes or methods using #register . The event listener must be added to the mod event bus. Test methods registered this way must supply their mod id to GameTest#templateNamespace on every method annotated with @GameTest . // In some class public void registerTests(RegisterGameTestsEvent event) { event.register(ExampleGameTests.class); } // In ExampleGameTests @GameTest(templateNamespace = MODID) public static void exampleTest3(GameTestHelper helper) { // Perform setup } Note The value supplied to GameTestHolder#value and GameTest#templateNamespace can be different from the current mod id. The configuration within the buildscript would need to be changed. Structure Templates Game Tests are performed within scenes loaded by structures, or templates. All templates define the dimensions of the scene and the initial data (blocks and entities) that will be loaded. The template must be stored as an .nbt file within data/<namespace>/structures . Tip A structure template can be created and saved using a structure block. The location of the template is specified by a few factors: If the namespace of the template is specified. If the class should be prepended to the name of the template. If the name of the template is specified. The namespace of the template is determined by GameTest#templateNamespace , then GameTestHolder#value if not specified, then minecraft if neither is specified. The simple class name is not prepended to the name of the template if the @PrefixGameTestTemplate is applied to a class or method with the test annotations and set to false . Otherwise, the simple class name is made lowercase and prepended and followed by a dot before the template name. The name of the template is determined by GameTest#template . If not specified, then the lowercase name of the method is used instead. // Modid for all structures will be MODID @GameTestHolder(MODID) public class ExampleGameTests { // Class name is prepended, template name is not specified // Template Location at 'modid:examplegametests.exampletest' @GameTest public static void exampleTest(GameTestHelper helper) { /*...*/ } // Class name is not prepended, template name is not specified // Template Location at 'modid:exampletest2' @PrefixGameTestTemplate(false) @GameTest public static void exampleTest2(GameTestHelper helper) { /*...*/ } // Class name is prepended, template name is specified // Template Location at 'modid:examplegametests.test_template' @GameTest(template = \"test_template\") public static void exampleTest3(GameTestHelper helper) { /*...*/ } // Class name is not prepended, template name is specified // Template Location at 'modid:test_template2' @PrefixGameTestTemplate(false) @GameTest(template = \"test_template2\") public static void exampleTest4(GameTestHelper helper) { /*...*/ } } Running Game Tests Game Tests can be run using the /test command. The test command is highly configurable; however, only a few are of importance to running tests: Subcommand Description run Runs the specified test: run <test_name> . runall Runs all available tests. runthis Runs the nearest test to the player within 15 blocks. runthese Runs tests within 200 blocks of the player. runfailed Runs all tests that failed in the previous run. Note Subcommands follow the test command: /test <subcommand> . Buildscript Configurations Game Tests provide additional configuration settings within a buildscript (the build.gradle file) to run and integrate into different settings. Enabling Other Namespaces If the buildscript was setup as recommended , then only Game Tests under the current mod id would be enabled. To enable other namespaces to load Game Tests from, a run configuration must set the property forge.enabledGameTestNamespaces to a string specifying each namespace separated by a comma. If the property is empty or not set, then all namespaces will be loaded. // Inside a run configuration property 'forge.enabledGameTestNamespaces', 'modid1,modid2,modid3' Warning There must be no spaces in-between namespaces; otherwise, the namespace will not be loaded correctly. Game Test Server Run Configuration The Game Test Server is a special configuration which runs a build server. The build server returns an exit code of the number of required, failed Game Tests. All failed tests, whether required or optional, are logged. This server can be run using gradlew runGameTestServer . Enabling Game Tests in Other Run Configurations By default, only the client , server , and gameTestServer run configurations have Game Tests enabled. If another run configuration should run Game Tests, then the forge.enableGameTest property must be set to true . // Inside a run configuration property 'forge.enableGameTest', 'true'","title":"Game Tests"},{"location":"misc/gametest/#game-tests","text":"Game Tests are a way to run in-game unit tests. The system was designed to be scalable and in parallel to run large numbers of different tests efficiently. Testing object interactions and behaviors are simply a few of the many applications of this framework.","title":"Game Tests"},{"location":"misc/gametest/#creating-a-game-test","text":"A standard Game Test follows three basic steps: A structure, or template, is loaded holding the scene on which the interaction or behavior is tested. A method conducts the logic to perform on the scene. The method logic executes. If a successful state is reached, then the test succeeds. Otherwise, the test fails and the result is stored within a lectern adjacent to the scene. As such, to create a Game Test, there must be an existing template holding the initial start state of the scene and a method which provides the logic of execution.","title":"Creating a Game Test"},{"location":"misc/gametest/#the-test-method","text":"A Game Test method is a Consumer<GameTestHelper> reference, meaning it takes in a GameTestHelper and returns nothing. For a Game Test method to be recognized, it must have a @GameTest annotation: public class ExampleGameTests { @GameTest public static void exampleTest(GameTestHelper helper) { // Do stuff } } The @GameTest annotation also contains members which configure how the game test should run. // In some class @GameTest( setupTicks = 20L, // The test spends 20 ticks to set up for execution required = false // The failure is logged but does not affect the execution of the batch ) public static void exampleConfiguredTest(GameTestHelper helper) { // Do stuff }","title":"The Test Method"},{"location":"misc/gametest/#relative-positioning","text":"All GameTestHelper methods translate relative coordinates within the structure template scene to its absolute coordinates using the structure block\u2019s current location. To allow for easy conversion between relative and absolute positioning, GameTestHelper#absolutePos and GameTestHelper#relativePos can be used respectively. The relative position of a structure template can be obtained in-game by loading the structure via the test command , placing the player at the wanted location, and finally running the /test pos command. This will grab the coordinates of the player relative to the closest structure within 200 blocks of the player. The command will export the relative position as a copyable text component in the chat to be used as a final local variable. Tip The local variable generated by /test pos can specify its reference name by appending it to the end of the command: /test pos <var> # Exports 'final BlockPos <var> = new BlockPos(...);'","title":"Relative Positioning"},{"location":"misc/gametest/#successful-completion","text":"A Game Test method is responsible for one thing: marking the test was successful on a valid completion. If no success state was achieved before the timeout is reached (as defined by GameTest#timeoutTicks ), then the test automatically fails. There are many abstracted methods within GameTestHelper which can be used to define a successful state; however, four are extremely important to be aware of. Method Description #succeed The test is marked as successful. #succeedIf The supplied Runnable is tested immediately and succeeds if no GameTestAssertException is thrown. If the test does not succeed on the immediate tick, then it is marked as a failure. #succeedWhen The supplied Runnable is tested every tick until timeout and succeeds if the check on one of the ticks does not throw a GameTestAssertException . #succeedOnTickWhen The supplied Runnable is tested on the specified tick and will succeed if no GameTestAssertException is thrown. If the Runnable succeeds on any other tick, then it is marked as a failure. Important Game Tests are executed every tick until the test is marked as a success. As such, methods which schedule success on a given tick must be careful to always fail on any previous tick.","title":"Successful Completion"},{"location":"misc/gametest/#scheduling-actions","text":"Not all actions will occur when a test begins. Actions can be scheduled to occur at specific times or intervals: Method Description #runAtTickTime The action is ran on the specified tick. #runAfterDelay The action is ran x ticks after the current tick. #onEachTick The action is ran every tick.","title":"Scheduling Actions"},{"location":"misc/gametest/#assertions","text":"At any time during a Game Test, an assertion can be made to check if a given condition is true. There are numerous assertion methods within GameTestHelper ; however, it simplifies to throwing a GameTestAssertException whenever the appropriate state is not met.","title":"Assertions"},{"location":"misc/gametest/#generated-test-methods","text":"If Game Test methods need to be generated dynamically, a test method generator can be created. These methods take in no parameters and return a collection of TestFunction s. For a test method generator to be recognized, it must have a @GameTestGenerator annotation: public class ExampleGameTests { @GameTestGenerator public static Collection<TestFunction> exampleTests() { // Return a collection of TestFunctions } }","title":"Generated Test Methods"},{"location":"misc/gametest/#testfunction","text":"A TestFunction is the boxed information held by the @GameTest annotation and the method running the test. Tip Any methods annotated using @GameTest are translated into a TestFunction using GameTestRegistry#turnMethodIntoTestFunction . That method can be used as a reference for creating TestFunction s without the use of the annotation.","title":"TestFunction"},{"location":"misc/gametest/#batching","text":"Game Tests can be executed in batches instead of registration order. A test can be added to a batch by having the same supplied GameTest#batch string. On its own, batching does not provide anything useful. However, batching can be used to perform setup and teardown states on the current level the tests are running in. This is done by annotating a method with either @BeforeBatch for setup or @AfterBatch for takedown. The #batch methods must match the string supplied to the game test. Batch methods are Consumer<ServerLevel> references, meaning they take in a ServerLevel and return nothing: public class ExampleGameTests { @BeforeBatch(batch = \"firstBatch\") public static void beforeTest(ServerLevel level) { // Perform setup } @GameTest(batch = \"firstBatch\") public static void exampleTest2(GameTestHelper helper) { // Do stuff } }","title":"Batching"},{"location":"misc/gametest/#registering-a-game-test","text":"A Game Test must be registered to be ran in-game. There are two methods of doing so: via the @GameTestHolder annotation or RegisterGameTestsEvent . Both registration methods still require the test methods to be annotated with either @GameTest , @GameTestGenerator , @BeforeBatch , or @AfterBatch .","title":"Registering a Game Test"},{"location":"misc/gametest/#gametestholder","text":"The @GameTestHolder annotation registers any test methods within the type (class, interface, enum, or record). @GameTestHolder contains a single method which has multiple uses. In this instance, the supplied #value must be the mod id of the mod; otherwise, the test will not run under default configurations. @GameTestHolder(MODID) public class ExampleGameTests { // ... }","title":"GameTestHolder"},{"location":"misc/gametest/#registergametestsevent","text":"RegisterGameTestEvent can also register either classes or methods using #register . The event listener must be added to the mod event bus. Test methods registered this way must supply their mod id to GameTest#templateNamespace on every method annotated with @GameTest . // In some class public void registerTests(RegisterGameTestsEvent event) { event.register(ExampleGameTests.class); } // In ExampleGameTests @GameTest(templateNamespace = MODID) public static void exampleTest3(GameTestHelper helper) { // Perform setup } Note The value supplied to GameTestHolder#value and GameTest#templateNamespace can be different from the current mod id. The configuration within the buildscript would need to be changed.","title":"RegisterGameTestsEvent"},{"location":"misc/gametest/#structure-templates","text":"Game Tests are performed within scenes loaded by structures, or templates. All templates define the dimensions of the scene and the initial data (blocks and entities) that will be loaded. The template must be stored as an .nbt file within data/<namespace>/structures . Tip A structure template can be created and saved using a structure block. The location of the template is specified by a few factors: If the namespace of the template is specified. If the class should be prepended to the name of the template. If the name of the template is specified. The namespace of the template is determined by GameTest#templateNamespace , then GameTestHolder#value if not specified, then minecraft if neither is specified. The simple class name is not prepended to the name of the template if the @PrefixGameTestTemplate is applied to a class or method with the test annotations and set to false . Otherwise, the simple class name is made lowercase and prepended and followed by a dot before the template name. The name of the template is determined by GameTest#template . If not specified, then the lowercase name of the method is used instead. // Modid for all structures will be MODID @GameTestHolder(MODID) public class ExampleGameTests { // Class name is prepended, template name is not specified // Template Location at 'modid:examplegametests.exampletest' @GameTest public static void exampleTest(GameTestHelper helper) { /*...*/ } // Class name is not prepended, template name is not specified // Template Location at 'modid:exampletest2' @PrefixGameTestTemplate(false) @GameTest public static void exampleTest2(GameTestHelper helper) { /*...*/ } // Class name is prepended, template name is specified // Template Location at 'modid:examplegametests.test_template' @GameTest(template = \"test_template\") public static void exampleTest3(GameTestHelper helper) { /*...*/ } // Class name is not prepended, template name is specified // Template Location at 'modid:test_template2' @PrefixGameTestTemplate(false) @GameTest(template = \"test_template2\") public static void exampleTest4(GameTestHelper helper) { /*...*/ } }","title":"Structure Templates"},{"location":"misc/gametest/#running-game-tests","text":"Game Tests can be run using the /test command. The test command is highly configurable; however, only a few are of importance to running tests: Subcommand Description run Runs the specified test: run <test_name> . runall Runs all available tests. runthis Runs the nearest test to the player within 15 blocks. runthese Runs tests within 200 blocks of the player. runfailed Runs all tests that failed in the previous run. Note Subcommands follow the test command: /test <subcommand> .","title":"Running Game Tests"},{"location":"misc/gametest/#buildscript-configurations","text":"Game Tests provide additional configuration settings within a buildscript (the build.gradle file) to run and integrate into different settings.","title":"Buildscript Configurations"},{"location":"misc/gametest/#enabling-other-namespaces","text":"If the buildscript was setup as recommended , then only Game Tests under the current mod id would be enabled. To enable other namespaces to load Game Tests from, a run configuration must set the property forge.enabledGameTestNamespaces to a string specifying each namespace separated by a comma. If the property is empty or not set, then all namespaces will be loaded. // Inside a run configuration property 'forge.enabledGameTestNamespaces', 'modid1,modid2,modid3' Warning There must be no spaces in-between namespaces; otherwise, the namespace will not be loaded correctly.","title":"Enabling Other Namespaces"},{"location":"misc/gametest/#game-test-server-run-configuration","text":"The Game Test Server is a special configuration which runs a build server. The build server returns an exit code of the number of required, failed Game Tests. All failed tests, whether required or optional, are logged. This server can be run using gradlew runGameTestServer .","title":"Game Test Server Run Configuration"},{"location":"misc/gametest/#enabling-game-tests-in-other-run-configurations","text":"By default, only the client , server , and gameTestServer run configurations have Game Tests enabled. If another run configuration should run Game Tests, then the forge.enableGameTest property must be set to true . // Inside a run configuration property 'forge.enableGameTest', 'true'","title":"Enabling Game Tests in Other Run Configurations"},{"location":"misc/updatechecker/","text":"Forge Update Checker Forge provides a very lightweight, opt-in, update-checking framework. If any mods have an available update, it will show a flashing icon on the \u2018Mods\u2019 button of the main menu and mod list along with the respective changelogs. It does not download updates automatically. Getting Started The first thing you want to do is specify the updateJSONURL parameter in your mods.toml file. The value of this parameter should be a valid URL pointing to an update JSON file. This file can be hosted on your own web server, GitHub, or wherever you want as long as it can be reliably reached by all users of your mod. Update JSON format The JSON itself has a relatively simple format as follows: { \"homepage\": \"<homepage/download page for your mod>\", \"<mcversion>\": { \"<modversion>\": \"<changelog for this version>\", // List all versions of your mod for the given Minecraft version, along with their changelogs // ... }, \"promos\": { \"<mcversion>-latest\": \"<modversion>\", // Declare the latest \"bleeding-edge\" version of your mod for the given Minecraft version \"<mcversion>-recommended\": \"<modversion>\", // Declare the latest \"stable\" version of your mod for the given Minecraft version // ... } } This is fairly self-explanatory, but some notes: The link under homepage is the link the user will be shown when the mod is outdated. Forge uses an internal algorithm to determine whether one version string of your mod is \u201cnewer\u201d than another. Most versioning schemes should be compatible, but see the ComparableVersion class if you are concerned about whether your scheme is supported. Adherence to semantic versioning is highly recommended. The changelog string can be separated into lines using \\n . Some prefer to include a abbreviated changelog, then link to an external site that provides a full listing of changes. Manually inputting data can be chore. You can configure your build.gradle to automatically update this file when building a release as Groovy has native JSON parsing support. Doing this is left as an exercise to the reader. Some examples can be found here for nocubes , Corail Tombstone and Chisels & Bits 2 . Retrieving Update Check Results You can retrieve the results of the Forge Update Checker using VersionChecker#getResult(IModInfo) . You can obtain your IModInfo via ModContainer#getModInfo . You can get your ModContainer using ModLoadingContext.get().getActiveContainer() inside your constructor, ModList.get().getModContainerById(<your modId>) , or ModList.get().getModContainerByObject(<your mod instance>) . You can obtain any other mod\u2019s ModContainer using ModList.get().getModContainerById(<modId>) . The returned object has a field status which indicates the status of the version check. Status Description FAILED The version checker could not connect to the URL provided. UP_TO_DATE The current version is equal to or newer than the latest stable version. OUTDATED There is a new stable version. BETA_OUTDATED There is a new unstable version. BETA The current version is equal to or newer than the latest unstable version. PENDING The result requested has not finished yet, so you should try again in a little bit. The returned object will also have the target version and any changelog lines as specified in update.json .","title":"Forge Update Checker"},{"location":"misc/updatechecker/#forge-update-checker","text":"Forge provides a very lightweight, opt-in, update-checking framework. If any mods have an available update, it will show a flashing icon on the \u2018Mods\u2019 button of the main menu and mod list along with the respective changelogs. It does not download updates automatically.","title":"Forge Update Checker"},{"location":"misc/updatechecker/#getting-started","text":"The first thing you want to do is specify the updateJSONURL parameter in your mods.toml file. The value of this parameter should be a valid URL pointing to an update JSON file. This file can be hosted on your own web server, GitHub, or wherever you want as long as it can be reliably reached by all users of your mod.","title":"Getting Started"},{"location":"misc/updatechecker/#update-json-format","text":"The JSON itself has a relatively simple format as follows: { \"homepage\": \"<homepage/download page for your mod>\", \"<mcversion>\": { \"<modversion>\": \"<changelog for this version>\", // List all versions of your mod for the given Minecraft version, along with their changelogs // ... }, \"promos\": { \"<mcversion>-latest\": \"<modversion>\", // Declare the latest \"bleeding-edge\" version of your mod for the given Minecraft version \"<mcversion>-recommended\": \"<modversion>\", // Declare the latest \"stable\" version of your mod for the given Minecraft version // ... } } This is fairly self-explanatory, but some notes: The link under homepage is the link the user will be shown when the mod is outdated. Forge uses an internal algorithm to determine whether one version string of your mod is \u201cnewer\u201d than another. Most versioning schemes should be compatible, but see the ComparableVersion class if you are concerned about whether your scheme is supported. Adherence to semantic versioning is highly recommended. The changelog string can be separated into lines using \\n . Some prefer to include a abbreviated changelog, then link to an external site that provides a full listing of changes. Manually inputting data can be chore. You can configure your build.gradle to automatically update this file when building a release as Groovy has native JSON parsing support. Doing this is left as an exercise to the reader. Some examples can be found here for nocubes , Corail Tombstone and Chisels & Bits 2 .","title":"Update JSON format"},{"location":"misc/updatechecker/#retrieving-update-check-results","text":"You can retrieve the results of the Forge Update Checker using VersionChecker#getResult(IModInfo) . You can obtain your IModInfo via ModContainer#getModInfo . You can get your ModContainer using ModLoadingContext.get().getActiveContainer() inside your constructor, ModList.get().getModContainerById(<your modId>) , or ModList.get().getModContainerByObject(<your mod instance>) . You can obtain any other mod\u2019s ModContainer using ModList.get().getModContainerById(<modId>) . The returned object has a field status which indicates the status of the version check. Status Description FAILED The version checker could not connect to the URL provided. UP_TO_DATE The current version is equal to or newer than the latest stable version. OUTDATED There is a new stable version. BETA_OUTDATED There is a new unstable version. BETA The current version is equal to or newer than the latest unstable version. PENDING The result requested has not finished yet, so you should try again in a little bit. The returned object will also have the target version and any changelog lines as specified in update.json .","title":"Retrieving Update Check Results"},{"location":"networking/","text":"Networking Communication between servers and clients is the backbone of a successful mod implementation. There are two primary goals in network communication: Making sure the client view is \u201cin sync\u201d with the server view The flower at coordinates (X, Y, Z) just grew Giving the client a way to tell the server that something has changed about the player the player pressed a key The most common way to accomplish these goals is to pass messages between the client and the server. These messages will usually be structured, containing data in a particular arrangement, for easy sending and receiving. There are a variety of techniques provided by Forge to facilitate communication mostly built on top of netty . The simplest, for a new mod, would be SimpleImpl , where most of the complexity of the netty system is abstracted away. It uses a message and handler style system.","title":"Introduction"},{"location":"networking/#networking","text":"Communication between servers and clients is the backbone of a successful mod implementation. There are two primary goals in network communication: Making sure the client view is \u201cin sync\u201d with the server view The flower at coordinates (X, Y, Z) just grew Giving the client a way to tell the server that something has changed about the player the player pressed a key The most common way to accomplish these goals is to pass messages between the client and the server. These messages will usually be structured, containing data in a particular arrangement, for easy sending and receiving. There are a variety of techniques provided by Forge to facilitate communication mostly built on top of netty . The simplest, for a new mod, would be SimpleImpl , where most of the complexity of the netty system is abstracted away. It uses a message and handler style system.","title":"Networking"},{"location":"networking/entities/","text":"Entities In addition to regular network messages, there are various other systems provided to handle synchronizing entity data. Spawn Data In general, the spawning of modded entities is handled separately, by Forge. Note This means that simply extending a vanilla entity class may not inherit all its behavior. You may need to implement certain vanilla behaviors yourself. You can add extra data to the spawn packet Forge sends by implementing the following interface. IEntityAdditionalSpawnData If your entity has data that is needed on the client, but does not change over time, then it can be added to the entity spawn packet using this interface. #writeSpawnData and #readSpawnData control how the data should be encoded to/decoded from the network buffer. Dynamic Data Data Parameters This is the main vanilla system for synchronizing entity data from the server to the client. As such, a number of vanilla examples are available to refer to. Firstly, you need a EntityDataAccessor<T> for the data you wish to keep synchronized. This should be stored as a static final field in your entity class, obtained by calling SynchedEntityData#defineId and passing the entity class and a serializer for that type of data. The available serializer implementations can be found as static constants within the EntityDataSerializers class. Warning You should only create data parameters for your own entities, within that entity\u2019s class . Adding parameters to entities you do not control can cause the IDs used to send that data over the network to become desynchronized, causing difficult to debug crashes. Then, override Entity#defineSynchedData and call this.entityData.define(...) for each of your data parameters, passing the parameter and an initial value to use. Remember to always call the super method first! You can then get and set these values via your entity\u2019s entityData instance. Changes made will be synchronized to the client automatically.","title":"Synchronizing Entities"},{"location":"networking/entities/#entities","text":"In addition to regular network messages, there are various other systems provided to handle synchronizing entity data.","title":"Entities"},{"location":"networking/entities/#spawn-data","text":"In general, the spawning of modded entities is handled separately, by Forge. Note This means that simply extending a vanilla entity class may not inherit all its behavior. You may need to implement certain vanilla behaviors yourself. You can add extra data to the spawn packet Forge sends by implementing the following interface.","title":"Spawn Data"},{"location":"networking/entities/#ientityadditionalspawndata","text":"If your entity has data that is needed on the client, but does not change over time, then it can be added to the entity spawn packet using this interface. #writeSpawnData and #readSpawnData control how the data should be encoded to/decoded from the network buffer.","title":"IEntityAdditionalSpawnData"},{"location":"networking/entities/#dynamic-data","text":"","title":"Dynamic Data"},{"location":"networking/entities/#data-parameters","text":"This is the main vanilla system for synchronizing entity data from the server to the client. As such, a number of vanilla examples are available to refer to. Firstly, you need a EntityDataAccessor<T> for the data you wish to keep synchronized. This should be stored as a static final field in your entity class, obtained by calling SynchedEntityData#defineId and passing the entity class and a serializer for that type of data. The available serializer implementations can be found as static constants within the EntityDataSerializers class. Warning You should only create data parameters for your own entities, within that entity\u2019s class . Adding parameters to entities you do not control can cause the IDs used to send that data over the network to become desynchronized, causing difficult to debug crashes. Then, override Entity#defineSynchedData and call this.entityData.define(...) for each of your data parameters, passing the parameter and an initial value to use. Remember to always call the super method first! You can then get and set these values via your entity\u2019s entityData instance. Changes made will be synchronized to the client automatically.","title":"Data Parameters"},{"location":"networking/simpleimpl/","text":"SimpleImpl SimpleImpl is the name given to the packet system that revolves around the SimpleChannel class. Using this system is by far the easiest way to send custom data between clients and the server. Getting Started First you need to create your SimpleChannel object. We recommend that you do this in a separate class, possibly something like ModidPacketHandler . Create your SimpleChannel as a static field in this class, like so: private static final String PROTOCOL_VERSION = \"1\"; public static final SimpleChannel INSTANCE = NetworkRegistry.newSimpleChannel( new ResourceLocation(\"mymodid\", \"main\"), () -> PROTOCOL_VERSION, PROTOCOL_VERSION::equals, PROTOCOL_VERSION::equals ); The first argument is a name for the channel. The second argument is a Supplier<String> returning the current network protocol version. The third and fourth arguments respectively are Predicate<String> checking whether an incoming connection protocol version is network-compatible with the client or server, respectively. Here, we simply compare with the PROTOCOL_VERSION field directly, meaning that the client and server PROTOCOL_VERSION s must always match or FML will deny login. The Version Checker If your mod does not require the other side to have a specific network channel, or to be a Forge instance at all, you should take care that you properly define your version compatibility checkers (the Predicate<String> parameters) to handle additional \u201cmeta-versions\u201d (defined in NetworkRegistry ) that can be received by the version checker. These are: ABSENT - if this channel is missing on the other endpoint. Note that in this case, the endpoint is still a Forge endpoint, and may have other mods. ACCEPTVANILLA - if the endpoint is a vanilla (or non-Forge) endpoint. Returning false for both means that this channel must be present on the other endpoint. If you just copy the code above, this is what it does. Note that these values are also used during the list ping compatibility check, which is responsible for showing the green check / red cross in the multiplayer server select screen. Registering Packets Next, we must declare the types of messages that we would like to send and receive. This is done using INSTANCE#registerMessage , which takes 5 parameters: The first parameter is the discriminator for the packet. This is a per-channel unique ID for the packet. We recommend you use a local variable to hold the ID, and then call registerMessage using id++ . This will guarantee 100% unique IDs. The second parameter is the actual packet class MSG . The third parameter is a BiConsumer<MSG, FriendlyByteBuf> responsible for encoding the message into the provided FriendlyByteBuf . The fourth parameter is a Function<FriendlyByteBuf, MSG> responsible for decoding the message from the provided FriendlyByteBuf . The final parameter is a BiConsumer<MSG, Supplier<NetworkEvent.Context>> responsible for handling the message itself. The last three parameters can be method references to either static or instance methods in Java. Remember that an instance method MSG#encode(FriendlyByteBuf) still satisfies BiConsumer<MSG, FriendlyByteBuf> ; the MSG simply becomes the implicit first argument. Handling Packets There are a couple things to highlight in a packet handler. A packet handler has both the message object and the network context available to it. The context allows access to the player that sent the packet (if on the server), and a way to enqueue thread-safe work. public static void handle(MyMessage msg, Supplier<NetworkEvent.Context> ctx) { ctx.get().enqueueWork(() -> { // Work that needs to be thread-safe (most work) ServerPlayer sender = ctx.get().getSender(); // the client that sent this packet // Do stuff }); ctx.get().setPacketHandled(true); } Packets sent from the server to the client should be handled in another class and wrapped via DistExecutor#unsafeRunWhenOn . // In Packet class public static void handle(MyClientMessage msg, Supplier<NetworkEvent.Context> ctx) { ctx.get().enqueueWork(() -> // Make sure it's only executed on the physical client DistExecutor.unsafeRunWhenOn(Dist.CLIENT, () -> () -> ClientPacketHandlerClass.handlePacket(msg, ctx)) ); ctx.get().setPacketHandled(true); } // In ClientPacketHandlerClass public static void handlePacket(MyClientMessage msg, Supplier<NetworkEvent.Context> ctx) { // Do stuff } Note the presence of #setPacketHandled , which is used to tell the network system that the packet has successfully completed handling. Warning As of Minecraft 1.8 packets are by default handled on the network thread. That means that your handler can not interact with most game objects directly. Forge provides a convenient way to make your code execute on the main thread instead through the supplied NetworkEvent$Context . Simply call NetworkEvent$Context#enqueueWork(Runnable) , which will call the given Runnable on the main thread at the next opportunity. Warning Be defensive when handling packets on the server. A client could attempt to exploit the packet handling by sending unexpected data. A common problem is vulnerability to arbitrary chunk generation . This typically happens when the server is trusting a block position sent by a client to access blocks and block entities. When accessing blocks and block entities in unloaded areas of the level, the server will either generate or load this area from disk, then promptly write it to disk. This can be exploited to cause catastrophic damage to a server\u2019s performance and storage space without leaving a trace. To avoid this problem, a general rule of thumb is to only access blocks and block entities if Level#hasChunkAt is true. Sending Packets Sending to the Server There is but one way to send a packet to the server. This is because there is only ever one server the client can be connected to at once. To do so, we must again use that SimpleChannel that was defined earlier. Simply call INSTANCE.sendToServer(new MyMessage()) . The message will be sent to the handler for its type, if one exists. Sending to Clients Packets can be sent directly to a client using the SimpleChannel : HANDLER.sendTo(new MyClientMessage(), serverPlayer.connection.getConnection(), NetworkDirection.PLAY_TO_CLIENT) . However, this can be quite inconvenient. Forge has some convenience functions that can be used: // Send to one player INSTANCE.send(PacketDistributor.PLAYER.with(serverPlayer), new MyMessage()); // Send to all players tracking this level chunk INSTANCE.send(PacketDistributor.TRACKING_CHUNK.with(levelChunk), new MyMessage()); // Send to all connected players INSTANCE.send(PacketDistributor.ALL.noArg(), new MyMessage()); There are additional PacketDistributor types available; check the documentation on the PacketDistributor class for more details.","title":"SimpleImpl"},{"location":"networking/simpleimpl/#simpleimpl","text":"SimpleImpl is the name given to the packet system that revolves around the SimpleChannel class. Using this system is by far the easiest way to send custom data between clients and the server.","title":"SimpleImpl"},{"location":"networking/simpleimpl/#getting-started","text":"First you need to create your SimpleChannel object. We recommend that you do this in a separate class, possibly something like ModidPacketHandler . Create your SimpleChannel as a static field in this class, like so: private static final String PROTOCOL_VERSION = \"1\"; public static final SimpleChannel INSTANCE = NetworkRegistry.newSimpleChannel( new ResourceLocation(\"mymodid\", \"main\"), () -> PROTOCOL_VERSION, PROTOCOL_VERSION::equals, PROTOCOL_VERSION::equals ); The first argument is a name for the channel. The second argument is a Supplier<String> returning the current network protocol version. The third and fourth arguments respectively are Predicate<String> checking whether an incoming connection protocol version is network-compatible with the client or server, respectively. Here, we simply compare with the PROTOCOL_VERSION field directly, meaning that the client and server PROTOCOL_VERSION s must always match or FML will deny login.","title":"Getting Started"},{"location":"networking/simpleimpl/#the-version-checker","text":"If your mod does not require the other side to have a specific network channel, or to be a Forge instance at all, you should take care that you properly define your version compatibility checkers (the Predicate<String> parameters) to handle additional \u201cmeta-versions\u201d (defined in NetworkRegistry ) that can be received by the version checker. These are: ABSENT - if this channel is missing on the other endpoint. Note that in this case, the endpoint is still a Forge endpoint, and may have other mods. ACCEPTVANILLA - if the endpoint is a vanilla (or non-Forge) endpoint. Returning false for both means that this channel must be present on the other endpoint. If you just copy the code above, this is what it does. Note that these values are also used during the list ping compatibility check, which is responsible for showing the green check / red cross in the multiplayer server select screen.","title":"The Version Checker"},{"location":"networking/simpleimpl/#registering-packets","text":"Next, we must declare the types of messages that we would like to send and receive. This is done using INSTANCE#registerMessage , which takes 5 parameters: The first parameter is the discriminator for the packet. This is a per-channel unique ID for the packet. We recommend you use a local variable to hold the ID, and then call registerMessage using id++ . This will guarantee 100% unique IDs. The second parameter is the actual packet class MSG . The third parameter is a BiConsumer<MSG, FriendlyByteBuf> responsible for encoding the message into the provided FriendlyByteBuf . The fourth parameter is a Function<FriendlyByteBuf, MSG> responsible for decoding the message from the provided FriendlyByteBuf . The final parameter is a BiConsumer<MSG, Supplier<NetworkEvent.Context>> responsible for handling the message itself. The last three parameters can be method references to either static or instance methods in Java. Remember that an instance method MSG#encode(FriendlyByteBuf) still satisfies BiConsumer<MSG, FriendlyByteBuf> ; the MSG simply becomes the implicit first argument.","title":"Registering Packets"},{"location":"networking/simpleimpl/#handling-packets","text":"There are a couple things to highlight in a packet handler. A packet handler has both the message object and the network context available to it. The context allows access to the player that sent the packet (if on the server), and a way to enqueue thread-safe work. public static void handle(MyMessage msg, Supplier<NetworkEvent.Context> ctx) { ctx.get().enqueueWork(() -> { // Work that needs to be thread-safe (most work) ServerPlayer sender = ctx.get().getSender(); // the client that sent this packet // Do stuff }); ctx.get().setPacketHandled(true); } Packets sent from the server to the client should be handled in another class and wrapped via DistExecutor#unsafeRunWhenOn . // In Packet class public static void handle(MyClientMessage msg, Supplier<NetworkEvent.Context> ctx) { ctx.get().enqueueWork(() -> // Make sure it's only executed on the physical client DistExecutor.unsafeRunWhenOn(Dist.CLIENT, () -> () -> ClientPacketHandlerClass.handlePacket(msg, ctx)) ); ctx.get().setPacketHandled(true); } // In ClientPacketHandlerClass public static void handlePacket(MyClientMessage msg, Supplier<NetworkEvent.Context> ctx) { // Do stuff } Note the presence of #setPacketHandled , which is used to tell the network system that the packet has successfully completed handling. Warning As of Minecraft 1.8 packets are by default handled on the network thread. That means that your handler can not interact with most game objects directly. Forge provides a convenient way to make your code execute on the main thread instead through the supplied NetworkEvent$Context . Simply call NetworkEvent$Context#enqueueWork(Runnable) , which will call the given Runnable on the main thread at the next opportunity. Warning Be defensive when handling packets on the server. A client could attempt to exploit the packet handling by sending unexpected data. A common problem is vulnerability to arbitrary chunk generation . This typically happens when the server is trusting a block position sent by a client to access blocks and block entities. When accessing blocks and block entities in unloaded areas of the level, the server will either generate or load this area from disk, then promptly write it to disk. This can be exploited to cause catastrophic damage to a server\u2019s performance and storage space without leaving a trace. To avoid this problem, a general rule of thumb is to only access blocks and block entities if Level#hasChunkAt is true.","title":"Handling Packets"},{"location":"networking/simpleimpl/#sending-packets","text":"","title":"Sending Packets"},{"location":"networking/simpleimpl/#sending-to-the-server","text":"There is but one way to send a packet to the server. This is because there is only ever one server the client can be connected to at once. To do so, we must again use that SimpleChannel that was defined earlier. Simply call INSTANCE.sendToServer(new MyMessage()) . The message will be sent to the handler for its type, if one exists.","title":"Sending to the Server"},{"location":"networking/simpleimpl/#sending-to-clients","text":"Packets can be sent directly to a client using the SimpleChannel : HANDLER.sendTo(new MyClientMessage(), serverPlayer.connection.getConnection(), NetworkDirection.PLAY_TO_CLIENT) . However, this can be quite inconvenient. Forge has some convenience functions that can be used: // Send to one player INSTANCE.send(PacketDistributor.PLAYER.with(serverPlayer), new MyMessage()); // Send to all players tracking this level chunk INSTANCE.send(PacketDistributor.TRACKING_CHUNK.with(levelChunk), new MyMessage()); // Send to all connected players INSTANCE.send(PacketDistributor.ALL.noArg(), new MyMessage()); There are additional PacketDistributor types available; check the documentation on the PacketDistributor class for more details.","title":"Sending to Clients"},{"location":"rendering/modelloaders/","text":"Custom Model Loaders A \u201cmodel\u201d is simply a shape. It can be a simple cube, it can be several cubes, it can be a truncated icosidodecahedron, or anything in between. Most models you\u2019ll see will be in the vanilla JSON format. Models in other formats are loaded into IModelGeometry s by an IModelLoader at runtime. Forge provides default implementations for WaveFront OBJ files, buckets, composite models, models in different render layers, and a reimplementation of Vanilla\u2019s builtin/generated item model. Most things do not care about what loaded the model or what format it\u2019s in as they are all eventually represented by an BakedModel in code. WaveFront OBJ Models Forge adds a loader for the .obj file format. To use these models, the JSON must reference the forge:obj loader. This loader accepts any model location that is in a registered namespace and whose path ends in .obj . The .mtl file should be placed in the same location with the same name as the .obj to be used automatically. The .mtl file will probably have to be manually edited to change the paths pointing to textures defined within the JSON. Additionally, the V axis for textures may be flipped depending on the external program that created the model (i.e. V = 0 may be the bottom edge, not the top). This may be rectified in the modelling program itself or done in the model JSON like so: { // Add the following line on the same level as a 'model' declaration \"loader\": \"forge:obj\", \"flip-v\": true, \"model\": \"examplemod:models/block/model.obj\", \"textures\": { // Can refer to in .mtl using #texture0 \"texture0\": \"minecraft:block/dirt\", \"particle\": \"minecraft:block/dirt\" } }","title":"Introduction"},{"location":"rendering/modelloaders/#custom-model-loaders","text":"A \u201cmodel\u201d is simply a shape. It can be a simple cube, it can be several cubes, it can be a truncated icosidodecahedron, or anything in between. Most models you\u2019ll see will be in the vanilla JSON format. Models in other formats are loaded into IModelGeometry s by an IModelLoader at runtime. Forge provides default implementations for WaveFront OBJ files, buckets, composite models, models in different render layers, and a reimplementation of Vanilla\u2019s builtin/generated item model. Most things do not care about what loaded the model or what format it\u2019s in as they are all eventually represented by an BakedModel in code.","title":"Custom Model Loaders"},{"location":"rendering/modelloaders/#wavefront-obj-models","text":"Forge adds a loader for the .obj file format. To use these models, the JSON must reference the forge:obj loader. This loader accepts any model location that is in a registered namespace and whose path ends in .obj . The .mtl file should be placed in the same location with the same name as the .obj to be used automatically. The .mtl file will probably have to be manually edited to change the paths pointing to textures defined within the JSON. Additionally, the V axis for textures may be flipped depending on the external program that created the model (i.e. V = 0 may be the bottom edge, not the top). This may be rectified in the modelling program itself or done in the model JSON like so: { // Add the following line on the same level as a 'model' declaration \"loader\": \"forge:obj\", \"flip-v\": true, \"model\": \"examplemod:models/block/model.obj\", \"textures\": { // Can refer to in .mtl using #texture0 \"texture0\": \"minecraft:block/dirt\", \"particle\": \"minecraft:block/dirt\" } }","title":"WaveFront OBJ Models"},{"location":"rendering/modelloaders/bakedmodel/","text":"BakedModel BakedModel is the result of calling UnbakedModel#bake for the vanilla model loader or IModelGeometry#bake for custom model loaders. Unlike UnbakedModel or IModelGeometry , which purely represents a shape without any concept of items or blocks, BakedModel is not as abstract. It represents geometry that has been optimized and reduced to a form where it is (almost) ready to go to the GPU. It can also process the state of an item or block to change the model. In a majority of cases, it is not really necessary to implement this interface manually. One can instead use one of the existing implementations. getOverrides Returns the ItemOverrides to use for this model. This is only used if this model is being rendered as an item. useAmbientOcclusion If the model is rendered as a block in the level, the block in question does not emit any light, and ambient occlusion is enabled. This causes the model to be rendered with ambient occlusion . isGui3d If the model is rendered as an item in an inventory, on the ground as an entity, on an item frame, etc., this makes the model look \u201cflat.\u201d In GUIs, this also disables the lighting. isCustomRenderer Important Unless you know what you\u2019re doing, just return false from this and continue on. When rendering this as an item, returning true causes the model to not be rendered, instead falling back to BlockEntityWithoutLevelRenderer#renderByItem . For certain vanilla items such as chests and banners, this method is hardcoded to copy data from the item into a BlockEntity , before using a BlockEntityRenderer to render that BE in place of the item. For all other items, it will use the BlockEntityWithoutLevelRenderer instance provided by IItemRenderProperties#getItemStackRenderer . Refer to BlockEntityWithoutLevelRenderer page for more information. getParticleIcon Whatever texture should be used for the particles. For blocks, this shows when an entity falls on it, when it breaks, etc. For items, this shows when it breaks or when it\u2019s eaten. Important The vanilla method with no parameters has been deprecated in favor of #getParticleIcon(IModelData) since model data can have an effect on how a particular model might be rendered. getTransforms Deprecated in favor of implementing #handlePerspective . The default implementation is fine if #handlePerspective is implemented. See Perspective . handlePerspective See Perspective . getQuads This is the main method of BakedModel . It returns a list of BakedQuad s: objects which contain the low-level vertex data that will be used to render the model. If the model is being rendered as a block, then the BlockState passed in is non-null. If the model is being rendered as an item, the ItemOverrides returned from #getOverrides is responsible for handling the state of the item, and the BlockState parameter will be null . The Direction passed in is used for face culling. If the block against the given side of another block being rendered is opaque, then the faces associated with that side are not rendered. If that parameter is null , all faces not associated with a side are returned (that will never be culled). The rand parameter is an instance of Random. It also takes in a non null IModelData instance. This can be used to define extra data when rendering the specific model via ModelProperty s. For example, one such property is CompositeModelData , which is used to store any additional submodel data for a model using the forge:composite model loader. Note that this method is called very often: once for every combination of non-culled face and supported block render layer (anywhere between 0 to 28 times) per block in a level . This method should be as fast as possible, and should probably cache heavily.","title":"Baked Model"},{"location":"rendering/modelloaders/bakedmodel/#bakedmodel","text":"BakedModel is the result of calling UnbakedModel#bake for the vanilla model loader or IModelGeometry#bake for custom model loaders. Unlike UnbakedModel or IModelGeometry , which purely represents a shape without any concept of items or blocks, BakedModel is not as abstract. It represents geometry that has been optimized and reduced to a form where it is (almost) ready to go to the GPU. It can also process the state of an item or block to change the model. In a majority of cases, it is not really necessary to implement this interface manually. One can instead use one of the existing implementations.","title":"BakedModel"},{"location":"rendering/modelloaders/bakedmodel/#getoverrides","text":"Returns the ItemOverrides to use for this model. This is only used if this model is being rendered as an item.","title":"getOverrides"},{"location":"rendering/modelloaders/bakedmodel/#useambientocclusion","text":"If the model is rendered as a block in the level, the block in question does not emit any light, and ambient occlusion is enabled. This causes the model to be rendered with ambient occlusion .","title":"useAmbientOcclusion"},{"location":"rendering/modelloaders/bakedmodel/#isgui3d","text":"If the model is rendered as an item in an inventory, on the ground as an entity, on an item frame, etc., this makes the model look \u201cflat.\u201d In GUIs, this also disables the lighting.","title":"isGui3d"},{"location":"rendering/modelloaders/bakedmodel/#iscustomrenderer","text":"Important Unless you know what you\u2019re doing, just return false from this and continue on. When rendering this as an item, returning true causes the model to not be rendered, instead falling back to BlockEntityWithoutLevelRenderer#renderByItem . For certain vanilla items such as chests and banners, this method is hardcoded to copy data from the item into a BlockEntity , before using a BlockEntityRenderer to render that BE in place of the item. For all other items, it will use the BlockEntityWithoutLevelRenderer instance provided by IItemRenderProperties#getItemStackRenderer . Refer to BlockEntityWithoutLevelRenderer page for more information.","title":"isCustomRenderer"},{"location":"rendering/modelloaders/bakedmodel/#getparticleicon","text":"Whatever texture should be used for the particles. For blocks, this shows when an entity falls on it, when it breaks, etc. For items, this shows when it breaks or when it\u2019s eaten. Important The vanilla method with no parameters has been deprecated in favor of #getParticleIcon(IModelData) since model data can have an effect on how a particular model might be rendered.","title":"getParticleIcon"},{"location":"rendering/modelloaders/bakedmodel/#gettransforms","text":"Deprecated in favor of implementing #handlePerspective . The default implementation is fine if #handlePerspective is implemented. See Perspective .","title":"getTransforms"},{"location":"rendering/modelloaders/bakedmodel/#handleperspective","text":"See Perspective .","title":"handlePerspective"},{"location":"rendering/modelloaders/bakedmodel/#getquads","text":"This is the main method of BakedModel . It returns a list of BakedQuad s: objects which contain the low-level vertex data that will be used to render the model. If the model is being rendered as a block, then the BlockState passed in is non-null. If the model is being rendered as an item, the ItemOverrides returned from #getOverrides is responsible for handling the state of the item, and the BlockState parameter will be null . The Direction passed in is used for face culling. If the block against the given side of another block being rendered is opaque, then the faces associated with that side are not rendered. If that parameter is null , all faces not associated with a side are returned (that will never be culled). The rand parameter is an instance of Random. It also takes in a non null IModelData instance. This can be used to define extra data when rendering the specific model via ModelProperty s. For example, one such property is CompositeModelData , which is used to store any additional submodel data for a model using the forge:composite model loader. Note that this method is called very often: once for every combination of non-culled face and supported block render layer (anywhere between 0 to 28 times) per block in a level . This method should be as fast as possible, and should probably cache heavily.","title":"getQuads"},{"location":"rendering/modelloaders/itemoverrides/","text":"ItemOverrides ItemOverrides provides a way for an BakedModel to process the state of an ItemStack and return a new BakedModel ; thereafter, the returned model replaces the old one. ItemOverrides represents an arbitrary function (BakedModel, ItemStack, ClientLevel, LivingEntity, int) \u2192 BakedModel , making it useful for dynamic models. In vanilla, it is used to implement item property overrides. ItemOverrides() Given a list of ItemOverride s, the constructor copies and bakes the list. The baked overrides may be accessed with #getOverrides . resolve This takes an BakedModel , an ItemStack , a ClientLevel , a LivingEntity , and an int to produce another BakedModel to use for rendering. This is where models can handle the state of their items. This should not mutate the level. getOverrides Returns an immutable list containing all the BakedOverride s used by this ItemOverrides . If none are applicable, this returns the empty list. BakedOverride This class represents a vanilla item override, which holds several ItemOverrides$PropertyMatcher for the properties on an item and a model to use in case those matchers are satisfied. They are the objects in the overrides array of a vanilla item JSON model: { // Inside a vanilla JSON item model \"overrides\": [ { // This is an ItemOverride \"predicate\": { // This is the Map<ResourceLocation, Float>, containing the names of properties and their minimum values \"example1:prop\": 0.5 }, // This is the 'location', or target model, of the override, which is used if the predicate above matches \"model\": \"example1:item/model\" }, { // This is another ItemOverride \"predicate\": { \"example2:prop\": 1 }, \"model\": \"example2:item/model\" } ] }","title":"Item Overrides"},{"location":"rendering/modelloaders/itemoverrides/#itemoverrides","text":"ItemOverrides provides a way for an BakedModel to process the state of an ItemStack and return a new BakedModel ; thereafter, the returned model replaces the old one. ItemOverrides represents an arbitrary function (BakedModel, ItemStack, ClientLevel, LivingEntity, int) \u2192 BakedModel , making it useful for dynamic models. In vanilla, it is used to implement item property overrides.","title":"ItemOverrides"},{"location":"rendering/modelloaders/itemoverrides/#itemoverrides_1","text":"Given a list of ItemOverride s, the constructor copies and bakes the list. The baked overrides may be accessed with #getOverrides .","title":"ItemOverrides()"},{"location":"rendering/modelloaders/itemoverrides/#resolve","text":"This takes an BakedModel , an ItemStack , a ClientLevel , a LivingEntity , and an int to produce another BakedModel to use for rendering. This is where models can handle the state of their items. This should not mutate the level.","title":"resolve"},{"location":"rendering/modelloaders/itemoverrides/#getoverrides","text":"Returns an immutable list containing all the BakedOverride s used by this ItemOverrides . If none are applicable, this returns the empty list.","title":"getOverrides"},{"location":"rendering/modelloaders/itemoverrides/#bakedoverride","text":"This class represents a vanilla item override, which holds several ItemOverrides$PropertyMatcher for the properties on an item and a model to use in case those matchers are satisfied. They are the objects in the overrides array of a vanilla item JSON model: { // Inside a vanilla JSON item model \"overrides\": [ { // This is an ItemOverride \"predicate\": { // This is the Map<ResourceLocation, Float>, containing the names of properties and their minimum values \"example1:prop\": 0.5 }, // This is the 'location', or target model, of the override, which is used if the predicate above matches \"model\": \"example1:item/model\" }, { // This is another ItemOverride \"predicate\": { \"example2:prop\": 1 }, \"model\": \"example2:item/model\" } ] }","title":"BakedOverride"},{"location":"rendering/modelloaders/perspective/","text":"Perspective When an BakedModel is being rendered as an item, it can apply special handling depending on which perspective it is being rendered in. \u201cPerspective\u201d means in what context the model is being rendered. The possible perspectives are represented in code by the ItemTransforms$TransformType enum. There are two systems for handling perspective: the deprecated vanilla system, constituted by BakedModel#getTransforms , ItemTransforms , and ItemTransform , and the Forge system, embodied by the method IForgeBakedModel#handlePerspective . The vanilla code is patched to favor using handlePerspective over the vanilla system whenever possible. TransformType NONE - Unused. THIRD_PERSON_LEFT_HAND / THIRD_PERSON_RIGHT_HAND / FIRST_PERSON_LEFT_HAND / FIRST_PERSON_RIGHT_HAND - The first person values represent when the player is holding the item in their own hand. The third person values represent when another player is holding the item and the client is looking at them in the 3rd person. Hands are self-explanatory. HEAD - Represents when any player is wearing the item in the helmet slot (e.g. pumpkins). GUI - Represents when the item is being rendered in a Screen . GROUND - Represents when the item is being rendered in the level as an ItemEntity . FIXED - Used for item frames. The Vanilla Way The vanilla way of handling perspective is through BakedModel#getTransforms . This method returns an ItemTransforms , which is a simple object that contains various ItemTransform s as public final fields. An ItemTransform represents a rotation, a translation, and a scale to be applied to the model. The ItemTransforms is a container for these, holding one for each of the TransformType s except NONE . In the vanilla implementation, calling #getTransform for NONE results in the default transform, ItemTransform#NO_TRANSFORM . The entire vanilla system for handling transforms is deprecated by Forge, and most implementations of BakedModel should simply return ItemTransforms#NO_TRANSFORMS (which is the default implementation) from BakedModel#getTransforms . Instead, they should implement #handlePerspective . The Forge Way The Forge way of handling transforms is #handlePerspective , a method patched into BakedModel . It supersedes the #getTransforms method. Additionally, the class PerspectiveMapWrapper is a simple implementation of an BakedModel with the method; it is a wrapper around other BakedModel s, augmenting them with a Map<TransformType, Transformation> to handle perspective. BakedModel#handlePerspective Given a TransformType and PoseStack , this method produces an BakedModel to be rendered. Because the returned BakedModel can be a totally new model, this method is more flexible than the vanilla method (e.g. a piece of paper that looks flat in hand but crumpled on the ground). PerspectiveMapWrapper A wrapper around other BakedModel s, this class delegates to the wrapped model for all BakedModel methods except #handlePerspective , and utilizes a simple Map<TransformType, Transformation> for #handlePerspective . However, the more interesting parts of this class are the static helper methods. getTransforms and getTransformsWithFallback Given an ItemTransforms or an ModelState , this method will extract an ImmutableMap<TransformType, Transformation> from it. To extract this information from an ModelState , each TransformType is passed to #getPartTransformation . This is how models should support custom perspective transforms through ModelState . UnbakedModel s should pass the ModelState in #bake . Then the BakedModel can use these custom transforms in #handlePerspective , composing them on top of its own. handlePerspective Given either a map of transforms or an ModelState , an BakedModel , a TransformType , and a PoseStack , this finds the BakedModel for the transform from the map or the ModelState , and then pairs it with the given model. To extract the transform from an ModelState , the TransformType is passed to #getPartTransformation . This method is meant to be a simple implementation of BakedModel#handlePerspective .","title":"Perspective"},{"location":"rendering/modelloaders/perspective/#perspective","text":"When an BakedModel is being rendered as an item, it can apply special handling depending on which perspective it is being rendered in. \u201cPerspective\u201d means in what context the model is being rendered. The possible perspectives are represented in code by the ItemTransforms$TransformType enum. There are two systems for handling perspective: the deprecated vanilla system, constituted by BakedModel#getTransforms , ItemTransforms , and ItemTransform , and the Forge system, embodied by the method IForgeBakedModel#handlePerspective . The vanilla code is patched to favor using handlePerspective over the vanilla system whenever possible.","title":"Perspective"},{"location":"rendering/modelloaders/perspective/#transformtype","text":"NONE - Unused. THIRD_PERSON_LEFT_HAND / THIRD_PERSON_RIGHT_HAND / FIRST_PERSON_LEFT_HAND / FIRST_PERSON_RIGHT_HAND - The first person values represent when the player is holding the item in their own hand. The third person values represent when another player is holding the item and the client is looking at them in the 3rd person. Hands are self-explanatory. HEAD - Represents when any player is wearing the item in the helmet slot (e.g. pumpkins). GUI - Represents when the item is being rendered in a Screen . GROUND - Represents when the item is being rendered in the level as an ItemEntity . FIXED - Used for item frames.","title":"TransformType"},{"location":"rendering/modelloaders/perspective/#the-vanilla-way","text":"The vanilla way of handling perspective is through BakedModel#getTransforms . This method returns an ItemTransforms , which is a simple object that contains various ItemTransform s as public final fields. An ItemTransform represents a rotation, a translation, and a scale to be applied to the model. The ItemTransforms is a container for these, holding one for each of the TransformType s except NONE . In the vanilla implementation, calling #getTransform for NONE results in the default transform, ItemTransform#NO_TRANSFORM . The entire vanilla system for handling transforms is deprecated by Forge, and most implementations of BakedModel should simply return ItemTransforms#NO_TRANSFORMS (which is the default implementation) from BakedModel#getTransforms . Instead, they should implement #handlePerspective .","title":"The Vanilla Way"},{"location":"rendering/modelloaders/perspective/#the-forge-way","text":"The Forge way of handling transforms is #handlePerspective , a method patched into BakedModel . It supersedes the #getTransforms method. Additionally, the class PerspectiveMapWrapper is a simple implementation of an BakedModel with the method; it is a wrapper around other BakedModel s, augmenting them with a Map<TransformType, Transformation> to handle perspective.","title":"The Forge Way"},{"location":"rendering/modelloaders/perspective/#bakedmodelhandleperspective","text":"Given a TransformType and PoseStack , this method produces an BakedModel to be rendered. Because the returned BakedModel can be a totally new model, this method is more flexible than the vanilla method (e.g. a piece of paper that looks flat in hand but crumpled on the ground).","title":"BakedModel#handlePerspective"},{"location":"rendering/modelloaders/perspective/#perspectivemapwrapper","text":"A wrapper around other BakedModel s, this class delegates to the wrapped model for all BakedModel methods except #handlePerspective , and utilizes a simple Map<TransformType, Transformation> for #handlePerspective . However, the more interesting parts of this class are the static helper methods.","title":"PerspectiveMapWrapper"},{"location":"rendering/modelloaders/perspective/#gettransforms-and-gettransformswithfallback","text":"Given an ItemTransforms or an ModelState , this method will extract an ImmutableMap<TransformType, Transformation> from it. To extract this information from an ModelState , each TransformType is passed to #getPartTransformation . This is how models should support custom perspective transforms through ModelState . UnbakedModel s should pass the ModelState in #bake . Then the BakedModel can use these custom transforms in #handlePerspective , composing them on top of its own.","title":"getTransforms and getTransformsWithFallback"},{"location":"rendering/modelloaders/perspective/#handleperspective","text":"Given either a map of transforms or an ModelState , an BakedModel , a TransformType , and a PoseStack , this finds the BakedModel for the transform from the map or the ModelState , and then pairs it with the given model. To extract the transform from an ModelState , the TransformType is passed to #getPartTransformation . This method is meant to be a simple implementation of BakedModel#handlePerspective .","title":"handlePerspective"},{"location":"resources/client/","text":"Resource Packs Resource Packs allow for the customization of client resources through the assets directory. This includes textures, models, sounds, localizations, and others. Your mod (as well as Forge itself) can also have resource packs. Any user can therefore modify all the textures, models, and other assets defined within this directory. Creating a Resource Pack Resource Packs are stored within your project\u2019s resources. The assets directory contains the contents of the pack, while the pack itself is defined by the pack.mcmeta alongside the assets folder. Your mod can have multiple asset domains, since you can add or modify already existing resource packs, like vanilla\u2019s, Forge\u2019s, or another mod\u2019s. You can then follow the steps found at the Minecraft Wiki to create any resource pack. Additional reading: Resource Locations","title":"Introduction"},{"location":"resources/client/#resource-packs","text":"Resource Packs allow for the customization of client resources through the assets directory. This includes textures, models, sounds, localizations, and others. Your mod (as well as Forge itself) can also have resource packs. Any user can therefore modify all the textures, models, and other assets defined within this directory.","title":"Resource Packs"},{"location":"resources/client/#creating-a-resource-pack","text":"Resource Packs are stored within your project\u2019s resources. The assets directory contains the contents of the pack, while the pack itself is defined by the pack.mcmeta alongside the assets folder. Your mod can have multiple asset domains, since you can add or modify already existing resource packs, like vanilla\u2019s, Forge\u2019s, or another mod\u2019s. You can then follow the steps found at the Minecraft Wiki to create any resource pack. Additional reading: Resource Locations","title":"Creating a Resource Pack"},{"location":"resources/client/models/","text":"Models The model system is Minecraft\u2019s way of giving blocks and items their shapes. Through the model system, blocks and items are mapped to their models, which define how they look. One of the main goals of the model system is to allow not only textures but the entire shape of a block/item to be changed by resource packs. Indeed, any mod that adds items or blocks also contains a mini-resource pack for their blocks and items. Model Files Models and textures are linked through ResourceLocation s but are stored in the ModelManager using ModelResourceLocation s. Models are referenced in different locations through the block or item\u2019s registry name depending on whether they are referencing block states or item models . Blocks will have their ModelResourceLocation represent their registry name along with a stringified version of its current BlockState while items will use their registry name followed by inventory . Note JSON models only support cuboid elements; there is no way to express a triangular wedge or anything like it. To have more complicated models, another format must be used. Textures Textures, like models, are contained within resource packs and are referred to with ResourceLocation s. In Minecraft, the UV coordinates (0,0) are taken to mean the top-left corner. UVs are always from 0 to 16. If a texture is larger or smaller, the coordinates are scaled to fit. A texture should also be square, and the side length of a texture should be a power of two, as doing otherwise breaks mipmapping (e.g. 1x1, 2x2, 8x8, 16x16, and 128x128 are good. 5x5 and 30x30 are not recommended because they are not powers of 2. 5x10 and 4x8 are completely broken as they are not square.). Textures should only ever be not a square if it is animated .","title":"Introduction"},{"location":"resources/client/models/#models","text":"The model system is Minecraft\u2019s way of giving blocks and items their shapes. Through the model system, blocks and items are mapped to their models, which define how they look. One of the main goals of the model system is to allow not only textures but the entire shape of a block/item to be changed by resource packs. Indeed, any mod that adds items or blocks also contains a mini-resource pack for their blocks and items.","title":"Models"},{"location":"resources/client/models/#model-files","text":"Models and textures are linked through ResourceLocation s but are stored in the ModelManager using ModelResourceLocation s. Models are referenced in different locations through the block or item\u2019s registry name depending on whether they are referencing block states or item models . Blocks will have their ModelResourceLocation represent their registry name along with a stringified version of its current BlockState while items will use their registry name followed by inventory . Note JSON models only support cuboid elements; there is no way to express a triangular wedge or anything like it. To have more complicated models, another format must be used.","title":"Model Files"},{"location":"resources/client/models/#textures","text":"Textures, like models, are contained within resource packs and are referred to with ResourceLocation s. In Minecraft, the UV coordinates (0,0) are taken to mean the top-left corner. UVs are always from 0 to 16. If a texture is larger or smaller, the coordinates are scaled to fit. A texture should also be square, and the side length of a texture should be a power of two, as doing otherwise breaks mipmapping (e.g. 1x1, 2x2, 8x8, 16x16, and 128x128 are good. 5x5 and 30x30 are not recommended because they are not powers of 2. 5x10 and 4x8 are completely broken as they are not square.). Textures should only ever be not a square if it is animated .","title":"Textures"},{"location":"resources/client/models/itemproperties/","text":"Item Properties Item properties are a way for the \u201cproperties\u201d of items to be exposed to the model system. An example is the bow, where the most important property is how far the bow has been pulled. This information is then used to choose a model for the bow, creating an animation for pulling it. An item property assigns a certain float value to every ItemStack it is registered for, and vanilla item model definitions can use these values to define \u201coverrides\u201d, where an item defaults to a certain model, but if an override matches, it overrides the model and uses another. They are useful mainly because they are continuous. For example, bows use item properties to define their pull animation. The item models are decided by the \u2018float\u2019 number predicates, it is not limited but generally between 0.0F and 1.0F . This allows resource packs to add as many models as they want for the bow pulling animation along that spectrum, instead of being stuck with four \u201cslots\u201d for their models in the animation. The same is true of the compass and clock. Adding Properties to Items ItemProperties#register is used to add a property to a certain item. The Item parameter is the item the property is being attached to (e.g. ExampleItems#APPLE ). The ResourceLocation parameter is the name given to the property (e.g. new ResourceLocation(\"pull\") ). The ItemPropertyFunction is a functional interface that takes the ItemStack , the ClientLevel it is in (may be null), the LivingEntity that holds it (may be null), and the int containing the id of the holding entity (may be 0 ), returning the float value for the property. For modded item properties, it is recommended that the modid of the mod is used as the namespace (e.g. examplemod:property and not just property , as that really means minecraft:property ). These should be done in FMLClientSetupEvent . There\u2019s also another method ItemProperties#registerGeneric that is used to add properties to all items, and it does not take Item as its parameter since all items will apply this property. Important Use FMLClientSetupEvent#enqueueWork to proceed with the tasks, since the data structures in ItemProperties are not thread-safe. Note ItemPropertyFunction is deprecated by Mojang in favor of using the subinterface ClampedItemPropertyFunction which clamps the result between 0 and 1 . Using Overrides The format of an override can be seen on the wiki , and a good example can be found in model/item/bow.json . For reference, here is a hypothetical example of an item with an examplemod:power property. If the values have no match, the default is the current model, but if there are multiple matches, the last match in the list will be selected. Important A predicate applies to all values greater than or equal to the given value. { \"parent\": \"item/generated\", \"textures\": { // Default \"layer0\": \"examplemod:items/example_partial\" }, \"overrides\": [ { // power >= .75 \"predicate\": { \"examplemod:power\": 0.75 }, \"model\": \"examplemod:item/example_powered\" } ] } And here is a hypothetical snippet from the supporting code. Unlike the older versions (lower than 1.16.x), this needs to be done on client side only because ItemProperties does not exist on server. private void setup(final FMLClientSetupEvent event) { event.enqueueWork(() -> { ItemProperties.register(ExampleItems.APPLE, new ResourceLocation(ExampleMod.MODID, \"pulling\"), (stack, level, living, id) -> { return living != null && living.isUsingItem() && living.getUseItem() == stack ? 1.0F : 0.0F; }); }); }","title":"Item Properties"},{"location":"resources/client/models/itemproperties/#item-properties","text":"Item properties are a way for the \u201cproperties\u201d of items to be exposed to the model system. An example is the bow, where the most important property is how far the bow has been pulled. This information is then used to choose a model for the bow, creating an animation for pulling it. An item property assigns a certain float value to every ItemStack it is registered for, and vanilla item model definitions can use these values to define \u201coverrides\u201d, where an item defaults to a certain model, but if an override matches, it overrides the model and uses another. They are useful mainly because they are continuous. For example, bows use item properties to define their pull animation. The item models are decided by the \u2018float\u2019 number predicates, it is not limited but generally between 0.0F and 1.0F . This allows resource packs to add as many models as they want for the bow pulling animation along that spectrum, instead of being stuck with four \u201cslots\u201d for their models in the animation. The same is true of the compass and clock.","title":"Item Properties"},{"location":"resources/client/models/itemproperties/#adding-properties-to-items","text":"ItemProperties#register is used to add a property to a certain item. The Item parameter is the item the property is being attached to (e.g. ExampleItems#APPLE ). The ResourceLocation parameter is the name given to the property (e.g. new ResourceLocation(\"pull\") ). The ItemPropertyFunction is a functional interface that takes the ItemStack , the ClientLevel it is in (may be null), the LivingEntity that holds it (may be null), and the int containing the id of the holding entity (may be 0 ), returning the float value for the property. For modded item properties, it is recommended that the modid of the mod is used as the namespace (e.g. examplemod:property and not just property , as that really means minecraft:property ). These should be done in FMLClientSetupEvent . There\u2019s also another method ItemProperties#registerGeneric that is used to add properties to all items, and it does not take Item as its parameter since all items will apply this property. Important Use FMLClientSetupEvent#enqueueWork to proceed with the tasks, since the data structures in ItemProperties are not thread-safe. Note ItemPropertyFunction is deprecated by Mojang in favor of using the subinterface ClampedItemPropertyFunction which clamps the result between 0 and 1 .","title":"Adding Properties to Items"},{"location":"resources/client/models/itemproperties/#using-overrides","text":"The format of an override can be seen on the wiki , and a good example can be found in model/item/bow.json . For reference, here is a hypothetical example of an item with an examplemod:power property. If the values have no match, the default is the current model, but if there are multiple matches, the last match in the list will be selected. Important A predicate applies to all values greater than or equal to the given value. { \"parent\": \"item/generated\", \"textures\": { // Default \"layer0\": \"examplemod:items/example_partial\" }, \"overrides\": [ { // power >= .75 \"predicate\": { \"examplemod:power\": 0.75 }, \"model\": \"examplemod:item/example_powered\" } ] } And here is a hypothetical snippet from the supporting code. Unlike the older versions (lower than 1.16.x), this needs to be done on client side only because ItemProperties does not exist on server. private void setup(final FMLClientSetupEvent event) { event.enqueueWork(() -> { ItemProperties.register(ExampleItems.APPLE, new ResourceLocation(ExampleMod.MODID, \"pulling\"), (stack, level, living, id) -> { return living != null && living.isUsingItem() && living.getUseItem() == stack ? 1.0F : 0.0F; }); }); }","title":"Using Overrides"},{"location":"resources/client/models/tinting/","text":"Coloring Textures Many blocks and items in vanilla change their texture color depending on where they are or what properties they have, such as grass. Models support specifying \u201ctint indices\u201d on faces, which are integers that can then be handled by BlockColor s and ItemColor s. See the wiki for information on how tint indices are defined in vanilla models. BlockColor / ItemColor Both of these are single-method interfaces. BlockColor takes a BlockState , a (nullable) BlockAndTintGetter , and a (nullable) BlockPos . ItemColor takes an ItemStack . Both of them take an int parameter tintIndex , which is the tint index of the face being colored. Both of them return an int , a color multiplier. This int is treated as 4 unsigned bytes, alpha, red, green, and blue, in that order, from most significant byte to least. For each pixel in the tinted face, the value of each color channel is (int)((float) base * multiplier / 255.0) , where base is the original value for the channel, and multiplier is the associated byte from the color multiplier. Note that blocks do not use the alpha channel. For example, the grass texture, untinted, looks white and gray. The BlockColor and ItemColor for grass return color multipliers with low red and blue components, but high alpha and green components, (at least in warm biomes) so when the multiplication is performed, the green is brought out and the red/blue diminished. If an item inherits from the builtin/generated model, each layer (\u201clayer0\u201d, \u201clayer1\u201d, etc.) has a tint index corresponding to its layer index. Creating Color Handlers BlockColor s need to be registered to the BlockColors instance of the game. BlockColors can be acquired through ColorHandlerEvent$Block , and an BlockColor can be registered by BlockColors#register . Note that this does not cause the BlockItem for the given block to be colored. BlockItem s are items and need to be colored with an ItemColor . @SubscribeEvent public void registerBlockColors(ColorHandlerEvent.Block event){ event.getBlockColors().register(myBlockColor, coloredBlock1, coloredBlock2, ...); } ItemColor s need to be registered to the ItemColors instance of the game. ItemColors can be acquired through ColorHandlerEvent$Item , and an ItemColor can be registered by ItemColors#register . This method is overloaded to also take Block s, which simply registers the color handler for the item Block#asItem (i.e. the block\u2019s BlockItem ). @SubscribeEvent public void registerItemColors(ColorHandlerEvent.Item event){ event.getItemColors().register(myItemColor, coloredItem1, coloredItem2, ...); }","title":"Texture Tinting"},{"location":"resources/client/models/tinting/#coloring-textures","text":"Many blocks and items in vanilla change their texture color depending on where they are or what properties they have, such as grass. Models support specifying \u201ctint indices\u201d on faces, which are integers that can then be handled by BlockColor s and ItemColor s. See the wiki for information on how tint indices are defined in vanilla models.","title":"Coloring Textures"},{"location":"resources/client/models/tinting/#blockcoloritemcolor","text":"Both of these are single-method interfaces. BlockColor takes a BlockState , a (nullable) BlockAndTintGetter , and a (nullable) BlockPos . ItemColor takes an ItemStack . Both of them take an int parameter tintIndex , which is the tint index of the face being colored. Both of them return an int , a color multiplier. This int is treated as 4 unsigned bytes, alpha, red, green, and blue, in that order, from most significant byte to least. For each pixel in the tinted face, the value of each color channel is (int)((float) base * multiplier / 255.0) , where base is the original value for the channel, and multiplier is the associated byte from the color multiplier. Note that blocks do not use the alpha channel. For example, the grass texture, untinted, looks white and gray. The BlockColor and ItemColor for grass return color multipliers with low red and blue components, but high alpha and green components, (at least in warm biomes) so when the multiplication is performed, the green is brought out and the red/blue diminished. If an item inherits from the builtin/generated model, each layer (\u201clayer0\u201d, \u201clayer1\u201d, etc.) has a tint index corresponding to its layer index.","title":"BlockColor/ItemColor"},{"location":"resources/client/models/tinting/#creating-color-handlers","text":"BlockColor s need to be registered to the BlockColors instance of the game. BlockColors can be acquired through ColorHandlerEvent$Block , and an BlockColor can be registered by BlockColors#register . Note that this does not cause the BlockItem for the given block to be colored. BlockItem s are items and need to be colored with an ItemColor . @SubscribeEvent public void registerBlockColors(ColorHandlerEvent.Block event){ event.getBlockColors().register(myBlockColor, coloredBlock1, coloredBlock2, ...); } ItemColor s need to be registered to the ItemColors instance of the game. ItemColors can be acquired through ColorHandlerEvent$Item , and an ItemColor can be registered by ItemColors#register . This method is overloaded to also take Block s, which simply registers the color handler for the item Block#asItem (i.e. the block\u2019s BlockItem ). @SubscribeEvent public void registerItemColors(ColorHandlerEvent.Item event){ event.getItemColors().register(myItemColor, coloredItem1, coloredItem2, ...); }","title":"Creating Color Handlers"},{"location":"resources/server/","text":"Datapacks In 1.13, Mojang added datapacks to the base game. They allow for the modification of the files for logical servers through the data directory. This includes advancements, loot_tables, structures, recipes, tags, etc. Forge, and your mod, can also have datapacks. Any user can therefore modify all the recipes, loot tables, and other data defined within this directory. Creating a Datapack Datapacks are stored within the data directory within your project\u2019s resources. Your mod can have multiple data domains, since you can add or modify already existing datapacks, like vanilla\u2019s, forge\u2019s, or another mod\u2019s. You can then follow the steps found here to create any datapack. Additional reading: Resource Locations","title":"Introduction"},{"location":"resources/server/#datapacks","text":"In 1.13, Mojang added datapacks to the base game. They allow for the modification of the files for logical servers through the data directory. This includes advancements, loot_tables, structures, recipes, tags, etc. Forge, and your mod, can also have datapacks. Any user can therefore modify all the recipes, loot tables, and other data defined within this directory.","title":"Datapacks"},{"location":"resources/server/#creating-a-datapack","text":"Datapacks are stored within the data directory within your project\u2019s resources. Your mod can have multiple data domains, since you can add or modify already existing datapacks, like vanilla\u2019s, forge\u2019s, or another mod\u2019s. You can then follow the steps found here to create any datapack. Additional reading: Resource Locations","title":"Creating a Datapack"},{"location":"resources/server/advancements/","text":"Advancements Advancements are tasks that can be achieved by the player which may advance the progress of the game. Advancements can trigger based on any action the player may be directly involved in. All advancement implementations within vanilla are data driven via JSON. This means that a mod is not necessary to create a new advancement, only a data pack . A full list on how to create and put these advancements within the mod\u2019s resources can be found on the Minecraft Wiki . Additionally, advancements can be loaded conditionally and defaulted depending on what information is present (mod loaded, item exists, etc.). Advancement Criteria To unlock an advancement, the specified criteria must be met. Criteria are tracked through triggers which execute when a certain action is performed: killing an entity, changing an inventory, breading animals, etc. Any time an advancement is loaded into the game, the criteria defined are read and added as listeners to the trigger. Afterwards a trigger function is called (usually named #trigger ) which checks all listeners as to whether the current state meets the conditions of the advancement criteria. The criteria listeners for the advancement are only removed once the advancement has been obtained by completing all requirements. Requirements are defined as an array of string arrays representing the name of the criteria specified on the advancement. An advancement is completed once one string array of criteria has been met: // In some advancement JSON // List of defined criteria to meet \"criteria\": { \"example_criterion1\": { /*...*/ }, \"example_criterion2\": { /*...*/ }, \"example_criterion3\": { /*...*/ }, \"example_criterion4\": { /*...*/ } }, // This advancement is only unlocked once // - Criteria 1 AND 2 have been met // OR // - Criteria 3 and 4 have been met \"requirements\": [ [ \"example_criterion1\", \"example_criterion2\" ], [ \"example_criterion3\", \"example_criterion4\" ] ] A list of criteria triggers defined by vanilla can be found in CriteriaTriggers . Additionally, the JSON formats are defined on the Minecraft Wiki . Custom Criteria Triggers Custom criteria triggers can be created by implementing SimpleCriterionTrigger for the created AbstractCriterionTriggerInstance subclass. AbstractCriterionTriggerInstance Subclass The AbstractCriterionTriggerInstance represents a single criteria defined in the criteria object. Trigger instances are responsible for holding the defined conditions, returning whether the inputs match the condition, and writing the instance to JSON for data generation. Conditions are usually passed in through the constructor. The AbstractCriterionTriggerInstance super constructor requires the instance to define the registry name of the trigger and the conditions the player must meet as an EntityPredicate$Composite . The registry name of the trigger should be supplied to the super directly while the conditions of the player should be a constructor parameter. // Where ID is the registry name of the trigger public ExampleTriggerInstance(EntityPredicate.Composite player, ItemPredicate item) { super(ID, player); // Store the item condition that must be met } Note Typically, trigger instances have a static constructor which allow these instances to be easily created for data generation. These static factory methods can also be statically imported instead of the class itself. public static ExampleTriggerInstance instance(EntityPredicate.Builder playerBuilder, ItemPredicate.Builder itemBuilder) { return new ExampleTriggerInstance(EntityPredicate.Composite.wrap(playerBuilder.build()), itemBuilder.build()); } Additionally, the #serializeToJson method should be overridden. The method should add the conditions of the instance to the other JSON data. @Override public JsonObject serializeToJson(SerializationContext context) { JsonObject obj = super.serializeToJson(context); // Write conditions to json return obj; } Finally, a method should be added which takes in the current data state and returns whether the user has met the necessary conditions. The conditions of the player are already checked through SimpleCriterionTrigger#trigger(ServerPlayer, Predicate) . Most trigger instances call this method #matches . // This method is unique for each instance and is as such not overridden public boolean matches(ItemStack stack) { // Since ItemPredicate matches a stack, a stack is the input return this.item.matches(stack); } SimpleCriterionTrigger The SimpleCriterionTrigger<T> subclass, where T is the type of the trigger instance, is responsible for specifying the registry name of the trigger, creating a trigger instance, and a method to check trigger instances and run attached listeners on success. The registry name of the trigger is supplied to #getId . This should match the registry name supplied to the trigger instance. A trigger instance is created via #createInstance . This method reads a criteria from JSON. @Override public ExampleTriggerInstance createInstance(JsonObject json, EntityPredicate.Composite player, DeserializationContext context) { // Read conditions from JSON: item return new ExampleTriggerInstance(player, item); } Finally, a method is defined to check all trigger instances and run the listeners if their condition is met. This method takes in the ServerPlayer and whatever other data defined by the matching method in the AbstractCriterionTriggerInstance subclass. This method should internally call SimpleCriterionTrigger#trigger to properly handle checking all listeners. Most trigger instances call this method #trigger . // This method is unique for each trigger and is as such not overridden public void trigger(ServerPlayer player, ItemStack stack) { this.trigger(player, // The condition checker method within the AbstractCriterionTriggerInstance subclass triggerInstance -> triggerInstance.matches(stack) ); } Afterwards, an instance should be registered using CriteriaTriggers#register during FMLCommonSetupEvent . Important CriteriaTriggers#register must be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork as the method is not thread-safe. Calling the Trigger Whenever the action being checked is performed, the #trigger method defined by the SimpleCriterionTrigger subclass should be called. // In some piece of code where the action is being performed // Where EXAMPLE_CRITERIA_TRIGGER is the custom criteria trigger public void performExampleAction(ServerPlayer player, ItemStack stack) { // Run code to perform action EXAMPLE_CRITERIA_TRIGGER.trigger(player, stack); } Advancement Rewards When an advancement is completed, rewards may be given out. These can be a combination of experience points, loot tables, recipes for the recipe book, or a function executed as a creative player. // In some advancement JSON \"rewards\": { \"experience\": 10, \"loot\": [ \"minecraft:example_loot_table\", \"minecraft:example_loot_table2\" // ... ], \"recipes\": [ \"minecraft:example_recipe\", \"minecraft:example_recipe2\" // ... ], \"function\": \"minecraft:example_function\" }","title":"Advancements"},{"location":"resources/server/advancements/#advancements","text":"Advancements are tasks that can be achieved by the player which may advance the progress of the game. Advancements can trigger based on any action the player may be directly involved in. All advancement implementations within vanilla are data driven via JSON. This means that a mod is not necessary to create a new advancement, only a data pack . A full list on how to create and put these advancements within the mod\u2019s resources can be found on the Minecraft Wiki . Additionally, advancements can be loaded conditionally and defaulted depending on what information is present (mod loaded, item exists, etc.).","title":"Advancements"},{"location":"resources/server/advancements/#advancement-criteria","text":"To unlock an advancement, the specified criteria must be met. Criteria are tracked through triggers which execute when a certain action is performed: killing an entity, changing an inventory, breading animals, etc. Any time an advancement is loaded into the game, the criteria defined are read and added as listeners to the trigger. Afterwards a trigger function is called (usually named #trigger ) which checks all listeners as to whether the current state meets the conditions of the advancement criteria. The criteria listeners for the advancement are only removed once the advancement has been obtained by completing all requirements. Requirements are defined as an array of string arrays representing the name of the criteria specified on the advancement. An advancement is completed once one string array of criteria has been met: // In some advancement JSON // List of defined criteria to meet \"criteria\": { \"example_criterion1\": { /*...*/ }, \"example_criterion2\": { /*...*/ }, \"example_criterion3\": { /*...*/ }, \"example_criterion4\": { /*...*/ } }, // This advancement is only unlocked once // - Criteria 1 AND 2 have been met // OR // - Criteria 3 and 4 have been met \"requirements\": [ [ \"example_criterion1\", \"example_criterion2\" ], [ \"example_criterion3\", \"example_criterion4\" ] ] A list of criteria triggers defined by vanilla can be found in CriteriaTriggers . Additionally, the JSON formats are defined on the Minecraft Wiki .","title":"Advancement Criteria"},{"location":"resources/server/advancements/#custom-criteria-triggers","text":"Custom criteria triggers can be created by implementing SimpleCriterionTrigger for the created AbstractCriterionTriggerInstance subclass.","title":"Custom Criteria Triggers"},{"location":"resources/server/advancements/#abstractcriteriontriggerinstance-subclass","text":"The AbstractCriterionTriggerInstance represents a single criteria defined in the criteria object. Trigger instances are responsible for holding the defined conditions, returning whether the inputs match the condition, and writing the instance to JSON for data generation. Conditions are usually passed in through the constructor. The AbstractCriterionTriggerInstance super constructor requires the instance to define the registry name of the trigger and the conditions the player must meet as an EntityPredicate$Composite . The registry name of the trigger should be supplied to the super directly while the conditions of the player should be a constructor parameter. // Where ID is the registry name of the trigger public ExampleTriggerInstance(EntityPredicate.Composite player, ItemPredicate item) { super(ID, player); // Store the item condition that must be met } Note Typically, trigger instances have a static constructor which allow these instances to be easily created for data generation. These static factory methods can also be statically imported instead of the class itself. public static ExampleTriggerInstance instance(EntityPredicate.Builder playerBuilder, ItemPredicate.Builder itemBuilder) { return new ExampleTriggerInstance(EntityPredicate.Composite.wrap(playerBuilder.build()), itemBuilder.build()); } Additionally, the #serializeToJson method should be overridden. The method should add the conditions of the instance to the other JSON data. @Override public JsonObject serializeToJson(SerializationContext context) { JsonObject obj = super.serializeToJson(context); // Write conditions to json return obj; } Finally, a method should be added which takes in the current data state and returns whether the user has met the necessary conditions. The conditions of the player are already checked through SimpleCriterionTrigger#trigger(ServerPlayer, Predicate) . Most trigger instances call this method #matches . // This method is unique for each instance and is as such not overridden public boolean matches(ItemStack stack) { // Since ItemPredicate matches a stack, a stack is the input return this.item.matches(stack); }","title":"AbstractCriterionTriggerInstance Subclass"},{"location":"resources/server/advancements/#simplecriteriontrigger","text":"The SimpleCriterionTrigger<T> subclass, where T is the type of the trigger instance, is responsible for specifying the registry name of the trigger, creating a trigger instance, and a method to check trigger instances and run attached listeners on success. The registry name of the trigger is supplied to #getId . This should match the registry name supplied to the trigger instance. A trigger instance is created via #createInstance . This method reads a criteria from JSON. @Override public ExampleTriggerInstance createInstance(JsonObject json, EntityPredicate.Composite player, DeserializationContext context) { // Read conditions from JSON: item return new ExampleTriggerInstance(player, item); } Finally, a method is defined to check all trigger instances and run the listeners if their condition is met. This method takes in the ServerPlayer and whatever other data defined by the matching method in the AbstractCriterionTriggerInstance subclass. This method should internally call SimpleCriterionTrigger#trigger to properly handle checking all listeners. Most trigger instances call this method #trigger . // This method is unique for each trigger and is as such not overridden public void trigger(ServerPlayer player, ItemStack stack) { this.trigger(player, // The condition checker method within the AbstractCriterionTriggerInstance subclass triggerInstance -> triggerInstance.matches(stack) ); } Afterwards, an instance should be registered using CriteriaTriggers#register during FMLCommonSetupEvent . Important CriteriaTriggers#register must be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork as the method is not thread-safe.","title":"SimpleCriterionTrigger"},{"location":"resources/server/advancements/#calling-the-trigger","text":"Whenever the action being checked is performed, the #trigger method defined by the SimpleCriterionTrigger subclass should be called. // In some piece of code where the action is being performed // Where EXAMPLE_CRITERIA_TRIGGER is the custom criteria trigger public void performExampleAction(ServerPlayer player, ItemStack stack) { // Run code to perform action EXAMPLE_CRITERIA_TRIGGER.trigger(player, stack); }","title":"Calling the Trigger"},{"location":"resources/server/advancements/#advancement-rewards","text":"When an advancement is completed, rewards may be given out. These can be a combination of experience points, loot tables, recipes for the recipe book, or a function executed as a creative player. // In some advancement JSON \"rewards\": { \"experience\": 10, \"loot\": [ \"minecraft:example_loot_table\", \"minecraft:example_loot_table2\" // ... ], \"recipes\": [ \"minecraft:example_recipe\", \"minecraft:example_recipe2\" // ... ], \"function\": \"minecraft:example_function\" }","title":"Advancement Rewards"},{"location":"resources/server/conditional/","text":"Conditionally-Loaded Data There are times when modders may want to include data-driven objects using information from another mod without having to explicitly make that mod a dependency. Other cases may be to swap out certain objects with other modded entries when they are present. This can be done through the conditional subsystem. Implementations Currently, conditional loading is implemented for recipes and advancements. For any conditional recipe or advancement, a list of conditions to datum pair is loaded. If the conditions specified for a datum in the list is true, then that datum is returned. Otherwise, the datum is discarded. { // The type needs to be specified for recipes as they can have custom serializers // Advancements do not need this type \"type\": \"forge:conditional\", \"recipes\": [ // Or 'advancements' for Advancements { // The conditions to check \"conditions\": [ // Conditions in the list are ANDed together { // Condition 1 }, { // Condition 2 } ], \"recipe\": { // Or 'advancement' for Advancements // The recipe to use if all conditions succeed } }, { // Next condition to check if the previous fails }, ] } Conditionally-loaded data additionally have wrappers for data generation through ConditionalRecipe$Builder and ConditionalAdvancement$Builder . Conditions Conditions are specified by setting type to the name of the condition as specified by IConditionSerializer#getID . True and False Boolean conditions consist of no data and return the expected value of the condition. They are represented by forge:true and forge:false . // For some condition { // Will always return true (or false for 'forge:false') \"type\": \"forge:true\" } Not, And, and Or Boolean operator conditions consist of the condition(s) being operated upon and apply the following logic. They are represented by forge:not , forge:and , and forge:or . // For some condition { // Inverts the result of the stored condition \"type\": \"forge:not\", \"value\": { // A condition } } // For some condition { // ANDs the stored conditions together (or ORs for 'forge:or') \"type\": \"forge:and\", \"values\": [ { // First condition }, { // Second condition to be ANDed (or ORed for 'forge:or') } ] } Mod Loaded ModLoadedCondition returns true whenever the specified mod with the given id is loaded in the current application. This is represented by forge:mod_loaded . // For some condition { \"type\": \"forge:mod_loaded\", // Returns true if 'examplemod' is loaded \"modid\": \"examplemod\" } Item Exists ItemExistsCondition returns true whenever the given item has been registered in the current application. This is represented by forge:item_exists . // For some condition { \"type\": \"forge:item_exists\", // Returns true if 'examplemod:example_item' has been registered \"item\": \"examplemod:example_item\" } Tag Empty TagEmptyCondition returns true whenever the given item tag has no items within it. This is represented by forge:tag_empty . // For some condition { \"type\": \"forge:tag_empty\", // Returns true if 'examplemod:example_tag' is an item tag with no entries \"tag\": \"examplemod:example_tag\" } Creating Custom Conditions Custom conditions can be created by implementing ICondition and its associated IConditionSerializer . ICondition Any condition only need to implement two methods: Method Description getID The registry name of the condition. Must be equivalent to IConditionSerializer#getID . Used only for data generation . test Returns true if the condition has been satisfied. Note Every #test has access to some IContext representing the state of the game. Currently, only tags can be obtained from a registry. IConditionSerializer Serializers need to implement three methods: Method Description getID The registry name of the condition. Must be equivalent to ICondition#getID . read Reads the condition data from JSON. write Writes the given condition data to JSON. Note Condition serializers are not responsible for writing or reading the type of the serializer, similar to other serializer implementations in Minecraft. Afterwards, a static instance should be declared to hold the initialized serializer and then registered using CraftingHelper#register either during the RegistryEvent$Register for RecipeSerializer s or during FMLCommonSetupEvent . // In some serializer class public static final ExampleConditionSerializer INSTANCE = new ExampleConditionSerializer(); // In some handler class public void registerSerializers(RegistryEvent.Register<RecipeSerializer<?>> event) { CraftingHelper.register(INSTANCE); } Important If using FMLCommonSetupEvent to register a condition serializer, it must be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork as CraftingHelper#register is not thread-safe.","title":"Conditionally-Loaded Data"},{"location":"resources/server/conditional/#conditionally-loaded-data","text":"There are times when modders may want to include data-driven objects using information from another mod without having to explicitly make that mod a dependency. Other cases may be to swap out certain objects with other modded entries when they are present. This can be done through the conditional subsystem.","title":"Conditionally-Loaded Data"},{"location":"resources/server/conditional/#implementations","text":"Currently, conditional loading is implemented for recipes and advancements. For any conditional recipe or advancement, a list of conditions to datum pair is loaded. If the conditions specified for a datum in the list is true, then that datum is returned. Otherwise, the datum is discarded. { // The type needs to be specified for recipes as they can have custom serializers // Advancements do not need this type \"type\": \"forge:conditional\", \"recipes\": [ // Or 'advancements' for Advancements { // The conditions to check \"conditions\": [ // Conditions in the list are ANDed together { // Condition 1 }, { // Condition 2 } ], \"recipe\": { // Or 'advancement' for Advancements // The recipe to use if all conditions succeed } }, { // Next condition to check if the previous fails }, ] } Conditionally-loaded data additionally have wrappers for data generation through ConditionalRecipe$Builder and ConditionalAdvancement$Builder .","title":"Implementations"},{"location":"resources/server/conditional/#conditions","text":"Conditions are specified by setting type to the name of the condition as specified by IConditionSerializer#getID .","title":"Conditions"},{"location":"resources/server/conditional/#true-and-false","text":"Boolean conditions consist of no data and return the expected value of the condition. They are represented by forge:true and forge:false . // For some condition { // Will always return true (or false for 'forge:false') \"type\": \"forge:true\" }","title":"True and False"},{"location":"resources/server/conditional/#not-and-and-or","text":"Boolean operator conditions consist of the condition(s) being operated upon and apply the following logic. They are represented by forge:not , forge:and , and forge:or . // For some condition { // Inverts the result of the stored condition \"type\": \"forge:not\", \"value\": { // A condition } } // For some condition { // ANDs the stored conditions together (or ORs for 'forge:or') \"type\": \"forge:and\", \"values\": [ { // First condition }, { // Second condition to be ANDed (or ORed for 'forge:or') } ] }","title":"Not, And, and Or"},{"location":"resources/server/conditional/#mod-loaded","text":"ModLoadedCondition returns true whenever the specified mod with the given id is loaded in the current application. This is represented by forge:mod_loaded . // For some condition { \"type\": \"forge:mod_loaded\", // Returns true if 'examplemod' is loaded \"modid\": \"examplemod\" }","title":"Mod Loaded"},{"location":"resources/server/conditional/#item-exists","text":"ItemExistsCondition returns true whenever the given item has been registered in the current application. This is represented by forge:item_exists . // For some condition { \"type\": \"forge:item_exists\", // Returns true if 'examplemod:example_item' has been registered \"item\": \"examplemod:example_item\" }","title":"Item Exists"},{"location":"resources/server/conditional/#tag-empty","text":"TagEmptyCondition returns true whenever the given item tag has no items within it. This is represented by forge:tag_empty . // For some condition { \"type\": \"forge:tag_empty\", // Returns true if 'examplemod:example_tag' is an item tag with no entries \"tag\": \"examplemod:example_tag\" }","title":"Tag Empty"},{"location":"resources/server/conditional/#creating-custom-conditions","text":"Custom conditions can be created by implementing ICondition and its associated IConditionSerializer .","title":"Creating Custom Conditions"},{"location":"resources/server/conditional/#icondition","text":"Any condition only need to implement two methods: Method Description getID The registry name of the condition. Must be equivalent to IConditionSerializer#getID . Used only for data generation . test Returns true if the condition has been satisfied. Note Every #test has access to some IContext representing the state of the game. Currently, only tags can be obtained from a registry.","title":"ICondition"},{"location":"resources/server/conditional/#iconditionserializer","text":"Serializers need to implement three methods: Method Description getID The registry name of the condition. Must be equivalent to ICondition#getID . read Reads the condition data from JSON. write Writes the given condition data to JSON. Note Condition serializers are not responsible for writing or reading the type of the serializer, similar to other serializer implementations in Minecraft. Afterwards, a static instance should be declared to hold the initialized serializer and then registered using CraftingHelper#register either during the RegistryEvent$Register for RecipeSerializer s or during FMLCommonSetupEvent . // In some serializer class public static final ExampleConditionSerializer INSTANCE = new ExampleConditionSerializer(); // In some handler class public void registerSerializers(RegistryEvent.Register<RecipeSerializer<?>> event) { CraftingHelper.register(INSTANCE); } Important If using FMLCommonSetupEvent to register a condition serializer, it must be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork as CraftingHelper#register is not thread-safe.","title":"IConditionSerializer"},{"location":"resources/server/glm/","text":"Global Loot Modifiers Global Loot Modifiers are a data-driven method of handling modification of harvested drops without the need to overwrite dozens to hundreds of vanilla loot tables or to handle effects that would require interactions with another mod\u2019s loot tables without knowing what mods may be loaded. Global Loot Modifiers are also stacking, rather than last-load-wins, similar to tags. Registering a Global Loot Modifier You will need 4 things: Create a global_loot_modifiers.json . This will tell Forge about your modifiers and works similar to tags . A serialized json representing your modifier. This will contain all of the data about your modification and allows data packs to tweak your effect. A class that extends IGlobalLootModifier . The operational code that makes your modifier work. Most modders can extend LootModifier as it supplies base functionality. Finally, a class that extends GlobalLootModifierSerializer for your operational class. This is registered as any other IForgeRegistryEntry . The global_loot_modifiers.json The global_loot_modifiers.json represents all loot modifiers to be loaded into the game. This file MUST be placed within data/forge/loot_modifiers/global_loot_modifiers.json . Important global_loot_modifiers.json will only be read in the forge namespace. The file will be neglected if it is under the mod\u2019s namespace. entries is an ordered list of the modifiers that will be loaded. The ResourceLocation s specified points to their associated entry within data/<namespace>/loot_modifiers/<path>.json . This is primarily relevant to data pack makers for resolving conflicts between modifiers from separate mods. replace , when true , changes the behavior from appending loot modifiers to the global list to replacing the global list entries entirely. Modders will want to use false for compatibility with other mod implementations. Datapack makers may want to specify their overrides with true . { \"replace\": false, // Must be present \"entries\": [ // Represents a loot modifier in 'data/examplemod/loot_modifiers/example_glm.json' \"examplemod:example_glm\", \"examplemod:example_glm2\" // ... ] } The Serialized JSON This file contains all of the potential variables related to your modifier, including the conditions that must be met prior to modifying any loot. Avoid hard-coded values wherever possible so that data pack makers can adjust balance if they wish to. type represents the registry name of the GlobalLootModifierSerializer used to read the associated JSON file. This must always be present. conditions should represent the loot table conditions for this modifier to activate. Conditions should avoid being hardcoded to allow datapack creators as much flexibility to adjust the criteria. This must also be always present. Important Although conditions should represent what is needed for the modifier to activate, this is only the case if using the bundled Forge classes. If using LootModifier as a subclass, all conditions will be ANDed together and checked to see if the modifier should be applied. Any additional properties read by the serializer and defined by the modifier can also be specified. // Within data/examplemod/loot_modifiers/example_glm.json { \"type\": \"examplemod:example_loot_modifier\", \"conditions\": [ // Normal loot table conditions // ... ], \"prop1\": \"val1\", \"prop2\": 10, \"prop3\": \"minecraft:dirt\" } IGlobalLootModifier To supply the functionality a global loot modifier specifies, a IGlobalLootModifier implementation must be specified. These are instances generated each time a serializer decodes the information from JSON and supplies it into this object. There is only one method that needs to be defined in order to create a new modifier: #apply . This takes in the current loot that will be generated along with the context information such as the currently level or additional defined parameters. It returns the list of drops to generate. Note The returned list of drops from any one modifier is fed into other modifiers in the order they are registered. As such, modified loot can be modified by another loot modifier. The LootModifier Subclass LootModifier is an abstract implementation of IGlobalLootModifier to provide the base functionality which most modders can easily extend and implement. This expands upon the existing interface by defining the #apply method to check the conditions to determine whether or not to modify the generated loot. There are two things of note within the subclass implementation: the constructor which must take in an array of LootItemCondition s and the #doApply method. The array of LootItemCondition s define the list of conditions that must be true before the loot can be modified. The supplied conditions are ANDed together, meaning that all conditions must be true. The #doApply method works the same as the #apply method except that it only executes once all conditions return true. public class ExampleModifier extends LootModifier { public ExampleModifier(LootItemCondition[] conditionsIn, String prop1, int prop2, Item prop3) { super(conditionsIn); // Store the rest of the parameters } @Nonnull @Override protected List<ItemStack> doApply(List<ItemStack> generatedLoot, LootContext context) { // Modify the loot and return the new drops } } GlobalLootModifierSerializer The connector between the JSON and the IGlobalLootModifier instance is the GlobalLootModifierSerializer<T> implementation, where T represents the type of the IGlobalLootModifier to use. Two methods must be defined within the serializer implementation: #read and #write . #read takes in the registry name of the JSON, the serialized JsonObject , and the array of conditions that, by most implementations, must be true to allow the loot modifier to execute. The only data that should be deserialized from the JsonObject are the custom properties specified for use by the implemented loot modifier. If no custom properties are needed, then no data should be deserialized from the JsonObject as the conditions are supplied as a parameter. #write is responsible for turning the defined loot modifier and writing it to a JsonObject . This requires that all conditions along with any custom properties must be written. For ease of convenience, #makeConditions can be called to create a new JsonObject with the conditions already serialized within. Any additional properties to be serialized can then be added to this JsonObject . This is utilized for data generation of the associated loot modifier. public ExampleModifierSerializer extends GlobalLootModifierSerializer<ExampleModifier> { @Override public ExampleModifier read(ResourceLocation location, JsonObject object, LootItemCondition[] conditions) { String prop1 = GsonHelper.getAsString(object, \"prop1\"); // Deserializer other properties return new ExampleModifier(conditions, prop1, prop2, prop3); } @Override public JsonObject write(ExampleModifier instance) { // Create json object with conditions in modifier JsonObject res = this.makeConditions(instance.conditionsIn); res.addProperty(\"prop1\", instance.prop1); // Add other properties in modifier return res; } } Examples can be found on the Forge Git repository, including silk touch and smelting effects.","title":"Global Loot Modifiers"},{"location":"resources/server/glm/#global-loot-modifiers","text":"Global Loot Modifiers are a data-driven method of handling modification of harvested drops without the need to overwrite dozens to hundreds of vanilla loot tables or to handle effects that would require interactions with another mod\u2019s loot tables without knowing what mods may be loaded. Global Loot Modifiers are also stacking, rather than last-load-wins, similar to tags.","title":"Global Loot Modifiers"},{"location":"resources/server/glm/#registering-a-global-loot-modifier","text":"You will need 4 things: Create a global_loot_modifiers.json . This will tell Forge about your modifiers and works similar to tags . A serialized json representing your modifier. This will contain all of the data about your modification and allows data packs to tweak your effect. A class that extends IGlobalLootModifier . The operational code that makes your modifier work. Most modders can extend LootModifier as it supplies base functionality. Finally, a class that extends GlobalLootModifierSerializer for your operational class. This is registered as any other IForgeRegistryEntry .","title":"Registering a Global Loot Modifier"},{"location":"resources/server/glm/#the-global_loot_modifiersjson","text":"The global_loot_modifiers.json represents all loot modifiers to be loaded into the game. This file MUST be placed within data/forge/loot_modifiers/global_loot_modifiers.json . Important global_loot_modifiers.json will only be read in the forge namespace. The file will be neglected if it is under the mod\u2019s namespace. entries is an ordered list of the modifiers that will be loaded. The ResourceLocation s specified points to their associated entry within data/<namespace>/loot_modifiers/<path>.json . This is primarily relevant to data pack makers for resolving conflicts between modifiers from separate mods. replace , when true , changes the behavior from appending loot modifiers to the global list to replacing the global list entries entirely. Modders will want to use false for compatibility with other mod implementations. Datapack makers may want to specify their overrides with true . { \"replace\": false, // Must be present \"entries\": [ // Represents a loot modifier in 'data/examplemod/loot_modifiers/example_glm.json' \"examplemod:example_glm\", \"examplemod:example_glm2\" // ... ] }","title":"The global_loot_modifiers.json"},{"location":"resources/server/glm/#the-serialized-json","text":"This file contains all of the potential variables related to your modifier, including the conditions that must be met prior to modifying any loot. Avoid hard-coded values wherever possible so that data pack makers can adjust balance if they wish to. type represents the registry name of the GlobalLootModifierSerializer used to read the associated JSON file. This must always be present. conditions should represent the loot table conditions for this modifier to activate. Conditions should avoid being hardcoded to allow datapack creators as much flexibility to adjust the criteria. This must also be always present. Important Although conditions should represent what is needed for the modifier to activate, this is only the case if using the bundled Forge classes. If using LootModifier as a subclass, all conditions will be ANDed together and checked to see if the modifier should be applied. Any additional properties read by the serializer and defined by the modifier can also be specified. // Within data/examplemod/loot_modifiers/example_glm.json { \"type\": \"examplemod:example_loot_modifier\", \"conditions\": [ // Normal loot table conditions // ... ], \"prop1\": \"val1\", \"prop2\": 10, \"prop3\": \"minecraft:dirt\" }","title":"The Serialized JSON"},{"location":"resources/server/glm/#igloballootmodifier","text":"To supply the functionality a global loot modifier specifies, a IGlobalLootModifier implementation must be specified. These are instances generated each time a serializer decodes the information from JSON and supplies it into this object. There is only one method that needs to be defined in order to create a new modifier: #apply . This takes in the current loot that will be generated along with the context information such as the currently level or additional defined parameters. It returns the list of drops to generate. Note The returned list of drops from any one modifier is fed into other modifiers in the order they are registered. As such, modified loot can be modified by another loot modifier.","title":"IGlobalLootModifier"},{"location":"resources/server/glm/#the-lootmodifier-subclass","text":"LootModifier is an abstract implementation of IGlobalLootModifier to provide the base functionality which most modders can easily extend and implement. This expands upon the existing interface by defining the #apply method to check the conditions to determine whether or not to modify the generated loot. There are two things of note within the subclass implementation: the constructor which must take in an array of LootItemCondition s and the #doApply method. The array of LootItemCondition s define the list of conditions that must be true before the loot can be modified. The supplied conditions are ANDed together, meaning that all conditions must be true. The #doApply method works the same as the #apply method except that it only executes once all conditions return true. public class ExampleModifier extends LootModifier { public ExampleModifier(LootItemCondition[] conditionsIn, String prop1, int prop2, Item prop3) { super(conditionsIn); // Store the rest of the parameters } @Nonnull @Override protected List<ItemStack> doApply(List<ItemStack> generatedLoot, LootContext context) { // Modify the loot and return the new drops } }","title":"The LootModifier Subclass"},{"location":"resources/server/glm/#globallootmodifierserializer","text":"The connector between the JSON and the IGlobalLootModifier instance is the GlobalLootModifierSerializer<T> implementation, where T represents the type of the IGlobalLootModifier to use. Two methods must be defined within the serializer implementation: #read and #write . #read takes in the registry name of the JSON, the serialized JsonObject , and the array of conditions that, by most implementations, must be true to allow the loot modifier to execute. The only data that should be deserialized from the JsonObject are the custom properties specified for use by the implemented loot modifier. If no custom properties are needed, then no data should be deserialized from the JsonObject as the conditions are supplied as a parameter. #write is responsible for turning the defined loot modifier and writing it to a JsonObject . This requires that all conditions along with any custom properties must be written. For ease of convenience, #makeConditions can be called to create a new JsonObject with the conditions already serialized within. Any additional properties to be serialized can then be added to this JsonObject . This is utilized for data generation of the associated loot modifier. public ExampleModifierSerializer extends GlobalLootModifierSerializer<ExampleModifier> { @Override public ExampleModifier read(ResourceLocation location, JsonObject object, LootItemCondition[] conditions) { String prop1 = GsonHelper.getAsString(object, \"prop1\"); // Deserializer other properties return new ExampleModifier(conditions, prop1, prop2, prop3); } @Override public JsonObject write(ExampleModifier instance) { // Create json object with conditions in modifier JsonObject res = this.makeConditions(instance.conditionsIn); res.addProperty(\"prop1\", instance.prop1); // Add other properties in modifier return res; } } Examples can be found on the Forge Git repository, including silk touch and smelting effects.","title":"GlobalLootModifierSerializer"},{"location":"resources/server/loottables/","text":"Loot Tables Loot tables are logic files which dictate what should happen when various actions or scenarios occur. Although the vanilla system deals purely with item generation, the system can be expanded to perform any number of defined actions. Data-Driven Tables Most loot tables within vanilla are data driven via JSON. This means that a mod is not necessary to create a new loot table, only a Data pack . A full list on how to create and put these loot tables within the mod\u2019s resources folder can be found on the Minecraft Wiki . Using a Loot Table A loot table is referenced by its ResourceLocation which points to data/<namespace>/loot_tables/<path>.json . The LootTable associated with the reference can be obtained using LootTables#get , where LootTables can be obtained via MinecraftServer#getLootTables . A loot table is always generated within a given context. The LootContext defines the level the table is generated in, a specific randomizer and seed if desired, luck for better generation, the LootContextParam s which define scenario context, and any dynamic information that should occur on activation. A loot context can be created using the constructor for LootContext$Builder and built using LootContext$Builder#create . The created LootContext adheres to some LootContextParamSet . The param set defines which LootContextParam s are required or optional in context for generation. A loot table generated within a given param set must only use contexts that are defined. A loot table can be generated using one of the available methods: Method Description getRandomItemsRaw Consumes the items generated by the loot table. getRandomItems Returns the items generated by the loot table. fill Fills a container with the generated loot table. Note Loot tables were built for generating items, so the methods expect some handling for the ItemStack s. Additional Features Forge provides some additional behavior to loot tables for greater control of the system. LootTableLoadEvent LootTableLoadEvent is an event fired on the Forge event bus which is fired whenever a loot table is loaded. If the event is canceled, then an empty loot table will be loaded instead. Important Do not modify a loot table\u2019s drops through this event. Those modifications should be done using global loot modifiers . Loot Pool Names Loot pools can be named using the name key. Any non-named loot pool will be the hash code of the pool prefixed by custom# . // For some loot pool { \"name\": \"example_pool\", // Pool will be named 'example_pool' \"rolls\": { // ... }, \"entries\": { // ... } } Looting Modifiers Loot tables are now affected by the LootingLevelEvent , on the Forge event bus, in addition to the looting enchantment. Additional Context Parameters Forge extends certain parameter sets to account for missing contexts which may be applicable. LootContextParamSets#CHEST now allows for a LootContextParams#KILLER_ENTITY as chest minecarts are entities which can be broken (or \u2018killed\u2019). LootContextParamSets#FISHING also allows for a LootContextParams#KILLER_ENTITY since the fishing hook is also an entity which is retracted (or \u2018killed\u2019) when the player retrieves it. Multiple Items on Smelting When using the SmeltItemFunction , a smelted recipe will now return the actual number of items from the result instead of a single smelted item (e.g. if a smelting recipe returns 3 items and there are 3 drops, then the result would be 9 smelted items instead of 3). Loot Table Id Condition Forge adds an additional LootItemCondition which allows certain items to generate for a specific table. This is typically used within global loot modifiers . // In some loot pool or pool entry { \"conditions\": [ { \"condition\": \"forge:loot_table_id\", // Will apply when the loot table is for dirt \"loot_table_id\": \"minecraft:blocks/dirt\" } ] } Can Tool Perform Action Condition Forge adds an additional LootItemCondition which checks whether the given LootContextParams#TOOL can perform the specified ToolAction . // In some loot pool or pool entry { \"conditions\": [ { \"condition\": \"forge:can_tool_perform_action\", // Will apply when the tool can strip a log like an axe \"action\": \"axe_strip\" } ] }","title":"Loot Tables"},{"location":"resources/server/loottables/#loot-tables","text":"Loot tables are logic files which dictate what should happen when various actions or scenarios occur. Although the vanilla system deals purely with item generation, the system can be expanded to perform any number of defined actions.","title":"Loot Tables"},{"location":"resources/server/loottables/#data-driven-tables","text":"Most loot tables within vanilla are data driven via JSON. This means that a mod is not necessary to create a new loot table, only a Data pack . A full list on how to create and put these loot tables within the mod\u2019s resources folder can be found on the Minecraft Wiki .","title":"Data-Driven Tables"},{"location":"resources/server/loottables/#using-a-loot-table","text":"A loot table is referenced by its ResourceLocation which points to data/<namespace>/loot_tables/<path>.json . The LootTable associated with the reference can be obtained using LootTables#get , where LootTables can be obtained via MinecraftServer#getLootTables . A loot table is always generated within a given context. The LootContext defines the level the table is generated in, a specific randomizer and seed if desired, luck for better generation, the LootContextParam s which define scenario context, and any dynamic information that should occur on activation. A loot context can be created using the constructor for LootContext$Builder and built using LootContext$Builder#create . The created LootContext adheres to some LootContextParamSet . The param set defines which LootContextParam s are required or optional in context for generation. A loot table generated within a given param set must only use contexts that are defined. A loot table can be generated using one of the available methods: Method Description getRandomItemsRaw Consumes the items generated by the loot table. getRandomItems Returns the items generated by the loot table. fill Fills a container with the generated loot table. Note Loot tables were built for generating items, so the methods expect some handling for the ItemStack s.","title":"Using a Loot Table"},{"location":"resources/server/loottables/#additional-features","text":"Forge provides some additional behavior to loot tables for greater control of the system.","title":"Additional Features"},{"location":"resources/server/loottables/#loottableloadevent","text":"LootTableLoadEvent is an event fired on the Forge event bus which is fired whenever a loot table is loaded. If the event is canceled, then an empty loot table will be loaded instead. Important Do not modify a loot table\u2019s drops through this event. Those modifications should be done using global loot modifiers .","title":"LootTableLoadEvent"},{"location":"resources/server/loottables/#loot-pool-names","text":"Loot pools can be named using the name key. Any non-named loot pool will be the hash code of the pool prefixed by custom# . // For some loot pool { \"name\": \"example_pool\", // Pool will be named 'example_pool' \"rolls\": { // ... }, \"entries\": { // ... } }","title":"Loot Pool Names"},{"location":"resources/server/loottables/#looting-modifiers","text":"Loot tables are now affected by the LootingLevelEvent , on the Forge event bus, in addition to the looting enchantment.","title":"Looting Modifiers"},{"location":"resources/server/loottables/#additional-context-parameters","text":"Forge extends certain parameter sets to account for missing contexts which may be applicable. LootContextParamSets#CHEST now allows for a LootContextParams#KILLER_ENTITY as chest minecarts are entities which can be broken (or \u2018killed\u2019). LootContextParamSets#FISHING also allows for a LootContextParams#KILLER_ENTITY since the fishing hook is also an entity which is retracted (or \u2018killed\u2019) when the player retrieves it.","title":"Additional Context Parameters"},{"location":"resources/server/loottables/#multiple-items-on-smelting","text":"When using the SmeltItemFunction , a smelted recipe will now return the actual number of items from the result instead of a single smelted item (e.g. if a smelting recipe returns 3 items and there are 3 drops, then the result would be 9 smelted items instead of 3).","title":"Multiple Items on Smelting"},{"location":"resources/server/loottables/#loot-table-id-condition","text":"Forge adds an additional LootItemCondition which allows certain items to generate for a specific table. This is typically used within global loot modifiers . // In some loot pool or pool entry { \"conditions\": [ { \"condition\": \"forge:loot_table_id\", // Will apply when the loot table is for dirt \"loot_table_id\": \"minecraft:blocks/dirt\" } ] }","title":"Loot Table Id Condition"},{"location":"resources/server/loottables/#can-tool-perform-action-condition","text":"Forge adds an additional LootItemCondition which checks whether the given LootContextParams#TOOL can perform the specified ToolAction . // In some loot pool or pool entry { \"conditions\": [ { \"condition\": \"forge:can_tool_perform_action\", // Will apply when the tool can strip a log like an axe \"action\": \"axe_strip\" } ] }","title":"Can Tool Perform Action Condition"},{"location":"resources/server/tags/","text":"Tags Tags are generalized sets of objects in the game used for grouping related things together and providing fast membership checks. Declaring Your Own Groupings Tags are declared in your mod\u2019s datapack . For example, a TagKey<Block> with a given identifier of modid:foo/tagname will reference a tag at /data/<modid>/tags/blocks/foo/tagname.json . Tags for Block s, Item s, EntityType s, Fluid s, and GameEvent s use the plural forms for their folder location while all other registries use the singular version ( EntityType uses the folder entity_types while Potion would use the folder potion ). Similarly, you may append to or override tags declared in other domains, such as Vanilla, by declaring your own JSONs. For example, to add your own mod\u2019s saplings to the Vanilla sapling tag, you would specify it in /data/minecraft/tags/blocks/saplings.json , and Vanilla will merge everything into one tag at reload, if the replace option is false. If replace is true, then all entries before the json specifying replace will be removed. Values listed that are not present will cause the tag to error unless the value is listed using an id string and required boolean set to false, as in the following example: { \"replace\": false, \"values\": [ \"minecraft:gold_ingot\", \"mymod:my_ingot\", { \"id\": \"othermod:ingot_other\", \"required\": false } ] } See the Vanilla wiki for a description of the base syntax. There is also a Forge extension on the Vanilla syntax. You may declare a remove array of the same format as the values array. Any values listed here will be removed from the tag. This acts as a finer grained version of the Vanilla replace option. Using Tags In Code Tags for all registries are automatically sent from the server to any remote clients on login and reload. Block s, Item s, EntityType s, Fluid s, and GameEvent s are special cased as they have Holder s allowing for available tags to be accessible through the object itself. Note Intrusive Holder s may be removed in a future version of Minecraft. If they are, the below methods can be used instead to query the associated Holder s. ITagManager Forge wrapped registries provide an additional helper for creating and managing tags through ITagManager which can be obtained via IForgeRegistry#tags . Tags can be created using using #createTagKey or #createOptionalTagKey . Tags or registry objects can also be checked for either or using #getTag or #getReverseTag respectively. Custom Registries Custom registries can create tags when constructing their DeferredRegister via #createTagKey or #createOptionalTagKey respectively. Their tags or registry objects can then checked for either using the IForgeRegistry obtained by calling DeferredRegister#makeRegistry . Referencing Tags There are four methods of creating a tag wrapper: Method For *Tags#create Block , Item , EntityType , Fluid , and Biome where * represents one of these types. ITagManager#createTagKey Forge wrapped vanilla registries, registries can be obtained from ForgeRegistries . DeferredRegister#createTagKey Custom forge registries. TagKey#create Vanilla registries without forge wrappers, registries can be obtained from Registry . Registry objects can check their tags or registry objects either through their Holder or through ITag / IReverseTag for vanilla or forge registry objects respectively. Vanilla registry objects can grab their associated holder using either Registry#getHolder or Registry#getHolderOrThrow and then compare if the registry object has a tag using Holder#is . Forge registry objects can grab their tag definition using either ITagManager#getTag or ITagManager#getReverseTag and then compare if a registry object has a tag using ITag#contains or IReverseTag#containsTag respectively. Tag-holding registry objects contain a method called #is in either their registry object or state-aware class to check whether the object belongs to a certain tag. As an example: public static final TagKey<Item> myItemTag = ItemTags.create(new ResourceLocation(\"mymod\", \"myitemgroup\")); public static final TagKey<Potion> myPotionTag = ForgeRegistries.POTIONS.tags().createTagKey(new ResourceLocation(\"mymod\", \"mypotiongroup\")); public static final TagKey<VillagerType> myVillagerTypeTag = TagKey.create(Registry.VILLAGER_TYPE, new ResourceLocation(\"mymod\", \"myvillagertypegroup\")); // In some method: ItemStack stack = /*...*/; boolean isInItemGroup = stack.is(myItemTag); Potion potion = /*...*/; boolean isInPotionGroup = ForgeRegistries.POTIONS.tags().getTag(myPotionTag).contains(potion); ResourceKey<VillagerType> villagerTypeKey = /*...*/; boolean isInVillagerTypeGroup = Registry.VILLAGER_TYPE.getHolder(villagerTypeKey).map(holder -> holder.is(myVillagerTypeTag)).orElse(false); Conventions There are several conventions that will help facilitate compatibility in the ecosystem: If there is a Vanilla tag that fits your block or item, add it to that tag. See the list of Vanilla tags . If there is a Forge tag that fits your block or item, add it to that tag. The list of tags declared by Forge can be seen on GitHub . If there is a group of something you feel should be shared by the community, use the forge namespace instead of your mod id. Tag naming conventions should follow Vanilla conventions. In particular, item and block groupings are plural instead of singular (e.g. minecraft:logs , minecraft:saplings ). Item tags should be sorted into subdirectories according to their type (e.g. forge:ingots/iron , forge:nuggets/brass , etc.). Migration from OreDictionary For recipes, tags can be used directly in the vanilla recipe format (see below). For matching items in code, see the section above. If you are declaring a new type of item grouping, follow a couple naming conventions: Use domain:type/material . When the name is a common one that all modders should adopt, use the forge domain. For example, brass ingots should be registered under the forge:ingots/brass tag and cobalt nuggets under the forge:nuggets/cobalt tag. Using Tags in Recipes and Advancements Tags are directly supported by Vanilla. See the respective Vanilla wiki pages for recipes and advancements for usage details.","title":"Tags"},{"location":"resources/server/tags/#tags","text":"Tags are generalized sets of objects in the game used for grouping related things together and providing fast membership checks.","title":"Tags"},{"location":"resources/server/tags/#declaring-your-own-groupings","text":"Tags are declared in your mod\u2019s datapack . For example, a TagKey<Block> with a given identifier of modid:foo/tagname will reference a tag at /data/<modid>/tags/blocks/foo/tagname.json . Tags for Block s, Item s, EntityType s, Fluid s, and GameEvent s use the plural forms for their folder location while all other registries use the singular version ( EntityType uses the folder entity_types while Potion would use the folder potion ). Similarly, you may append to or override tags declared in other domains, such as Vanilla, by declaring your own JSONs. For example, to add your own mod\u2019s saplings to the Vanilla sapling tag, you would specify it in /data/minecraft/tags/blocks/saplings.json , and Vanilla will merge everything into one tag at reload, if the replace option is false. If replace is true, then all entries before the json specifying replace will be removed. Values listed that are not present will cause the tag to error unless the value is listed using an id string and required boolean set to false, as in the following example: { \"replace\": false, \"values\": [ \"minecraft:gold_ingot\", \"mymod:my_ingot\", { \"id\": \"othermod:ingot_other\", \"required\": false } ] } See the Vanilla wiki for a description of the base syntax. There is also a Forge extension on the Vanilla syntax. You may declare a remove array of the same format as the values array. Any values listed here will be removed from the tag. This acts as a finer grained version of the Vanilla replace option.","title":"Declaring Your Own Groupings"},{"location":"resources/server/tags/#using-tags-in-code","text":"Tags for all registries are automatically sent from the server to any remote clients on login and reload. Block s, Item s, EntityType s, Fluid s, and GameEvent s are special cased as they have Holder s allowing for available tags to be accessible through the object itself. Note Intrusive Holder s may be removed in a future version of Minecraft. If they are, the below methods can be used instead to query the associated Holder s.","title":"Using Tags In Code"},{"location":"resources/server/tags/#itagmanager","text":"Forge wrapped registries provide an additional helper for creating and managing tags through ITagManager which can be obtained via IForgeRegistry#tags . Tags can be created using using #createTagKey or #createOptionalTagKey . Tags or registry objects can also be checked for either or using #getTag or #getReverseTag respectively.","title":"ITagManager"},{"location":"resources/server/tags/#custom-registries","text":"Custom registries can create tags when constructing their DeferredRegister via #createTagKey or #createOptionalTagKey respectively. Their tags or registry objects can then checked for either using the IForgeRegistry obtained by calling DeferredRegister#makeRegistry .","title":"Custom Registries"},{"location":"resources/server/tags/#referencing-tags","text":"There are four methods of creating a tag wrapper: Method For *Tags#create Block , Item , EntityType , Fluid , and Biome where * represents one of these types. ITagManager#createTagKey Forge wrapped vanilla registries, registries can be obtained from ForgeRegistries . DeferredRegister#createTagKey Custom forge registries. TagKey#create Vanilla registries without forge wrappers, registries can be obtained from Registry . Registry objects can check their tags or registry objects either through their Holder or through ITag / IReverseTag for vanilla or forge registry objects respectively. Vanilla registry objects can grab their associated holder using either Registry#getHolder or Registry#getHolderOrThrow and then compare if the registry object has a tag using Holder#is . Forge registry objects can grab their tag definition using either ITagManager#getTag or ITagManager#getReverseTag and then compare if a registry object has a tag using ITag#contains or IReverseTag#containsTag respectively. Tag-holding registry objects contain a method called #is in either their registry object or state-aware class to check whether the object belongs to a certain tag. As an example: public static final TagKey<Item> myItemTag = ItemTags.create(new ResourceLocation(\"mymod\", \"myitemgroup\")); public static final TagKey<Potion> myPotionTag = ForgeRegistries.POTIONS.tags().createTagKey(new ResourceLocation(\"mymod\", \"mypotiongroup\")); public static final TagKey<VillagerType> myVillagerTypeTag = TagKey.create(Registry.VILLAGER_TYPE, new ResourceLocation(\"mymod\", \"myvillagertypegroup\")); // In some method: ItemStack stack = /*...*/; boolean isInItemGroup = stack.is(myItemTag); Potion potion = /*...*/; boolean isInPotionGroup = ForgeRegistries.POTIONS.tags().getTag(myPotionTag).contains(potion); ResourceKey<VillagerType> villagerTypeKey = /*...*/; boolean isInVillagerTypeGroup = Registry.VILLAGER_TYPE.getHolder(villagerTypeKey).map(holder -> holder.is(myVillagerTypeTag)).orElse(false);","title":"Referencing Tags"},{"location":"resources/server/tags/#conventions","text":"There are several conventions that will help facilitate compatibility in the ecosystem: If there is a Vanilla tag that fits your block or item, add it to that tag. See the list of Vanilla tags . If there is a Forge tag that fits your block or item, add it to that tag. The list of tags declared by Forge can be seen on GitHub . If there is a group of something you feel should be shared by the community, use the forge namespace instead of your mod id. Tag naming conventions should follow Vanilla conventions. In particular, item and block groupings are plural instead of singular (e.g. minecraft:logs , minecraft:saplings ). Item tags should be sorted into subdirectories according to their type (e.g. forge:ingots/iron , forge:nuggets/brass , etc.).","title":"Conventions"},{"location":"resources/server/tags/#migration-from-oredictionary","text":"For recipes, tags can be used directly in the vanilla recipe format (see below). For matching items in code, see the section above. If you are declaring a new type of item grouping, follow a couple naming conventions: Use domain:type/material . When the name is a common one that all modders should adopt, use the forge domain. For example, brass ingots should be registered under the forge:ingots/brass tag and cobalt nuggets under the forge:nuggets/cobalt tag.","title":"Migration from OreDictionary"},{"location":"resources/server/tags/#using-tags-in-recipes-and-advancements","text":"Tags are directly supported by Vanilla. See the respective Vanilla wiki pages for recipes and advancements for usage details.","title":"Using Tags in Recipes and Advancements"},{"location":"resources/server/recipes/","text":"Recipes Recipes are a way to transform some number of objects into other objects within a Minecraft world. Although the vanilla system deals purely with item transformations, the system as a whole can be expanded to use any object the programmer creates. Data-Driven Recipes Most recipe implementations within vanilla are data driven via JSON. This means that a mod is not necessary to create a new recipe, only a Data pack . A full list on how to create and put these recipes within the mod\u2019s resources folder can be found on the Minecraft Wiki . A recipe can be obtained within the Recipe Book as a reward for completing an advancement . Recipe advancements always have minecraft:recipes/root as their parent, to not to appear on the advancement screen. The default criteria to gain the recipe advancement is a check if the user has unlocked the recipe from using it once or receiving it through a command like /recipe : // Within some recipe advancement json \"has_the_recipe\": { // Criteria label // Succeeds if examplemod:example_recipe is used \"trigger\": \"minecraft:recipe_unlocked\", \"conditions\": { \"recipe\": \"examplemod:example_recipe\" } } //... \"requirements\": [ [ \"has_the_recipe\" // ... Other criteria labels to be ORed against to unlock recipe ] ] Data-driven recipes and their unlocking advancement can be generated via RecipeProvider . Recipe Manager Recipes are loaded and stored via the RecipeManager . Any operations relating to getting available recipe(s) are handled by this manager. There are two important methods to know of: Method Description getRecipeFor Gets the first recipe that matches the current input. getRecipesFor Gets all recipes that match the current input. Each method takes in a RecipeType , which denotes what method is being applied to use the recipe (crafting, smelting, etc.), a Container which holds the configuration of the inputs, and the current level which is passed to Recipe#matches along with the container. Important Forge provides the RecipeWrapper utility class which extends Container for wrapping around IItemHandler s and passing them to methods which requires a Container parameter. // Within some method with IItemHandlerModifiable handler recipeManger.getRecipeFor(RecipeType.CRAFTING, new RecipeWrapper(handler), level); Additional Features Forge provides some additional behavior to the recipe schema and its implementations for greater control of the system. Recipe ItemStack Result Except for minecraft:stonecutting recipes, all vanilla recipe serializers expand the result tag to take in a full ItemStack as a JsonObject instead of just the item name and amount in some cases. // In some recipe JSON \"result\": { // The name of the registry item to give as a result \"item\": \"examplemod:example_item\", // The number of items to return \"count\": 4, // The tag data of the stack, can also be a string \"nbt\": { // Add tag data here } } Note The nbt tag can alternatively be a string containing a stringified NBT (or SNBT) for data which cannot be properly represented as a JSON object (such as IntArrayTag s). Conditional Recipes Recipes and their unlocking advancement can be loaded conditionally and defaulted depending on what information is present (mod loaded, item exists, etc.). Larger Crafting Grids By default, vanilla declares a maximum width and height for a crafting grid to be a 3x3 square. This can be expanded by calling ShapedRecipe#setCraftingSize with the new width and height in FMLCommonSetupEvent . Warning ShapedRecipe#setCraftingSize is NOT thread-safe. As such, it should be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork . Larger crafting grids in recipes can be data generated . Ingredient Types A few additional ingredient types are added to allow recipes to have inputs which check tag data or combine multiple ingredients into a single input checker.","title":"Introduction"},{"location":"resources/server/recipes/#recipes","text":"Recipes are a way to transform some number of objects into other objects within a Minecraft world. Although the vanilla system deals purely with item transformations, the system as a whole can be expanded to use any object the programmer creates.","title":"Recipes"},{"location":"resources/server/recipes/#data-driven-recipes","text":"Most recipe implementations within vanilla are data driven via JSON. This means that a mod is not necessary to create a new recipe, only a Data pack . A full list on how to create and put these recipes within the mod\u2019s resources folder can be found on the Minecraft Wiki . A recipe can be obtained within the Recipe Book as a reward for completing an advancement . Recipe advancements always have minecraft:recipes/root as their parent, to not to appear on the advancement screen. The default criteria to gain the recipe advancement is a check if the user has unlocked the recipe from using it once or receiving it through a command like /recipe : // Within some recipe advancement json \"has_the_recipe\": { // Criteria label // Succeeds if examplemod:example_recipe is used \"trigger\": \"minecraft:recipe_unlocked\", \"conditions\": { \"recipe\": \"examplemod:example_recipe\" } } //... \"requirements\": [ [ \"has_the_recipe\" // ... Other criteria labels to be ORed against to unlock recipe ] ] Data-driven recipes and their unlocking advancement can be generated via RecipeProvider .","title":"Data-Driven Recipes"},{"location":"resources/server/recipes/#recipe-manager","text":"Recipes are loaded and stored via the RecipeManager . Any operations relating to getting available recipe(s) are handled by this manager. There are two important methods to know of: Method Description getRecipeFor Gets the first recipe that matches the current input. getRecipesFor Gets all recipes that match the current input. Each method takes in a RecipeType , which denotes what method is being applied to use the recipe (crafting, smelting, etc.), a Container which holds the configuration of the inputs, and the current level which is passed to Recipe#matches along with the container. Important Forge provides the RecipeWrapper utility class which extends Container for wrapping around IItemHandler s and passing them to methods which requires a Container parameter. // Within some method with IItemHandlerModifiable handler recipeManger.getRecipeFor(RecipeType.CRAFTING, new RecipeWrapper(handler), level);","title":"Recipe Manager"},{"location":"resources/server/recipes/#additional-features","text":"Forge provides some additional behavior to the recipe schema and its implementations for greater control of the system.","title":"Additional Features"},{"location":"resources/server/recipes/#recipe-itemstack-result","text":"Except for minecraft:stonecutting recipes, all vanilla recipe serializers expand the result tag to take in a full ItemStack as a JsonObject instead of just the item name and amount in some cases. // In some recipe JSON \"result\": { // The name of the registry item to give as a result \"item\": \"examplemod:example_item\", // The number of items to return \"count\": 4, // The tag data of the stack, can also be a string \"nbt\": { // Add tag data here } } Note The nbt tag can alternatively be a string containing a stringified NBT (or SNBT) for data which cannot be properly represented as a JSON object (such as IntArrayTag s).","title":"Recipe ItemStack Result"},{"location":"resources/server/recipes/#conditional-recipes","text":"Recipes and their unlocking advancement can be loaded conditionally and defaulted depending on what information is present (mod loaded, item exists, etc.).","title":"Conditional Recipes"},{"location":"resources/server/recipes/#larger-crafting-grids","text":"By default, vanilla declares a maximum width and height for a crafting grid to be a 3x3 square. This can be expanded by calling ShapedRecipe#setCraftingSize with the new width and height in FMLCommonSetupEvent . Warning ShapedRecipe#setCraftingSize is NOT thread-safe. As such, it should be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork . Larger crafting grids in recipes can be data generated .","title":"Larger Crafting Grids"},{"location":"resources/server/recipes/#ingredient-types","text":"A few additional ingredient types are added to allow recipes to have inputs which check tag data or combine multiple ingredients into a single input checker.","title":"Ingredient Types"},{"location":"resources/server/recipes/custom/","text":"Custom Recipes Every recipe definition is made up of three components: the Recipe implementation which holds the data and handles the execution logic with the provided inputs, the RecipeType which represents the category or context the recipe will be used in, and the RecipeSerializer which handles decoding and network communication of the recipe data. How one chooses to use the recipe is up to the implementor. Recipe The Recipe interface describes the recipe data and the execution logic. This includes matching the inputs and providing the associated result. As the recipe subsystem performs item transformations by default, the inputs are supplied through a Container subtype. Important The Container s passed into the recipe should be treated as if its contents were immutable. Any mutable operations should be performed on a copy of the input through ItemStack#copy . To be able to obtain a recipe instance from the manager, #matches must return true. This method checks against the provided container to see whether the associated inputs are valid. Ingredient s can be used for validation by calling Ingredient#test . If the recipe has been chosen, it is then built using #assemble which may use data from the inputs to create the result. Tip #assemble should always produce a unique ItemStack . If unsure whether #assemble does so, call ItemStack#copy on the result before returning. Most of the other methods are purely for integration with the recipe book. public record ExampleRecipe(Ingredient input, int data, ItemStack output) implements Recipe<Container> { // Implement methods here } Note While a record is used in the above example, it is not required to do so in your own implementation. RecipeType RecipeType is responsible for defining the category or context the recipe will be used within. For example, if a recipe was going to be smelted in a furnace, it would have a type of RecipeType#SMELTING . Being blasted in a blast furnace would have a type of RecipeType#BLASTING . If none of the existing types match what context the recipe will be used within, then a new RecipeType must be registered . The RecipeType instance must then be returned by Recipe#getType in the new recipe subtype. // For some RecipeType EXAMPLE_TYPE // In ExampleRecipe @Override public RecipeType<?> getType() { return EXAMPLE_TYPE; } RecipeSerializer A RecipeSerializer is responsible for decoding JSONs and communicating across the network for an associated Recipe subtype. Each recipe decoded by the serializer is saved as a unique instance within the RecipeManager . A RecipeSerializer must be registered . Only three methods need to be implemented for a RecipeSerializer : Method Description fromJson Decodes a JSON into the Recipe subtype. toNetwork Encodes a Recipe to the buffer to send to the client. The recipe identifier does not need to be encoded. fromNetwork Decodes a Recipe from the buffer sent from the server. The recipe identifier does not need to be decoded. Tip For ease of convenience, the RecipeSerializer subtype can extend ForgeRegistryEntry to implement the methods within IForgeRegistryEntry . public class ExampleSerializer extends ForgeRegistryEntry<RecipeSerializer<?>> implements RecipeSerializer<ExampleRecipe> { // Implement methods here } The RecipeSerializer instance must then be returned by Recipe#getSerializer in the new recipe subtype. // For some RecipeSerializer EXAMPLE_SERIALIZER // In ExampleRecipe @Override public RecipeSerializer<?> getSerializer() { return EXAMPLE_SERIALIZER; } Tip There are some useful methods to make reading and writing data for recipes easier. Ingredient s can use #fromJson , #toNetwork , and #fromNetwork while ItemStack s can use CraftingHelper#getItemStack , FriendlyByteBuf#writeItem , and FriendlyByteBuf# readItem . Building the JSON Custom Recipe JSONs are stored in the same place as other recipes . The specified type should represent the registry name of the recipe serializer . Any additional data is specified by the serializer during decoding. { // The custom serializer registry name \"type\": \"examplemod:example_serializer\", \"input\": { // Some ingredient input }, \"data\": 0, // Some data wanted for the recipe \"output\": { // Some stack output } } Non-Item Logic If items are not used as part of the input or result of a recipe, then the normal methods provided in RecipeManager will not be useful. Instead, an additional method for testing a recipe\u2019s validity and/or supplying the result should be added to the custom Recipe instance. From there, all the recipes for that specific RecipeType can be obtained via RecipeManager#getAllRecipesFor and then checked and/or supplied the result using the newly implemented methods. // In some Recipe subimplementation ExampleRecipe // Checks the block at the position to see if it matches the stored data boolean matches(Level level, BlockPos pos); // Creates the block state to set the block at the specified position to BlockState assemble(); // In some manager class public Optional<ExampleRecipe> getRecipeFor(Level level, BlockPos pos) { return level.getRecipeManager() .getAllRecipesFor(exampleRecipeType) // Gets all recipes .stream() // Looks through all recipes for types .filter(recipe -> recipe.matches(level, pos)) // Checks if the recipe inputs are valid .findFirst(); // Finds the first recipe whose inputs match } Data Generation All custom recipes, regardless of input or output data, can be created into a FinishedRecipe for data generation using the RecipeProvider .","title":"Custom Recipes"},{"location":"resources/server/recipes/custom/#custom-recipes","text":"Every recipe definition is made up of three components: the Recipe implementation which holds the data and handles the execution logic with the provided inputs, the RecipeType which represents the category or context the recipe will be used in, and the RecipeSerializer which handles decoding and network communication of the recipe data. How one chooses to use the recipe is up to the implementor.","title":"Custom Recipes"},{"location":"resources/server/recipes/custom/#recipe","text":"The Recipe interface describes the recipe data and the execution logic. This includes matching the inputs and providing the associated result. As the recipe subsystem performs item transformations by default, the inputs are supplied through a Container subtype. Important The Container s passed into the recipe should be treated as if its contents were immutable. Any mutable operations should be performed on a copy of the input through ItemStack#copy . To be able to obtain a recipe instance from the manager, #matches must return true. This method checks against the provided container to see whether the associated inputs are valid. Ingredient s can be used for validation by calling Ingredient#test . If the recipe has been chosen, it is then built using #assemble which may use data from the inputs to create the result. Tip #assemble should always produce a unique ItemStack . If unsure whether #assemble does so, call ItemStack#copy on the result before returning. Most of the other methods are purely for integration with the recipe book. public record ExampleRecipe(Ingredient input, int data, ItemStack output) implements Recipe<Container> { // Implement methods here } Note While a record is used in the above example, it is not required to do so in your own implementation.","title":"Recipe"},{"location":"resources/server/recipes/custom/#recipetype","text":"RecipeType is responsible for defining the category or context the recipe will be used within. For example, if a recipe was going to be smelted in a furnace, it would have a type of RecipeType#SMELTING . Being blasted in a blast furnace would have a type of RecipeType#BLASTING . If none of the existing types match what context the recipe will be used within, then a new RecipeType must be registered . The RecipeType instance must then be returned by Recipe#getType in the new recipe subtype. // For some RecipeType EXAMPLE_TYPE // In ExampleRecipe @Override public RecipeType<?> getType() { return EXAMPLE_TYPE; }","title":"RecipeType"},{"location":"resources/server/recipes/custom/#recipeserializer","text":"A RecipeSerializer is responsible for decoding JSONs and communicating across the network for an associated Recipe subtype. Each recipe decoded by the serializer is saved as a unique instance within the RecipeManager . A RecipeSerializer must be registered . Only three methods need to be implemented for a RecipeSerializer : Method Description fromJson Decodes a JSON into the Recipe subtype. toNetwork Encodes a Recipe to the buffer to send to the client. The recipe identifier does not need to be encoded. fromNetwork Decodes a Recipe from the buffer sent from the server. The recipe identifier does not need to be decoded. Tip For ease of convenience, the RecipeSerializer subtype can extend ForgeRegistryEntry to implement the methods within IForgeRegistryEntry . public class ExampleSerializer extends ForgeRegistryEntry<RecipeSerializer<?>> implements RecipeSerializer<ExampleRecipe> { // Implement methods here } The RecipeSerializer instance must then be returned by Recipe#getSerializer in the new recipe subtype. // For some RecipeSerializer EXAMPLE_SERIALIZER // In ExampleRecipe @Override public RecipeSerializer<?> getSerializer() { return EXAMPLE_SERIALIZER; } Tip There are some useful methods to make reading and writing data for recipes easier. Ingredient s can use #fromJson , #toNetwork , and #fromNetwork while ItemStack s can use CraftingHelper#getItemStack , FriendlyByteBuf#writeItem , and FriendlyByteBuf# readItem .","title":"RecipeSerializer"},{"location":"resources/server/recipes/custom/#building-the-json","text":"Custom Recipe JSONs are stored in the same place as other recipes . The specified type should represent the registry name of the recipe serializer . Any additional data is specified by the serializer during decoding. { // The custom serializer registry name \"type\": \"examplemod:example_serializer\", \"input\": { // Some ingredient input }, \"data\": 0, // Some data wanted for the recipe \"output\": { // Some stack output } }","title":"Building the JSON"},{"location":"resources/server/recipes/custom/#non-item-logic","text":"If items are not used as part of the input or result of a recipe, then the normal methods provided in RecipeManager will not be useful. Instead, an additional method for testing a recipe\u2019s validity and/or supplying the result should be added to the custom Recipe instance. From there, all the recipes for that specific RecipeType can be obtained via RecipeManager#getAllRecipesFor and then checked and/or supplied the result using the newly implemented methods. // In some Recipe subimplementation ExampleRecipe // Checks the block at the position to see if it matches the stored data boolean matches(Level level, BlockPos pos); // Creates the block state to set the block at the specified position to BlockState assemble(); // In some manager class public Optional<ExampleRecipe> getRecipeFor(Level level, BlockPos pos) { return level.getRecipeManager() .getAllRecipesFor(exampleRecipeType) // Gets all recipes .stream() // Looks through all recipes for types .filter(recipe -> recipe.matches(level, pos)) // Checks if the recipe inputs are valid .findFirst(); // Finds the first recipe whose inputs match }","title":"Non-Item Logic"},{"location":"resources/server/recipes/custom/#data-generation","text":"All custom recipes, regardless of input or output data, can be created into a FinishedRecipe for data generation using the RecipeProvider .","title":"Data Generation"},{"location":"resources/server/recipes/incode/","text":"Non-Datapack Recipes Not all recipes are simplistic enough or migrated to using data-driven recipes. Some subsystems still need to be patched within the codebase to provide support for adding new recipes. Brewing Recipes Brewing is one of the few recipes that still exist in code. Brewing recipes are added as part of a bootstrap within PotionBrewing for their containers, container recipes, and potion mixes. To expand upon the existing system, Forge allows brewing recipes to be added by calling BrewingRecipeRegistry#addRecipe in FMLCommonSetupEvent . Warning BrewingRecipeRegistry#addRecipe must be called within the synchronous work queue via #enqueueWork as the method is not thread-safe. The default implementation takes in an input ingredient, a catalyst ingredient, and a stack output for a standard implementation. Additionally, an IBrewingRecipe instance can be supplied instead to do the transformations. IBrewingRecipe IBrewingRecipe is a pseudo- Recipe interface that checks whether the input and catalyst is valid and provides the associated output if so. This is provided through #isInput , #isIngredient , and #getOutput respectively. The output method has access to the input and catalyst stacks to construct the result. Important When copying data between ItemStack s or CompoundTag s, make sure to use their respective #copy methods to create unique instances. There is no wrapper for adding additional potion containers or potion mixes similar to vanilla. A new IBrewingRecipe implementation will need to be added to replicate this behavior. Anvil Recipes Anvils are responsible for taking a damaged input and given some material or a similar input, remove some of the damage on the input result. As such, its system is not easily data-driven. However, as anvil recipes are an input with some number of materials equals some output when the user has the required experience levels, it can be modified to create a pseudo-recipe system via AnvilUpdateEvent . This takes in the input and materials and allows the modder to specify the output, experience level cost, and number of materials to use for the output. The event can also prevent any output by canceling it. // Checks whether the left and right items are correct // When true, sets the output, level experience cost, and material amount public void updateAnvil(AnvilUpdateEvent event) { if (event.getLeft().is(...) && event.getRight().is(...)) { event.setOutput(...); event.setCost(...); event.setMaterialCost(...); } } The update event must be attached to the Forge event bus. Loom Recipes Looms are responsible for applying a dye and pattern (either from the loom or from an item) to a banner. While the banner and the dye must be a BannerItem or DyeItem respectively, custom patterns can be created and applied in the loom. Banner Patterns can be created by calling BannerPattern#create during mod construction. Important BannerPattern s which return true for #hasPatternItem do not appear as an option in the loom. These patterns must have an accompanying BannerPatternItem to be used. // In the main mod class public static final BannerPattern EXAMPLE_PATTERN = BannerPattern.create( \"EXAMPLE_MOD_EXAMPLE_PATTERN\", // Name of the enum constant \"examplemod/example_pattern\", // Texture location (assets/minecraft/textures/entity/(banner|shield)/<texture_location>.png) \"examplemod:ep\", // Pattern name to send over the network false // The pattern is an option in the loom ); Important The enum name supplied to BannerPattern#create should be a valid identifier and prefixed with the mod id followed by an underscore _ (e.g. examplemod:example_pattern should be EXAMPLE_MOD_EXAMPLE_PATTERN ).","title":"Non-Datapack Recipes"},{"location":"resources/server/recipes/incode/#non-datapack-recipes","text":"Not all recipes are simplistic enough or migrated to using data-driven recipes. Some subsystems still need to be patched within the codebase to provide support for adding new recipes.","title":"Non-Datapack Recipes"},{"location":"resources/server/recipes/incode/#brewing-recipes","text":"Brewing is one of the few recipes that still exist in code. Brewing recipes are added as part of a bootstrap within PotionBrewing for their containers, container recipes, and potion mixes. To expand upon the existing system, Forge allows brewing recipes to be added by calling BrewingRecipeRegistry#addRecipe in FMLCommonSetupEvent . Warning BrewingRecipeRegistry#addRecipe must be called within the synchronous work queue via #enqueueWork as the method is not thread-safe. The default implementation takes in an input ingredient, a catalyst ingredient, and a stack output for a standard implementation. Additionally, an IBrewingRecipe instance can be supplied instead to do the transformations.","title":"Brewing Recipes"},{"location":"resources/server/recipes/incode/#ibrewingrecipe","text":"IBrewingRecipe is a pseudo- Recipe interface that checks whether the input and catalyst is valid and provides the associated output if so. This is provided through #isInput , #isIngredient , and #getOutput respectively. The output method has access to the input and catalyst stacks to construct the result. Important When copying data between ItemStack s or CompoundTag s, make sure to use their respective #copy methods to create unique instances. There is no wrapper for adding additional potion containers or potion mixes similar to vanilla. A new IBrewingRecipe implementation will need to be added to replicate this behavior.","title":"IBrewingRecipe"},{"location":"resources/server/recipes/incode/#anvil-recipes","text":"Anvils are responsible for taking a damaged input and given some material or a similar input, remove some of the damage on the input result. As such, its system is not easily data-driven. However, as anvil recipes are an input with some number of materials equals some output when the user has the required experience levels, it can be modified to create a pseudo-recipe system via AnvilUpdateEvent . This takes in the input and materials and allows the modder to specify the output, experience level cost, and number of materials to use for the output. The event can also prevent any output by canceling it. // Checks whether the left and right items are correct // When true, sets the output, level experience cost, and material amount public void updateAnvil(AnvilUpdateEvent event) { if (event.getLeft().is(...) && event.getRight().is(...)) { event.setOutput(...); event.setCost(...); event.setMaterialCost(...); } } The update event must be attached to the Forge event bus.","title":"Anvil Recipes"},{"location":"resources/server/recipes/incode/#loom-recipes","text":"Looms are responsible for applying a dye and pattern (either from the loom or from an item) to a banner. While the banner and the dye must be a BannerItem or DyeItem respectively, custom patterns can be created and applied in the loom. Banner Patterns can be created by calling BannerPattern#create during mod construction. Important BannerPattern s which return true for #hasPatternItem do not appear as an option in the loom. These patterns must have an accompanying BannerPatternItem to be used. // In the main mod class public static final BannerPattern EXAMPLE_PATTERN = BannerPattern.create( \"EXAMPLE_MOD_EXAMPLE_PATTERN\", // Name of the enum constant \"examplemod/example_pattern\", // Texture location (assets/minecraft/textures/entity/(banner|shield)/<texture_location>.png) \"examplemod:ep\", // Pattern name to send over the network false // The pattern is an option in the loom ); Important The enum name supplied to BannerPattern#create should be a valid identifier and prefixed with the mod id followed by an underscore _ (e.g. examplemod:example_pattern should be EXAMPLE_MOD_EXAMPLE_PATTERN ).","title":"Loom Recipes"},{"location":"resources/server/recipes/ingredients/","text":"Ingredients Ingredient s are predicate handlers for item-based inputs which check whether a certain ItemStack meets the condition to be a valid input in a recipe. All vanilla recipes that take inputs use an Ingredient or a list of Ingredient s, which is then merged into a single Ingredient . Custom Ingredients Custom ingredients can be specified by setting type to the name of the ingredient\u2019s serializer , with the exception of compound ingredients . When no type is specified, type defaults to the vanilla ingredient minecraft:item . Custom ingredients can also easily be used in data generation . Forge Types Forge provides a few additional Ingredient types for programmers to implement. CompoundIngredient Though they are functionally identical, Compound ingredients replaces the way one would implement a list of ingredients would in a recipe. They work as a set OR where the passed in stack must be within at least one of the supplied ingredients. This change was made to allow custom ingredients to work correctly within lists. As such, no type needs to be specified. // For some input [ // At least one of these ingredients must match to succeed { // Ingredient }, { // Custom ingredient \"type\": \"examplemod:example_ingredient\" } ] NBTIngredient NBTIngredient s compare the item, damage, and the share tags (as defined by IForgeItem#getShareTag ) on an ItemStack for exact equivalency. This can be used by specifying the type as forge:nbt . // For some input { \"type\": \"forge:nbt\", \"item\": \"examplemod:example_item\", \"nbt\": { // Add nbt data (must match exactly what is on the stack) } } PartialNBTIngredient PartialNBTIngredient s are a looser version of NBTIngredient as they compare against a single or set of items and only keys specified within the share tag (as defined by IForgeItem#getShareTag ). This can be used by specifying the type as forge:partial_nbt . // For some input { \"type\": \"forge:partial_nbt\", // Either 'item' or 'items' must be specified // If both are specified, only 'item' will be read \"item\": \"examplemod:example_item\", \"items\": [ \"examplemod:example_item\", \"examplemod:example_item2\" // ... ], \"nbt\": { // Checks only for equivalency on 'key1' and 'key2' // All other keys in the stack will not be checked \"key1\": \"data1\", \"key2\": { // Data 2 } } } IntersectionIngredient IntersectionIngredient s work as a set AND where the passed in stack must match all supplied ingredients. There must be at least two ingredients supplied to this. This can be used by specifying the type as forge:intersection . // For some input { \"type\": \"forge:intersection\", // All of these ingredients must return true to succeed \"children\": [ { // Ingredient 1 }, { // Ingredient 2 } // ... ] } DifferenceIngredient DifferenceIngredient s work as a set subtraction (SUB) where the passed in stack must match the first ingredient but must not match the second ingredient. This can be used by specifying the type as forge:difference . // For some input { \"type\": \"forge:difference\", \"base\": { // Ingredient the stack is in }, \"subtracted\": { // Ingredient the stack is NOT in } } Creating Custom Ingredients Custom ingredients can be created by implementing IIngredientSerializer for the created Ingredient subclass. Tip Custom ingredients should subclass AbstractIngredient as it provides some useful abstractions for ease of implementation. Ingredient Subclass There are three important methods to implement for each ingredient subclass: Method Description getSerializer Returns the serializer used to read and write the ingredient. test Returns true if the input is valid for this ingredient. isSimple Returns false if the ingredient matches on the stack\u2019s tag. AbstractIngredient subclasses will need to define this behavior, while Ingredient subclasses return true by default. All other defined methods are left as an exercise to the reader to use as required for the ingredient subclass. IIngredientSerializer IIngredientSerializer subtypes must implement three methods: Method Description parse (JSON) Converts a JsonObject to an Ingredient . parse (Network) Reads the network buffer to decode an Ingredient . write Writes an Ingredient to the network buffer. Additionally, Ingredient subclasses should implement Ingredient#toJson for use with data generation . AbstractIngredient subclasses make #toJson an abstract method requiring the method to be implemented. Afterwards, a static instance should be declared to hold the initialized serializer and then registered using CraftingHelper#register either during the RegistryEvent$Register for RecipeSerializer s or during FMLCommonSetupEvent . The Ingredient subclass return the static instance of the serializer in Ingredient#getSerializer . // In some serializer class public static final ExampleIngredientSerializer INSTANCE = new ExampleIngredientSerializer(); // In some handler class public void registerSerializers(RegistryEvent.Register<RecipeSerializer<?>> event) { CraftingHelper.register(registryName, INSTANCE); } // In some ingredient subclass @Override public IIngredientSerializer<? extends Ingredient> getSerializer() { return INSTANCE; } Tip If using FMLCommonSetupEvent to register an ingredient serializer, it must be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork as CraftingHelper#register is not thread-safe.","title":"Ingredients"},{"location":"resources/server/recipes/ingredients/#ingredients","text":"Ingredient s are predicate handlers for item-based inputs which check whether a certain ItemStack meets the condition to be a valid input in a recipe. All vanilla recipes that take inputs use an Ingredient or a list of Ingredient s, which is then merged into a single Ingredient .","title":"Ingredients"},{"location":"resources/server/recipes/ingredients/#custom-ingredients","text":"Custom ingredients can be specified by setting type to the name of the ingredient\u2019s serializer , with the exception of compound ingredients . When no type is specified, type defaults to the vanilla ingredient minecraft:item . Custom ingredients can also easily be used in data generation .","title":"Custom Ingredients"},{"location":"resources/server/recipes/ingredients/#forge-types","text":"Forge provides a few additional Ingredient types for programmers to implement.","title":"Forge Types"},{"location":"resources/server/recipes/ingredients/#compoundingredient","text":"Though they are functionally identical, Compound ingredients replaces the way one would implement a list of ingredients would in a recipe. They work as a set OR where the passed in stack must be within at least one of the supplied ingredients. This change was made to allow custom ingredients to work correctly within lists. As such, no type needs to be specified. // For some input [ // At least one of these ingredients must match to succeed { // Ingredient }, { // Custom ingredient \"type\": \"examplemod:example_ingredient\" } ]","title":"CompoundIngredient"},{"location":"resources/server/recipes/ingredients/#nbtingredient","text":"NBTIngredient s compare the item, damage, and the share tags (as defined by IForgeItem#getShareTag ) on an ItemStack for exact equivalency. This can be used by specifying the type as forge:nbt . // For some input { \"type\": \"forge:nbt\", \"item\": \"examplemod:example_item\", \"nbt\": { // Add nbt data (must match exactly what is on the stack) } }","title":"NBTIngredient"},{"location":"resources/server/recipes/ingredients/#partialnbtingredient","text":"PartialNBTIngredient s are a looser version of NBTIngredient as they compare against a single or set of items and only keys specified within the share tag (as defined by IForgeItem#getShareTag ). This can be used by specifying the type as forge:partial_nbt . // For some input { \"type\": \"forge:partial_nbt\", // Either 'item' or 'items' must be specified // If both are specified, only 'item' will be read \"item\": \"examplemod:example_item\", \"items\": [ \"examplemod:example_item\", \"examplemod:example_item2\" // ... ], \"nbt\": { // Checks only for equivalency on 'key1' and 'key2' // All other keys in the stack will not be checked \"key1\": \"data1\", \"key2\": { // Data 2 } } }","title":"PartialNBTIngredient"},{"location":"resources/server/recipes/ingredients/#intersectioningredient","text":"IntersectionIngredient s work as a set AND where the passed in stack must match all supplied ingredients. There must be at least two ingredients supplied to this. This can be used by specifying the type as forge:intersection . // For some input { \"type\": \"forge:intersection\", // All of these ingredients must return true to succeed \"children\": [ { // Ingredient 1 }, { // Ingredient 2 } // ... ] }","title":"IntersectionIngredient"},{"location":"resources/server/recipes/ingredients/#differenceingredient","text":"DifferenceIngredient s work as a set subtraction (SUB) where the passed in stack must match the first ingredient but must not match the second ingredient. This can be used by specifying the type as forge:difference . // For some input { \"type\": \"forge:difference\", \"base\": { // Ingredient the stack is in }, \"subtracted\": { // Ingredient the stack is NOT in } }","title":"DifferenceIngredient"},{"location":"resources/server/recipes/ingredients/#creating-custom-ingredients","text":"Custom ingredients can be created by implementing IIngredientSerializer for the created Ingredient subclass. Tip Custom ingredients should subclass AbstractIngredient as it provides some useful abstractions for ease of implementation.","title":"Creating Custom Ingredients"},{"location":"resources/server/recipes/ingredients/#ingredient-subclass","text":"There are three important methods to implement for each ingredient subclass: Method Description getSerializer Returns the serializer used to read and write the ingredient. test Returns true if the input is valid for this ingredient. isSimple Returns false if the ingredient matches on the stack\u2019s tag. AbstractIngredient subclasses will need to define this behavior, while Ingredient subclasses return true by default. All other defined methods are left as an exercise to the reader to use as required for the ingredient subclass.","title":"Ingredient Subclass"},{"location":"resources/server/recipes/ingredients/#iingredientserializer","text":"IIngredientSerializer subtypes must implement three methods: Method Description parse (JSON) Converts a JsonObject to an Ingredient . parse (Network) Reads the network buffer to decode an Ingredient . write Writes an Ingredient to the network buffer. Additionally, Ingredient subclasses should implement Ingredient#toJson for use with data generation . AbstractIngredient subclasses make #toJson an abstract method requiring the method to be implemented. Afterwards, a static instance should be declared to hold the initialized serializer and then registered using CraftingHelper#register either during the RegistryEvent$Register for RecipeSerializer s or during FMLCommonSetupEvent . The Ingredient subclass return the static instance of the serializer in Ingredient#getSerializer . // In some serializer class public static final ExampleIngredientSerializer INSTANCE = new ExampleIngredientSerializer(); // In some handler class public void registerSerializers(RegistryEvent.Register<RecipeSerializer<?>> event) { CraftingHelper.register(registryName, INSTANCE); } // In some ingredient subclass @Override public IIngredientSerializer<? extends Ingredient> getSerializer() { return INSTANCE; } Tip If using FMLCommonSetupEvent to register an ingredient serializer, it must be enqueued to the synchronous work queue via FMLCommonSetupEvent#enqueueWork as CraftingHelper#register is not thread-safe.","title":"IIngredientSerializer"}]}